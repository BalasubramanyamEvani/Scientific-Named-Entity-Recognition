-DOCSTART- -X- O
Byte-Pair -X- _ B-MethodName
Encoding -X- _ I-MethodName
(BPE) -X- _ I-MethodName
(Sennrich -X- _ O
et -X- _ O
al., -X- _ O
2016) -X- _ O
is -X- _ O
a -X- _ O
hybrid -X- _ O
between -X- _ O
character-and -X- _ O
word-level -X- _ O
representations -X- _ O
that -X- _ O
allows -X- _ O
handling -X- _ O
the -X- _ O
large -X- _ O
vocabularies -X- _ O
common -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
corpora. -X- _ O
Instead -X- _ O
of -X- _ O
full -X- _ O
words, -X- _ O
BPE -X- _ O
relies -X- _ O
on -X- _ O
subwords -X- _ O
units, -X- _ O
which -X- _ O
are -X- _ O
extracted -X- _ O
by -X- _ O
performing -X- _ O
statistical -X- _ O
analysis -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
corpus. -X- _ O
BPE -X- _ O
vocabulary -X- _ O
sizes -X- _ O
typically -X- _ O
range -X- _ O
from -X- _ O
10K-100K -X- _ O
subword -X- _ O
units. -X- _ O
However, -X- _ O
unicode -X- _ O
characters -X- _ O
can -X- _ O
account -X- _ O
for -X- _ O
a -X- _ O
sizeable -X- _ O
portion -X- _ O
of -X- _ O
this -X- _ O
vocabulary -X- _ O
when -X- _ O
modeling -X- _ O
large -X- _ O
and -X- _ O
diverse -X- _ O
corpora, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
ones -X- _ O
considered -X- _ O
in -X- _ O
this -X- _ O
work. -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
(2019) -X- _ O
introduce -X- _ O
a -X- _ O
clever -X- _ O
implementation -X- _ O
of -X- _ O
BPE -X- _ O
that -X- _ O
uses -X- _ O
bytes -X- _ O
instead -X- _ O
of -X- _ O
unicode -X- _ O
characters -X- _ O
as -X- _ O
the -X- _ O
base -X- _ O
subword -X- _ O
units. -X- _ O
Using -X- _ O
bytes -X- _ O
makes -X- _ O
it -X- _ O
possible -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
subword -X- _ O
vocabulary -X- _ O
of -X- _ O
a -X- _ O
modest -X- _ O
size -X- _ O
(50K -X- _ O
units) -X- _ O
that -X- _ O
can -X- _ O
still -X- _ O
encode -X- _ O
any -X- _ O
input -X- _ O
text -X- _ O
without -X- _ O
introducing -X- _ O
any -X- _ O
"unknown" -X- _ O
tokens. -X- _ O
8 -X- _ O
Large -X- _ O
batch -X- _ O
training -X- _ O
can -X- _ O
improve -X- _ O
training -X- _ O
efficiency -X- _ O
even -X- _ O
without -X- _ O
large -X- _ O
scale -X- _ O
parallel -X- _ O
hardware -X- _ O
through -X- _ O
gradient -X- _ O
accumulation, -X- _ O
whereby -X- _ O
gradients -X- _ O
from -X- _ O
multiple -X- _ O
mini-batches -X- _ O
are -X- _ O
accumulated -X- _ O
locally -X- _ O
before -X- _ O
each -X- _ O
optimization -X- _ O
step. -X- _ O
This -X- _ O
functionality -X- _ O
is -X- _ O
supported -X- _ O
natively -X- _ O
in -X- _ O
FAIRSEQ -X- _ O
(Ott -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O
The -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
implementation -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
uses -X- _ O
a -X- _ O
character-level -X- _ O
BPE -X- _ B-HyperparameterName
vocabulary -X- _ I-HyperparameterName
of -X- _ O
size -X- _ O
30K, -X- _ B-HyperparameterValue
which -X- _ O
is -X- _ O
learned -X- _ O
after -X- _ O
preprocessing -X- _ O
the -X- _ O
input -X- _ O
with -X- _ O
heuristic -X- _ O
tokenization -X- _ O
rules. -X- _ O
Following -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
(2019), -X- _ O
we -X- _ O
instead -X- _ O
consider -X- _ O
training -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
a -X- _ O
larger -X- _ O
byte-level -X- _ O
BPE -X- _ B-HyperparameterName
vocabulary -X- _ I-HyperparameterName
containing -X- _ O
50K -X- _ B-HyperparameterValue
subword -X- _ I-HyperparameterValue
units, -X- _ I-HyperparameterValue
without -X- _ O
any -X- _ O
additional -X- _ O
preprocessing -X- _ O
or -X- _ O
tokenization -X- _ O
of -X- _ O
the -X- _ O
input. -X- _ O
This -X- _ O
adds -X- _ O
approximately -X- _ O
15M -X- _ O
and -X- _ O
20M -X- _ O
additional -X- _ O
parameters -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
and -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
, -X- _ O
respectively. -X- _ O
Early -X- _ O
experiments -X- _ O
revealed -X- _ O
only -X- _ O
slight -X- _ O
differences -X- _ O
between -X- _ O
these -X- _ O
encodings, -X- _ O
with -X- _ O
the -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
( -X- _ O
2019) -X- _ O
BPE -X- _ B-MethodName
achieving -X- _ O
slightly -X- _ O
worse -X- _ O
end-task -X- _ O
performance -X- _ O
on -X- _ O
some -X- _ O
tasks. -X- _ O
Nevertheless, -X- _ O
we -X- _ O
believe -X- _ O
the -X- _ O
advantages -X- _ O
of -X- _ O
a -X- _ O
universal -X- _ O
encoding -X- _ O
scheme -X- _ O
outweighs -X- _ O
the -X- _ O
minor -X- _ O
degredation -X- _ O
in -X- _ O
performance -X- _ O
and -X- _ O
use -X- _ O
this -X- _ O
encoding -X- _ O
in -X- _ O
the -X- _ O
remainder -X- _ O
of -X- _ O
our -X- _ O
experiments. -X- _ O
A -X- _ O
more -X- _ O
detailed -X- _ O
comparison -X- _ O
of -X- _ O
these -X- _ O
encodings -X- _ O
is -X- _ O
left -X- _ O
to -X- _ O
future -X- _ O
work. -X- _ O

In -X- _ O
the -X- _ O
previous -X- _ O
section -X- _ O
we -X- _ O
propose -X- _ O
modifications -X- _ O
to -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
pretraining -X- _ O
procedure -X- _ O
that -X- _ O
improve -X- _ O
end-task -X- _ O
performance. -X- _ O
We -X- _ O
now -X- _ O
aggregate -X- _ O
these -X- _ O
improvements -X- _ O
and -X- _ O
evaluate -X- _ O
their -X- _ O
combined -X- _ O
impact. -X- _ O
We -X- _ O
call -X- _ O
this -X- _ O
configuration -X- _ O
RoBERTa -X- _ B-MethodName
for -X- _ O
Robustly -X- _ B-MethodName
optimized -X- _ I-MethodName
BERT -X- _ I-MethodName
approach. -X- _ O
Specifically, -X- _ O
RoBERTa -X- _ B-MethodName
is -X- _ O
trained -X- _ O
with -X- _ O
dynamic -X- _ O
masking -X- _ O
(Section -X- _ O
4.1), -X- _ O
FULL-SENTENCES -X- _ O
without -X- _ O
NSP -X- _ O
loss -X- _ O
(Section -X- _ O
4.2), -X- _ O
large -X- _ O
mini-batches -X- _ O
(Section -X- _ O
4.3) -X- _ O
and -X- _ O
a -X- _ O
larger -X- _ O
byte-level -X- _ O
BPE -X- _ O
(Section -X- _ O
4.4). -X- _ O
Additionally, -X- _ O
we -X- _ O
investigate -X- _ O
two -X- _ O
other -X- _ O
important -X- _ O
factors -X- _ O
that -X- _ O
have -X- _ O
been -X- _ O
under-emphasized -X- _ O
in -X- _ O
previous -X- _ O
work: -X- _ O
(1) -X- _ O
the -X- _ O
data -X- _ O
used -X- _ O
for -X- _ O
pretraining, -X- _ O
and -X- _ O
(2) -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
training -X- _ O
passes -X- _ O
through -X- _ O
the -X- _ O
data. -X- _ O
For -X- _ O
example, -X- _ O
the -X- _ O
recently -X- _ O
proposed -X- _ O
XLNet -X- _ B-MethodName
architecture -X- _ O
(Yang -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
is -X- _ O
pretrained -X- _ O
using -X- _ O
nearly -X- _ O
10 -X- _ O
times -X- _ O
more -X- _ O
data -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
eight -X- _ O
times -X- _ O
larger -X- _ O
for -X- _ O
half -X- _ O
as -X- _ O
many -X- _ O
optimization -X- _ O
steps, -X- _ O
thus -X- _ O
seeing -X- _ O
four -X- _ O
times -X- _ O
as -X- _ O
many -X- _ O
sequences -X- _ O
in -X- _ O
pretraining -X- _ O
compared -X- _ O
to -X- _ O
BERT. -X- _ B-MethodName
To -X- _ O
help -X- _ O
disentangle -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
these -X- _ O
factors -X- _ O
from -X- _ O
other -X- _ O
modeling -X- _ O
choices -X- _ O
(e.g., -X- _ O
the -X- _ O
pretraining -X- _ O
objective), -X- _ O
we -X- _ O
begin -X- _ O
by -X- _ O
training -X- _ O
RoBERTa -X- _ B-MethodName
following -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
architecture -X- _ O
(L -X- _ B-HyperparameterName
= -X- _ O
24, -X- _ B-HyperparameterValue
H -X- _ B-HyperparameterName
= -X- _ O
1024, -X- _ B-HyperparameterValue
A -X- _ B-HyperparameterName
= -X- _ O
16, -X- _ B-HyperparameterValue
355M -X- _ O
parameters). -X- _ O
We -X- _ O
pretrain -X- _ O
for -X- _ O
100K -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
over -X- _ O
a -X- _ O
comparable -X- _ O
BOOK-CORPUS -X- _ B-DatasetName
plus -X- _ O
WIKIPEDIA -X- _ B-DatasetName
dataset -X- _ O
as -X- _ O
was -X- _ O
used -X- _ O
in -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
(2019), -X- _ O
respectively. -X- _ O
Complete -X- _ O
results -X- _ O
on -X- _ O
all -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
Appendix. -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
(2019). -X- _ O
We -X- _ O
pretrain -X- _ O
our -X- _ O
model -X- _ O
using -X- _ O
1024 -X- _ O
V100 -X- _ O
GPUs -X- _ O
for -X- _ O
approximately -X- _ O
one -X- _ O
day. -X- _ O
Results -X- _ O
We -X- _ O
present -X- _ O
our -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
4. -X- _ O
When -X- _ O
controlling -X- _ O
for -X- _ O
training -X- _ O
data, -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
RoBERTa -X- _ B-MethodName
provides -X- _ O
a -X- _ O
large -X- _ O
improvement -X- _ O
over -X- _ O
the -X- _ O
originally -X- _ O
reported -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
results, -X- _ O
reaffirming -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
the -X- _ O
design -X- _ O
choices -X- _ O
we -X- _ O
explored -X- _ O
in -X- _ O
Section -X- _ O
4. -X- _ O
Next, -X- _ O
we -X- _ O
combine -X- _ O
this -X- _ O
data -X- _ O
with -X- _ O
the -X- _ O
three -X- _ O
additional -X- _ O
datasets -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
3.2. -X- _ O
We -X- _ O
train -X- _ O
RoBERTa -X- _ B-MethodName
over -X- _ O
the -X- _ O
combined -X- _ O
data -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
number -X- _ O
of -X- _ O
training -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
as -X- _ O
before -X- _ O
(100K). -X- _ B-HyperparameterValue
In -X- _ O
total, -X- _ O
we -X- _ O
pretrain -X- _ O
over -X- _ O
160GB -X- _ O
of -X- _ O
text. -X- _ O
We -X- _ O
observe -X- _ O
further -X- _ O
improvements -X- _ O
in -X- _ O
performance -X- _ O
across -X- _ O
all -X- _ O
downstream -X- _ O
tasks, -X- _ O
validating -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
data -X- _ O
size -X- _ O
and -X- _ O
diversity -X- _ O
in -X- _ O
pretraining. -X- _ O
9 -X- _ O
Finally, -X- _ O
we -X- _ O
pretrain -X- _ O
RoBERTa -X- _ B-MethodName
for -X- _ O
significantly -X- _ O
longer, -X- _ O
increasing -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
pretraining -X- _ B-HyperparameterName
steps -X- _ I-HyperparameterName
from -X- _ O
100K -X- _ B-HyperparameterValue
to -X- _ I-HyperparameterValue
300K, -X- _ I-HyperparameterValue
and -X- _ O
then -X- _ O
further -X- _ O
to -X- _ O
500K. -X- _ B-HyperparameterValue
We -X- _ O
again -X- _ O
observe -X- _ O
significant -X- _ O
gains -X- _ O
in -X- _ O
downstream -X- _ O
task -X- _ O
performance, -X- _ O
and -X- _ O
the -X- _ O
300K -X- _ O
and -X- _ O
500K -X- _ O
step -X- _ O
models -X- _ O
outperform -X- _ O
XLNet -X- _ B-MethodName
LARGE -X- _ I-MethodName
across -X- _ O
most -X- _ O
tasks. -X- _ O
We -X- _ O
note -X- _ O
that -X- _ O
even -X- _ O
our -X- _ O
longest-trained -X- _ O
model -X- _ O
does -X- _ O
not -X- _ O
appear -X- _ O
to -X- _ O
overfit -X- _ O
our -X- _ O
data -X- _ O
and -X- _ O
would -X- _ O
likely -X- _ O
benefit -X- _ O
from -X- _ O
additional -X- _ O
training. -X- _ O
In -X- _ O
the -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
paper, -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
best -X- _ O
RoBERTa -X- _ B-MethodName
model -X- _ O
on -X- _ O
the -X- _ O
three -X- _ O
different -X- _ O
benchmarks: -X- _ O
GLUE, -X- _ B-DatasetName
SQuaD -X- _ B-DatasetName
and -X- _ O
RACE. -X- _ B-DatasetName
Specifically -X- _ O
we -X- _ O
consider -X- _ O
RoBERTa -X- _ B-MethodName
trained -X- _ O
for -X- _ O
500K -X- _ B-HyperparameterValue
steps -X- _ B-HyperparameterName
over -X- _ O
all -X- _ O
five -X- _ O
of -X- _ O
the -X- _ O
datasets -X- _ O
introduced -X- _ O
in -X- _ O
Section -X- _ O
3.2. -X- _ O

For -X- _ O
GLUE -X- _ B-DatasetName
we -X- _ O
consider -X- _ O
two -X- _ O
finetuning -X- _ O
settings. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
setting -X- _ O
(single-task, -X- _ O
dev) -X- _ O
we -X- _ O
finetune -X- _ O
RoBERTa -X- _ B-MethodName
separately -X- _ O
for -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
tasks, -X- _ O
using -X- _ O
only -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
for -X- _ O
the -X- _ O
corresponding -X- _ O
task. -X- _ O
We -X- _ O
consider -X- _ O
a -X- _ O
limited -X- _ O
hyperparameter -X- _ O
sweep -X- _ O
for -X- _ O
each -X- _ O
task, -X- _ O
with -X- _ O
batch -X- _ B-HyperparameterName
sizes -X- _ I-HyperparameterName
∈ -X- _ O
{16, -X- _ B-HyperparameterValue
32} -X- _ I-HyperparameterValue
and -X- _ O
learning -X- _ B-HyperparameterName
rates -X- _ I-HyperparameterName
∈ -X- _ O
{1e−5, -X- _ B-HyperparameterValue
2e−5, -X- _ I-HyperparameterValue
3e−5}, -X- _ I-HyperparameterValue
with -X- _ O
a -X- _ O
linear -X- _ B-HyperparameterName
warmup -X- _ I-HyperparameterName
for -X- _ O
the -X- _ O
first -X- _ O
6% -X- _ B-HyperparameterValue
of -X- _ O
steps -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
linear -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
to -X- _ O
0. -X- _ O
We -X- _ O
finetune -X- _ O
for -X- _ O
10 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
and -X- _ O
perform -X- _ O
early -X- _ O
stopping -X- _ O
based -X- _ O
on -X- _ O
each -X- _ O
task's -X- _ O
evaluation -X- _ O
metric -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set. -X- _ O
The -X- _ O
rest -X- _ O
of -X- _ O
the -X- _ O
hyperparameters -X- _ O
remain -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
during -X- _ O
pretraining. -X- _ O
In -X- _ O
this -X- _ O
setting, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
median -X- _ O
development -X- _ O
set -X- _ O
results -X- _ O
for -X- _ O
each -X- _ O
task -X- _ O
over -X- _ O
five -X- _ O
random -X- _ O
initializations, -X- _ O
without -X- _ O
model -X- _ O
ensembling. -X- _ O
In -X- _ O
the -X- _ O
second -X- _ O
setting -X- _ O
(ensembles, -X- _ O
test), -X- _ O
we -X- _ O
compare -X- _ O
RoBERTa -X- _ B-MethodName
to -X- _ O
other -X- _ O
approaches -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
via -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
leaderboard. -X- _ O
While -X- _ O
many -X- _ O
submissions -X- _ O
to -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
leaderboard -X- _ O
depend -X- _ O
on -X- _ O
multitask -X- _ O
finetuning, -X- _ O
our -X- _ O
submission -X- _ O
depends -X- _ O
only -X- _ O
on -X- _ O
single-task -X- _ O
finetuning. -X- _ O
For -X- _ O
RTE, -X- _ B-DatasetName
STS -X- _ B-DatasetName
and -X- _ O
MRPC -X- _ B-DatasetName
we -X- _ O
found -X- _ O
it -X- _ O
helpful -X- _ O
to -X- _ O
finetune -X- _ O
starting -X- _ O
from -X- _ O
the -X- _ O
MNLI -X- _ O
single-task -X- _ O
model, -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
baseline -X- _ O
pretrained -X- _ O
RoBERTa. -X- _ O
We -X- _ O
explore -X- _ O
a -X- _ O
slightly -X- _ O
wider -X- _ O
hyperparameter -X- _ O
space, -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
Appendix, -X- _ O
and -X- _ O
ensemble -X- _ O
between -X- _ O
5 -X- _ O
and -X- _ O
7 -X- _ O
models -X- _ O
per -X- _ O
task. -X- _ O
Task-specific -X- _ O
modifications -X- _ O
Two -X- _ O
of -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
require -X- _ O
task-specific -X- _ O
finetuning -X- _ O
approaches -X- _ O
to -X- _ O
achieve -X- _ O
competitive -X- _ O
leaderboard -X- _ O
results. -X- _ O
QNLI: -X- _ B-DatasetName
Recent -X- _ O
submissions -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
leaderboard -X- _ O
adopt -X- _ O
a -X- _ O
pairwise -X- _ O
ranking -X- _ O
formulation -X- _ O
for -X- _ O
the -X- _ O
QNLI -X- _ B-DatasetName
task, -X- _ O
in -X- _ O
which -X- _ O
candidate -X- _ O
answers -X- _ O
are -X- _ O
mined -X- _ O
from -X- _ O
the -X- _ O
training -X- _ O
set -X- _ O
and -X- _ O
compared -X- _ O
to -X- _ O
one -X- _ O
another, -X- _ O
and -X- _ O
a -X- _ O
single -X- _ O
(question, -X- _ O
candidate) -X- _ O
pair -X- _ O
is -X- _ O
classified -X- _ O
as -X- _ O
positive -X- _ O
(Liu -X- _ O
et -X- _ O
al., -X- _ O
2019b,a;Yang -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O
This -X- _ O
formulation -X- _ O
significantly -X- _ O
simplifies -X- _ O
the -X- _ O
task, -X- _ O
but -X- _ O
is -X- _ O
not -X- _ O
directly -X- _ O
comparable -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O
Following -X- _ O
recent -X- _ O
work, -X- _ O
we -X- _ O
adopt -X- _ O
the -X- _ O
ranking -X- _ O
approach -X- _ O
for -X- _ O
our -X- _ O
test -X- _ O
submission, -X- _ O
but -X- _ O
for -X- _ O
direct -X- _ O
comparison -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
we -X- _ O
report -X- _ O
development -X- _ O
set -X- _ O
results -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
pure -X- _ O
classification -X- _ O
approach. -X- _ O
WNLI: -X- _ B-DatasetName
We -X- _ O
found -X- _ O
the -X- _ O
provided -X- _ O
NLI-format -X- _ O
data -X- _ O
to -X- _ O
be -X- _ O
challenging -X- _ O
to -X- _ O
work -X- _ O
with. -X- _ O
Instead -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
reformatted -X- _ O
WNLI -X- _ B-DatasetName
data -X- _ O
from -X- _ O
Super-GLUE -X- _ B-DatasetName
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2019a), -X- _ O
which -X- _ O
indicates -X- _ O
the -X- _ O
span -X- _ O
of -X- _ O
the -X- _ O
query -X- _ O
pronoun -X- _ O
and -X- _ O
referent. -X- _ O
We -X- _ O
finetune -X- _ O
RoBERTa -X- _ B-MethodName
using -X- _ O
the -X- _ O
margin -X- _ O
ranking -X- _ O
loss -X- _ O
from -X- _ O
Kocijan -X- _ O
et -X- _ O
al. -X- _ O
(2019). -X- _ O
For -X- _ O
a -X- _ O
given -X- _ O
input -X- _ O
sentence, -X- _ O
we -X- _ O
use -X- _ O
spaCy -X- _ O
(Honnibal -X- _ O
and -X- _ O
Montani, -X- _ O
2017) -X- _ O
to -X- _ O
extract -X- _ O
additional -X- _ O
candidate -X- _ O
noun -X- _ O
phrases -X- _ O
from -X- _ O
the -X- _ O
sentence -X- _ O
and -X- _ O
finetune -X- _ O
our -X- _ O
model -X- _ O
so -X- _ O
that -X- _ O
it -X- _ O
assigns -X- _ O
higher -X- _ O
scores -X- _ O
to -X- _ O
positive -X- _ O
referent -X- _ O
phrases -X- _ O
than -X- _ O
for -X- _ O
any -X- _ O
of -X- _ O
the -X- _ O
generated -X- _ O
negative -X- _ O
candidate -X- _ O
phrases. -X- _ O
One -X- _ O
unfortunate -X- _ O
consequence -X- _ O
of -X- _ O
this -X- _ O
formulation -X- _ O
is -X- _ O
that -X- _ O
we -X- _ O
can -X- _ O
only -X- _ O
make -X- _ O
use -X- _ O
Results -X- _ O
We -X- _ O
present -X- _ O
our -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
5. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
setting -X- _ O
(single-task, -X- _ O
dev), -X- _ O
RoBERTa -X- _ B-MethodName
achieves -X- _ O
state-of-the-art -X- _ O
results -X- _ O
on -X- _ O
all -X- _ O
9 -X- _ O
of -X- _ O
the -X- _ O
GLUE -X- _ O
task -X- _ O
development -X- _ O
sets. -X- _ O
Crucially, -X- _ O
RoBERTa -X- _ B-MethodName
uses -X- _ O
the -X- _ O
same -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
pretraining -X- _ O
objective -X- _ O
and -X- _ O
architecture -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
, -X- _ O
yet -X- _ O
consistently -X- _ O
outperforms -X- _ O
both -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
and -X- _ O
XLNet -X- _ B-MethodName
LARGE -X- _ I-MethodName
. -X- _ O
This -X- _ O
raises -X- _ O
questions -X- _ O
about -X- _ O
the -X- _ O
relative -X- _ O
importance -X- _ O
of -X- _ O
model -X- _ O
architecture -X- _ O
and -X- _ O
pretraining -X- _ O
objective, -X- _ O
compared -X- _ O
to -X- _ O
more -X- _ O
mundane -X- _ O
details -X- _ O
like -X- _ O
dataset -X- _ O
size -X- _ O
and -X- _ O
training -X- _ O
time -X- _ O
that -X- _ O
we -X- _ O
explore -X- _ O
in -X- _ O
this -X- _ O
work. -X- _ O
In -X- _ O
the -X- _ O
second -X- _ O
setting -X- _ O
(ensembles, -X- _ O
test), -X- _ O
we -X- _ O
submit -X- _ O
RoBERTa -X- _ B-MethodName
to -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
leaderboard -X- _ O
and -X- _ O
achieve -X- _ O
state-of-the-art -X- _ O
results -X- _ O
on -X- _ O
4 -X- _ O
out -X- _ O
of -X- _ O
9 -X- _ O
tasks -X- _ O
and -X- _ O
the -X- _ O
highest -X- _ O
average -X- _ O
score -X- _ O
to -X- _ O
date. -X- _ O
This -X- _ O
is -X- _ O
especially -X- _ O
exciting -X- _ O
because -X- _ O
RoBERTa -X- _ B-MethodName
does -X- _ O
not -X- _ O
depend -X- _ O
on -X- _ O
multi-task -X- _ O
finetuning, -X- _ O
unlike -X- _ O
most -X- _ O
of -X- _ O
the -X- _ O
other -X- _ O
top -X- _ O
submissions. -X- _ O
We -X- _ O
expect -X- _ O
future -X- _ O
work -X- _ O
may -X- _ O
further -X- _ O
improve -X- _ O
these -X- _ O
results -X- _ O
by -X- _ O
incorporating -X- _ O
more -X- _ O
sophisticated -X- _ O
multi-task -X- _ O
finetuning -X- _ O
procedures. -X- _ O

We -X- _ O
adopt -X- _ O
a -X- _ O
much -X- _ O
simpler -X- _ O
approach -X- _ O
for -X- _ O
SQuAD -X- _ B-DatasetName
compared -X- _ O
to -X- _ O
past -X- _ O
work. -X- _ O
In -X- _ O
particular, -X- _ O
while -X- _ O
both -X- _ O
BERT -X- _ B-MethodName
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
and -X- _ O
XL-Net -X- _ B-MethodName
(Yang -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
XLNet, -X- _ B-MethodName
while -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
learning -X- _ O
rate -X- _ O
for -X- _ O
all -X- _ O
layers. -X- _ O
For -X- _ O
SQuAD -X- _ B-DatasetName
v1.1 -X- _ I-DatasetName
we -X- _ O
follow -X- _ O
the -X- _ O
same -X- _ O
finetuning -X- _ O
procedure -X- _ O
as -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
(2019). -X- _ O
For -X- _ O
SQuAD -X- _ B-DatasetName
v2.0, -X- _ I-DatasetName
we -X- _ O
additionally -X- _ O
classify -X- _ O
whether -X- _ O
a -X- _ O
given -X- _ O
question -X- _ O
is -X- _ O
answerable; -X- _ O
we -X- _ O
train -X- _ O
this -X- _ O
classifier -X- _ O
jointly -X- _ O
with -X- _ O
the -X- _ O
span -X- _ O
predictor -X- _ O
by -X- _ O
summing -X- _ O
the -X- _ O
classification -X- _ O
and -X- _ O
span -X- _ O
loss -X- _ O
terms. -X- _ O

We -X- _ O
present -X- _ O
our -X- _ O
results -X- _ O
in -X- _ O
Table -X- _ O
6. -X- _ O
On -X- _ O
the -X- _ O
SQuAD -X- _ O
v1.1 -X- _ O
development -X- _ O
set, -X- _ O
RoBERTa -X- _ B-MethodName
matches -X- _ O
the -X- _ O
state-of-the-art -X- _ O
set -X- _ O
by -X- _ O
XLNet. -X- _ B-MethodName
On -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
v2.0 -X- _ I-DatasetName
development -X- _ O
set, -X- _ O
RoBERTa -X- _ B-DatasetName
sets -X- _ O
a -X- _ O
new -X- _ O
state-of-the-art, -X- _ O
improving -X- _ O
over -X- _ O
XLNet -X- _ B-DatasetName
by -X- _ B-MetricValue
0.4 -X- _ I-MetricValue
points -X- _ I-MetricValue
(EM) -X- _ B-MetricName
and -X- _ O
0.6 -X- _ B-MetricValue
points -X- _ I-MetricValue
(F1). -X- _ B-MetricName
We -X- _ O
also -X- _ O
submit -X- _ O
RoBERTa -X- _ B-MethodName
to -X- _ O
the -X- _ O
public -X- _ O
SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
leaderboard -X- _ O
and -X- _ O
evaluate -X- _ O
its -X- _ O
performance -X- _ O
relative -X- _ O
to -X- _ O
other -X- _ O
systems. -X- _ O
Most -X- _ O
of -X- _ O
the -X- _ O
top -X- _ O
systems -X- _ O
build -X- _ O
upon -X- _ O
either -X- _ O
BERT -X- _ B-MethodName
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
or -X- _ O
XLNet -X- _ B-MethodName
(Yang -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
both -X- _ O
of -X- _ O
which -X- _ O
rely -X- _ O
on -X- _ O
additional -X- _ O
external -X- _ O
training -X- _ O
data. -X- _ O
In -X- _ O
contrast, -X- _ O
our -X- _ O
submission -X- _ O
does -X- _ O
not -X- _ O
use -X- _ O
any -X- _ O
additional -X- _ O
data. -X- _ O
Our -X- _ O
single -X- _ B-MethodName
RoBERTa -X- _ I-MethodName
model -X- _ O
outperforms -X- _ O
all -X- _ O
but -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
single -X- _ O
model -X- _ O
submissions, -X- _ O
and -X- _ O
is -X- _ O
the -X- _ O
top -X- _ O
scoring -X- _ O
system -X- _ O
among -X- _ O
those -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
data -X- _ O
augmentation. -X- _ O

In -X- _ O
RACE, -X- _ B-DatasetName
systems -X- _ O
are -X- _ O
provided -X- _ O
with -X- _ O
a -X- _ O
passage -X- _ O
of -X- _ O
text, -X- _ O
an -X- _ O
associated -X- _ O
question, -X- _ O
and -X- _ O
four -X- _ O
candidate -X- _ O
answers. -X- _ O
Systems -X- _ O
are -X- _ O
required -X- _ O
to -X- _ O
classify -X- _ O
which -X- _ O
of -X- _ O
the -X- _ O
four -X- _ O
candidate -X- _ O
answers -X- _ O
is -X- _ O
correct. -X- _ O
We -X- _ O
modify -X- _ O
RoBERTa -X- _ B-MethodName
for -X- _ O
this -X- _ O
task -X- _ O
by -X- _ O
concate- -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
(2019). -X- _ O
nating -X- _ O
each -X- _ O
candidate -X- _ O
answer -X- _ O
with -X- _ O
the -X- _ O
corresponding -X- _ O
question -X- _ O
and -X- _ O
passage. -X- _ O
We -X- _ O
then -X- _ O
encode -X- _ O
each -X- _ O
of -X- _ O
these -X- _ O
four -X- _ O
sequences -X- _ O
and -X- _ O
pass -X- _ O
the -X- _ O
resulting -X- _ O
[CLS] -X- _ O
representations -X- _ O
through -X- _ O
a -X- _ O
fully-connected -X- _ O
layer, -X- _ O
which -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
correct -X- _ O
answer. -X- _ O
We -X- _ O
truncate -X- _ O
question-answer -X- _ O
pairs -X- _ O
that -X- _ O
are -X- _ O
longer -X- _ O
than -X- _ O
128 -X- _ O
tokens -X- _ O
and, -X- _ O
if -X- _ O
needed, -X- _ O
the -X- _ O
passage -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
total -X- _ O
length -X- _ O
is -X- _ O
at -X- _ O
most -X- _ O
512 -X- _ O
tokens. -X- _ O
Results -X- _ O
on -X- _ O
the -X- _ O
RACE -X- _ B-DatasetName
test -X- _ O
sets -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
7. -X- _ O
RoBERTa -X- _ B-MethodName
achieves -X- _ O
state-of-the-art -X- _ O
results -X- _ O
on -X- _ O
both -X- _ O
middle-school -X- _ O
and -X- _ O
high-school -X- _ O
settings. -X- _ O

Past -X- _ O
work -X- _ O
in -X- _ O
Neural -X- _ B-TaskName
Machine -X- _ I-TaskName
Translation -X- _ I-TaskName
has -X- _ O
shown -X- _ O
that -X- _ O
training -X- _ O
with -X- _ O
very -X- _ O
large -X- _ O
mini-batches -X- _ B-HyperparameterName
can -X- _ O
both -X- _ O
improve -X- _ O
optimization -X- _ O
speed -X- _ O
and -X- _ O
end-task -X- _ O
performance -X- _ O
when -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
increased -X- _ O
appropriately -X- _ O
(Ott -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O
Recent -X- _ O
work -X- _ O
has -X- _ O
shown -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
also -X- _ O
amenable -X- _ O
to -X- _ O
large -X- _ O
batch -X- _ O
training -X- _ O
(You -X- _ O
et -X- _ O
al., -X- _ O
2019 -X- _ O

In -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
pretraining -X- _ O
procedure, -X- _ O
the -X- _ O
model -X- _ O
observes -X- _ O
two -X- _ O
concatenated -X- _ O
document -X- _ O
segments, -X- _ O
which -X- _ O
are -X- _ O
either -X- _ O
sampled -X- _ O
contiguously -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
document -X- _ O
(with -X- _ O
p -X- _ B-MetricName
= -X- _ O
0.5) -X- _ B-MetricValue
or -X- _ O
from -X- _ O
distinct -X- _ O
documents. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
objective, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
the -X- _ O
observed -X- _ O
document -X- _ O
segments -X- _ O
come -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
or -X- _ O
distinct -X- _ O
documents -X- _ O
via -X- _ O
an -X- _ O
auxiliary -X- _ O
Next -X- _ O
Sentence -X- _ O
Prediction -X- _ O
(NSP) -X- _ O
loss. -X- _ O
The -X- _ O
NSP -X- _ O
loss -X- _ O
was -X- _ O
hypothesized -X- _ O
to -X- _ O
be -X- _ O
an -X- _ O
important -X- _ O
factor -X- _ O
in -X- _ O
training -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
model. -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
(2019) -X- _ O
observe -X- _ O
that -X- _ O
removing -X- _ O
NSP -X- _ O
hurts -X- _ O
performance, -X- _ O
with -X- _ O
significant -X- _ O
performance -X- _ O
degradation -X- _ O
on -X- _ O
QNLI, -X- _ B-DatasetName
MNLI, -X- _ B-DatasetName
and -X- _ O
SQuAD -X- _ B-DatasetName
1.1. -X- _ I-DatasetName
However, -X- _ O
some -X- _ O
recent -X- _ O
work -X- _ O
has -X- _ O
questioned -X- _ O
the -X- _ O
necessity -X- _ O
of -X- _ O
the -X- _ O
NSP -X- _ O
loss -X- _ O
(Lample -X- _ O
and -X- _ O
Conneau, -X- _ O
2019;Yang -X- _ O
et -X- _ O
al., -X- _ O
2019;Joshi -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O
To -X- _ O
better -X- _ O
understand -X- _ O
this -X- _ O
discrepancy, -X- _ O
we -X- _ O
compare -X- _ O
several -X- _ O
alternative -X- _ O
training -X- _ O
formats: -X- _ O
• -X- _ O
SEGMENT-PAIR+NSP: -X- _ O
This -X- _ O
follows -X- _ O
the -X- _ O
original -X- _ O
input -X- _ O
format -X- _ O
used -X- _ O
in -X- _ O
BERT -X- _ B-MethodName
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
with -X- _ O
the -X- _ O
NSP -X- _ O
loss. -X- _ O
Each -X- _ O
input -X- _ O
has -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
segments, -X- _ O
which -X- _ O
can -X- _ O
each -X- _ O
contain -X- _ O
multiple -X- _ O
natural -X- _ O
sentences, -X- _ O
but -X- _ O
the -X- _ O
total -X- _ O
combined -X- _ O
length -X- _ O
must -X- _ O
be -X- _ O
less -X- _ O
than -X- _ O
512 -X- _ O
tokens. -X- _ O
• -X- _ O
SENTENCE-PAIR+NSP: -X- _ O
Each -X- _ O
input -X- _ O
contains -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
natural -X- _ O
sentences, -X- _ O
either -X- _ O
sampled -X- _ O
from -X- _ O
a -X- _ O
contiguous -X- _ O
portion -X- _ O
of -X- _ O
one -X- _ O
document -X- _ O
or -X- _ O
from -X- _ O
separate -X- _ O
documents. -X- _ O
Since -X- _ O
these -X- _ O
inputs -X- _ O
are -X- _ O
significantly -X- _ O
shorter -X- _ O
than -X- _ O
512 -X- _ O
tokens, -X- _ O
we -X- _ O
increase -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
so -X- _ O
that -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
tokens -X- _ O
remains -X- _ O
similar -X- _ O
to -X- _ O
SEGMENT-PAIR+NSP. -X- _ O
We -X- _ O
retain -X- _ O
the -X- _ O
NSP -X- _ O
loss. -X- _ O
• -X- _ O
FULL-SENTENCES: -X- _ O
Each -X- _ O
input -X- _ O
is -X- _ O
packed -X- _ O
with -X- _ O
full -X- _ O
sentences -X- _ O
sampled -X- _ O
contiguously -X- _ O
from -X- _ O
one -X- _ O
or -X- _ O
more -X- _ O
documents, -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
total -X- _ O
length -X- _ O
is -X- _ O
at -X- _ O
most -X- _ O
512 -X- _ O
tokens. -X- _ O
Inputs -X- _ O
may -X- _ O
cross -X- _ O
document -X- _ O
boundaries. -X- _ O
When -X- _ O
we -X- _ O
reach -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
one -X- _ O
document, -X- _ O
we -X- _ O
begin -X- _ O
sampling -X- _ O
sentences -X- _ O
from -X- _ O
the -X- _ O
next -X- _ O
document -X- _ O
and -X- _ O
add -X- _ O
an -X- _ O
extra -X- _ O
separator -X- _ O
token -X- _ O
between -X- _ O
documents. -X- _ O
We -X- _ O
remove -X- _ O
the -X- _ O
NSP -X- _ O
loss. -X- _ O
• -X- _ O
DOC-SENTENCES: -X- _ O
Inputs -X- _ O
are -X- _ O
constructed -X- _ O
similarly -X- _ O
to -X- _ O
FULL-SENTENCES, -X- _ O
except -X- _ O
that -X- _ O
they -X- _ O
may -X- _ O
not -X- _ O
cross -X- _ O
document -X- _ O
boundaries. -X- _ O
Inputs -X- _ O
sampled -X- _ O
near -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
a -X- _ O
document -X- _ O
may -X- _ O
be -X- _ O
shorter -X- _ O
than -X- _ O
512 -X- _ O
tokens, -X- _ O
so -X- _ O
we -X- _ O
dynamically -X- _ O
increase -X- _ O
the -X- _ O
batch -X- _ O
size -X- _ O
in -X- _ O
these -X- _ O
cases -X- _ O
to -X- _ O
achieve -X- _ O
a -X- _ O
similar -X- _ O
number -X- _ O
of -X- _ O
total -X- _ O
tokens -X- _ O
as -X- _ O
FULL-SENTENCES. -X- _ O
We -X- _ O
remove -X- _ O
the -X- _ O
NSP -X- _ O
loss. -X- _ O
Results -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
results -X- _ O
for -X- _ O
the -X- _ O
four -X- _ O
different -X- _ O
settings. -X- _ O
We -X- _ O
first -X- _ O
compare -X- _ O
the -X- _ O
original -X- _ O
SEGMENT-PAIR -X- _ O
input -X- _ O
format -X- _ O
from -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
(2019) -X- _ O
to -X- _ O
the -X- _ O
SENTENCE-PAIR -X- _ O
format; -X- _ O
both -X- _ O
formats -X- _ O
retain -X- _ O
the -X- _ O
NSP -X- _ O
loss, -X- _ O
but -X- _ O
the -X- _ O
latter -X- _ O
uses -X- _ O
single -X- _ O
sentences. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
using -X- _ O
individual -X- _ O
sentences -X- _ O
hurts -X- _ O
performance -X- _ O
on -X- _ O
downstream -X- _ O
tasks, -X- _ O
which -X- _ O
we -X- _ O
hypothesize -X- _ O
is -X- _ O
because -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
not -X- _ O
able -X- _ O
to -X- _ O
learn -X- _ O
long-range -X- _ O
dependencies. -X- _ O
We -X- _ O
next -X- _ O
compare -X- _ O
training -X- _ O
without -X- _ O
the -X- _ O
NSP -X- _ O
loss -X- _ O
and -X- _ O
training -X- _ O
with -X- _ O
blocks -X- _ O
of -X- _ O
text -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
document -X- _ O
(DOC-SENTENCES). -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
this -X- _ O
setting -X- _ O
outperforms -X- _ O
the -X- _ O
originally -X- _ O
published -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
results -X- _ O
and -X- _ O
that -X- _ O
removing -X- _ O
the -X- _ O
NSP -X- _ O
loss -X- _ O
matches -X- _ O
or -X- _ O
slightly -X- _ O
improves -X- _ O
downstream -X- _ O
task -X- _ O
performance, -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
(2019). -X- _ O
It -X- _ O
is -X- _ O
possible -X- _ O
that -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
implementation -X- _ O
may -X- _ O
only -X- _ O
have -X- _ O
removed -X- _ O
the -X- _ O
loss -X- _ O
term -X- _ O
while -X- _ O
still -X- _ O
retaining -X- _ O
the -X- _ O
SEGMENT-PAIR -X- _ O
input -X- _ O
format. -X- _ O
Finally -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
restricting -X- _ O
sequences -X- _ O
to -X- _ O
come -X- _ O
from -X- _ O
a -X- _ O
single -X- _ O
document -X- _ O
(DOC-SENTENCES) -X- _ O
performs -X- _ O
slightly -X- _ O
better -X- _ O
than -X- _ O
packing -X- _ O
sequences -X- _ O
from -X- _ O
multiple -X- _ O
documents -X- _ O
(FULL-SENTENCES). -X- _ O
However, -X- _ O
because -X- _ O
the -X- _ O
DOC-SENTENCES -X- _ O
format -X- _ O
results -X- _ O
in -X- _ O
variable -X- _ O
batch -X- _ O
sizes, -X- _ O
we -X- _ O
use -X- _ O
FULL-SENTENCES -X- _ O
in -X- _ O
the -X- _ O
remainder -X- _ O
of -X- _ O
our -X- _ O
experiments -X- _ O
for -X- _ O
easier -X- _ O
comparison -X- _ O
with -X- _ O
related -X- _ O
work. -X- _ O

As -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
2, -X- _ O
BERT -X- _ B-MethodName
relies -X- _ O
on -X- _ O
randomly -X- _ O
masking -X- _ O
and -X- _ O
predicting -X- _ O
tokens. -X- _ O
The -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
implementation -X- _ O
performed -X- _ O
masking -X- _ O
once -X- _ O
during -X- _ O
data -X- _ O
preprocessing, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
single -X- _ O
static -X- _ O
mask. -X- _ O
To -X- _ O
avoid -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
mask -X- _ O
for -X- _ O
each -X- _ O
training -X- _ O
instance -X- _ O
in -X- _ O
every -X- _ O
epoch, -X- _ O
training -X- _ O
data -X- _ O
was -X- _ O
duplicated -X- _ O
10 -X- _ O
times -X- _ O
so -X- _ O
that -X- _ O
each -X- _ O
sequence -X- _ O
is -X- _ O
masked -X- _ O
in -X- _ O
10 -X- _ O
different -X- _ O
ways -X- _ O
over -X- _ O
the -X- _ O
40 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
of -X- _ O
training. -X- _ O
Thus, -X- _ O
each -X- _ O
training -X- _ O
sequence -X- _ O
was -X- _ O
seen -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
mask -X- _ O
four -X- _ O
times -X- _ O
during -X- _ O
training. -X- _ O
We -X- _ O
compare -X- _ O
this -X- _ O
strategy -X- _ O
with -X- _ O
dynamic -X- _ O
masking -X- _ O
where -X- _ O
we -X- _ O
generate -X- _ O
the -X- _ O
masking -X- _ O
pattern -X- _ O
every -X- _ O
time -X- _ O
we -X- _ O
feed -X- _ O
a -X- _ O
sequence -X- _ O
to -X- _ O
the -X- _ O
model. -X- _ O
This -X- _ O
becomes -X- _ O
crucial -X- _ O
when -X- _ O
pretraining -X- _ O
for -X- _ O
more -X- _ O
steps -X- _ O
or -X- _ O
with -X- _ O
larger -X- _ O
datasets. -X- _ O
Results -X- _ O
Table -X- _ O
1 -X- _ O
compares -X- _ O
the -X- _ O
published -X- _ O
BERT -X- _ O
BASE -X- _ O
results -X- _ O
from -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
(2019) -X- _ O
to -X- _ O
our -X- _ O
reimplementation -X- _ O
with -X- _ O
either -X- _ O
static -X- _ O
or -X- _ O
dynamic -X- _ O
masking. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
our -X- _ O
reimplementation -X- _ O
with -X- _ O
static -X- _ O
masking -X- _ O
performs -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
model, -X- _ O
and -X- _ O
dynamic -X- _ O
masking -X- _ O
is -X- _ O
comparable -X- _ O
or -X- _ O
slightly -X- _ O
better -X- _ O
than -X- _ O
static -X- _ O
masking. -X- _ O
Given -X- _ O
these -X- _ O
results -X- _ O
and -X- _ O
the -X- _ O
additional -X- _ O
efficiency -X- _ O
benefits -X- _ O
of -X- _ O
dynamic -X- _ O
masking, -X- _ O
we -X- _ O
use -X- _ O
dynamic -X- _ O
masking -X- _ O
in -X- _ O
the -X- _ O
remainder -X- _ O
of -X- _ O
the -X- _ O
experiments. -X- _ O

Pretraining -X- _ O
methods -X- _ O
have -X- _ O
been -X- _ O
designed -X- _ O
with -X- _ O
different -X- _ O
training -X- _ O
objectives, -X- _ O
including -X- _ O
language -X- _ O
modeling -X- _ O
(Dai -X- _ O
and -X- _ O
Le, -X- _ O
2015;Peters -X- _ O
et -X- _ O
al., -X- _ O
2018;Howard -X- _ O
and -X- _ O
Ruder, -X- _ O
2018), -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
(McCann -X- _ O
et -X- _ O
al., -X- _ O
2017), -X- _ O
and -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019;Lample -X- _ O
and -X- _ O
Conneau, -X- _ O
2019). -X- _ O
Many -X- _ O
recent -X- _ O
papers -X- _ O
have -X- _ O
used -X- _ O
a -X- _ O
basic -X- _ O
recipe -X- _ O
of -X- _ O
finetuning -X- _ O
models -X- _ O
for -X- _ O
each -X- _ O
end -X- _ O
task -X- _ O
(Howard -X- _ O
and -X- _ O
Ruder, -X- _ O
2018;Radford -X- _ O
et -X- _ O
al., -X- _ O
2018), -X- _ O
and -X- _ O
pretraining -X- _ O
with -X- _ O
some -X- _ O
variant -X- _ O
of -X- _ O
a -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
objective. -X- _ O
However, -X- _ O
newer -X- _ O
methods -X- _ O
have -X- _ O
improved -X- _ O
performance -X- _ O
by -X- _ O
multi-task -X- _ O
fine -X- _ O
tuning -X- _ O
(Dong -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
incorporating -X- _ O
entity -X- _ O
embeddings -X- _ O
(Sun -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
span -X- _ O
prediction -X- _ O
(Joshi -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
and -X- _ O
multiple -X- _ O
variants -X- _ O
of -X- _ O
autoregressive -X- _ O
pretraining -X- _ O
Chan -X- _ O
et -X- _ O
al., -X- _ O
2019;Yang -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O
Performance -X- _ O
is -X- _ O
also -X- _ O
typically -X- _ O
improved -X- _ O
by -X- _ O
training -X- _ O
bigger -X- _ O
models -X- _ O
on -X- _ O
more -X- _ O
data -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019;Yang -X- _ O
et -X- _ O
al., -X- _ O
2019;Radford -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O
Our -X- _ O
goal -X- _ O
was -X- _ O
to -X- _ O
replicate, -X- _ O
simplify, -X- _ O
and -X- _ O
better -X- _ O
tune -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
BERT, -X- _ B-MethodName
as -X- _ O
a -X- _ O
reference -X- _ O
point -X- _ O
for -X- _ O
better -X- _ O
understanding -X- _ O
the -X- _ O
relative -X- _ O
performance -X- _ O
of -X- _ O
all -X- _ O
of -X- _ O
these -X- _ O
methods. -X- _ O
We -X- _ O
carefully -X- _ O
evaluate -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
design -X- _ O
decisions -X- _ O
when -X- _ O
pretraining -X- _ O
BERT -X- _ B-MethodName
models. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
performance -X- _ O
can -X- _ O
be -X- _ O
substantially -X- _ O
improved -X- _ O
by -X- _ O
training -X- _ O
the -X- _ O
model -X- _ O
longer, -X- _ O
with -X- _ O
bigger -X- _ O
batches -X- _ O
over -X- _ O
more -X- _ O
data; -X- _ O
removing -X- _ O
the -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
objective; -X- _ O
training -X- _ O
on -X- _ O
longer -X- _ O
sequences; -X- _ O
and -X- _ O
dynamically -X- _ O
changing -X- _ O
the -X- _ O
masking -X- _ O
pattern -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
data. -X- _ O
Our -X- _ O
improved -X- _ O
pretraining -X- _ O
procedure, -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
RoBERTa, -X- _ B-MethodName
achieves -X- _ O
state-of-the-art -X- _ O
results -X- _ O
on -X- _ O
GLUE, -X- _ B-DatasetName
RACE -X- _ B-DatasetName
and -X- _ O
SQuAD, -X- _ B-DatasetName
without -X- _ O
multi-task -X- _ O
finetuning -X- _ O
for -X- _ O
GLUE -X- _ B-DatasetName
or -X- _ O
additional -X- _ O
data -X- _ O
for -X- _ O
SQuAD. -X- _ B-DatasetName
These -X- _ O
results -X- _ O
illustrate -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
these -X- _ O
previously -X- _ O
overlooked -X- _ O
design -X- _ O
decisions -X- _ O
and -X- _ O
suggest -X- _ O
that -X- _ O
BERT's -X- _ B-MethodName
pretraining -X- _ O
objective -X- _ O
remains -X- _ O
competitive -X- _ O
with -X- _ O
recently -X- _ O
proposed -X- _ O
alternatives. -X- _ O
We -X- _ O
additionally -X- _ O
use -X- _ O
a -X- _ O
novel -X- _ O
dataset, -X- _ O
CC-NEWS, -X- _ B-DatasetName
and -X- _ O
release -X- _ O
our -X- _ O
models -X- _ O
and -X- _ O
code -X- _ O
for -X- _ O
pretraining -X- _ O
and -X- _ O
finetuning -X- _ O
at: -X- _ O

This -X- _ O
section -X- _ O
explores -X- _ O
and -X- _ O
quantifies -X- _ O
which -X- _ O
choices -X- _ O
are -X- _ O
important -X- _ O
for -X- _ O
successfully -X- _ O
pretraining -X- _ O
BERT -X- _ B-MethodName
models. -X- _ O
We -X- _ O
keep -X- _ O
the -X- _ O
model -X- _ O
architecture -X- _ O
fixed. -X- _ O
7 -X- _ O
Specifically, -X- _ O
we -X- _ O
begin -X- _ O
by -X- _ O
training -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
configuration -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
(L -X- _ B-HyperparameterName
= -X- _ O
12, -X- _ B-HyperparameterValue
H -X- _ B-HyperparameterName
= -X- _ O
768, -X- _ B-HyperparameterValue
A -X- _ B-HyperparameterName
= -X- _ O
12, -X- _ B-HyperparameterValue
110M -X- _ B-MetricValue
params). -X- _ I-MetricValue

Following -X- _ O
previous -X- _ O
work, -X- _ O
we -X- _ O
evaluate -X- _ O
our -X- _ O
pretrained -X- _ O
models -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
using -X- _ O
the -X- _ O
following -X- _ O
three -X- _ O
benchmarks. -X- _ O
GLUE -X- _ B-DatasetName
The -X- _ B-DatasetName
General -X- _ I-DatasetName
Language -X- _ I-DatasetName
Understanding -X- _ I-DatasetName
Evaluation -X- _ I-DatasetName
(GLUE) -X- _ I-DatasetName
benchmark -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2019b) -X- _ O
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
9 -X- _ O
datasets -X- _ O
for -X- _ O
evaluating -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
systems. -X- _ O
6 -X- _ O
Tasks -X- _ O
are -X- _ O
framed -X- _ O
as -X- _ O
either -X- _ O
single-sentence -X- _ O
classification -X- _ O
or -X- _ O
sentence-pair -X- _ O
classification -X- _ O
tasks. -X- _ O
The -X- _ O
GLUE -X- _ B-DatasetName
organizers -X- _ O
provide -X- _ O
training -X- _ O
and -X- _ O
development -X- _ O
data -X- _ O
splits -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
submission -X- _ O
server -X- _ O
and -X- _ O
leaderboard -X- _ O
that -X- _ O
allows -X- _ O
participants -X- _ O
to -X- _ O
evaluate -X- _ O
and -X- _ O
compare -X- _ O
their -X- _ O
systems -X- _ O
on -X- _ O
private -X- _ O
held-out -X- _ O
test -X- _ O
data. -X- _ O
For -X- _ O
the -X- _ O
replication -X- _ O
study -X- _ O
in -X- _ O
Section -X- _ O
4, -X- _ O
we -X- _ O
report -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
sets -X- _ O
after -X- _ O
finetuning -X- _ O
the -X- _ O
pretrained -X- _ O
models -X- _ O
on -X- _ O
the -X- _ O
corresponding -X- _ O
singletask -X- _ O
training -X- _ O
data -X- _ O
(i.e., -X- _ O
without -X- _ O
multi-task -X- _ O
training -X- _ O
or -X- _ O
ensembling). -X- _ O
Our -X- _ O
finetuning -X- _ O
procedure -X- _ O
follows -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
paper -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O
In -X- _ O
Section -X- _ O
5 -X- _ O
we -X- _ O
additionally -X- _ O
report -X- _ O
test -X- _ O
set -X- _ O
results -X- _ O
obtained -X- _ O
from -X- _ O
the -X- _ O
public -X- _ O
leaderboard. -X- _ O
These -X- _ O
results -X- _ O
depend -X- _ O
on -X- _ O
a -X- _ O
several -X- _ O
task-specific -X- _ O
modifications, -X- _ O
which -X- _ O
we -X- _ O
describe -X- _ O
in -X- _ O
Section -X- _ O
5.1. -X- _ O
SQuAD -X- _ B-DatasetName
The -X- _ B-DatasetName
Stanford -X- _ I-DatasetName
Question -X- _ I-DatasetName
Answering -X- _ I-DatasetName
Dataset -X- _ I-DatasetName
(SQuAD) -X- _ I-DatasetName
provides -X- _ O
a -X- _ O
paragraph -X- _ O
of -X- _ O
context -X- _ O
and -X- _ O
a -X- _ O
question. -X- _ O
The -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
question -X- _ O
by -X- _ O
extracting -X- _ O
the -X- _ O
relevant -X- _ O
span -X- _ O
from -X- _ O
the -X- _ O
context. -X- _ O
We -X- _ O
evaluate -X- _ O
on -X- _ O
two -X- _ O
versions -X- _ O
of -X- _ O
SQuAD: -X- _ B-DatasetName
V1.1 -X- _ O
and -X- _ O
V2.0 -X- _ O
(Rajpurkar -X- _ O
et -X- _ O
al., -X- _ O
2016(Rajpurkar -X- _ O
et -X- _ O
al., -X- _ O
, -X- _ O
2018. -X- _ O
In -X- _ O
V1.1 -X- _ O
the -X- _ O
context -X- _ O
always -X- _ O
contains -X- _ O
an -X- _ O
answer, -X- _ O
whereas -X- _ O
in -X- _ O
V2.0 -X- _ O
some -X- _ O
questions -X- _ O
are -X- _ O
not -X- _ O
answered -X- _ O
in -X- _ O
the -X- _ O
provided -X- _ O
context, -X- _ O
making -X- _ O
the -X- _ O
task -X- _ O
more -X- _ O
challenging. -X- _ O
For -X- _ O
SQuAD -X- _ B-DatasetName
V1.1 -X- _ I-DatasetName
we -X- _ O
adopt -X- _ O
the -X- _ O
same -X- _ O
span -X- _ O
prediction -X- _ O
method -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O
For -X- _ O
SQuAD -X- _ B-DatasetName
V2.0, -X- _ I-DatasetName
we -X- _ O
add -X- _ O
an -X- _ O
additional -X- _ O
binary -X- _ O
classifier -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
the -X- _ O
question -X- _ O
is -X- _ O
answerable, -X- _ O
which -X- _ O
we -X- _ O
train -X- _ O
jointly -X- _ O
by -X- _ O
summing -X- _ O
the -X- _ O
classification -X- _ O
and -X- _ O
span -X- _ O
loss -X- _ O
terms. -X- _ O
During -X- _ O
evaluation, -X- _ O
we -X- _ O
only -X- _ O
predict -X- _ O
span -X- _ O
indices -X- _ O
on -X- _ O
pairs -X- _ O
that -X- _ O
are -X- _ O
classified -X- _ O
as -X- _ O
answerable. -X- _ O
RACE -X- _ B-DatasetName
The -X- _ B-DatasetName
ReAding -X- _ I-DatasetName
Comprehension -X- _ I-DatasetName
from -X- _ I-DatasetName
Examinations -X- _ I-DatasetName
(RACE) -X- _ I-DatasetName
(Lai -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
task -X- _ O
is -X- _ O
a -X- _ O
large-scale -X- _ O
reading -X- _ O
comprehension -X- _ O
dataset -X- _ O
with -X- _ O
more -X- _ O
than -X- _ O
28,000 -X- _ O
passages -X- _ O
and -X- _ O
nearly -X- _ O
100,000 -X- _ O
questions. -X- _ O
The -X- _ O
dataset -X- _ O
is -X- _ O
collected -X- _ O
from -X- _ O
English -X- _ O
examinations -X- _ O
in -X- _ O
China, -X- _ O
which -X- _ O
are -X- _ O
designed -X- _ O
for -X- _ O
middle -X- _ O
and -X- _ O
high -X- _ O
school -X- _ O
students. -X- _ O
In -X- _ O
RACE, -X- _ B-DatasetName
each -X- _ O
passage -X- _ O
is -X- _ O
associated -X- _ O
with -X- _ O
multiple -X- _ O
questions. -X- _ O
For -X- _ O
every -X- _ O
question, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
select -X- _ O
one -X- _ O
correct -X- _ O
answer -X- _ O
from -X- _ O
four -X- _ O
options. -X- _ O
RACE -X- _ B-DatasetName
has -X- _ O
significantly -X- _ O
longer -X- _ O
context -X- _ O
than -X- _ O
other -X- _ O
popular -X- _ O
reading -X- _ O
comprehension -X- _ O
datasets -X- _ O
and -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
questions -X- _ O
that -X- _ O
requires -X- _ O
reasoning -X- _ O
is -X- _ O
very -X- _ O
large. -X- _ O

BERT-style -X- _ B-MethodName
pretraining -X- _ O
crucially -X- _ O
relies -X- _ O
on -X- _ O
large -X- _ O
quantities -X- _ O
of -X- _ O
text. -X- _ O
demonstrate -X- _ O
that -X- _ O
increasing -X- _ O
data -X- _ O
size -X- _ O
can -X- _ O
result -X- _ O
in -X- _ O
improved -X- _ O
end-task -X- _ O
performance. -X- _ O
Several -X- _ O
efforts -X- _ O
have -X- _ O
trained -X- _ O
on -X- _ O
datasets -X- _ O
larger -X- _ O
and -X- _ O
more -X- _ O
diverse -X- _ O
than -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
(Radford -X- _ O
et -X- _ O
al., -X- _ O
2019;Yang -X- _ O
et -X- _ O
al., -X- _ O
2019;Zellers -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O
Unfortunately, -X- _ O
not -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
additional -X- _ O
datasets -X- _ O
can -X- _ O
be -X- _ O
publicly -X- _ O
released. -X- _ O
For -X- _ O
our -X- _ O
study, -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
gathering -X- _ O
as -X- _ O
much -X- _ O
data -X- _ O
as -X- _ O
possible -X- _ O
for -X- _ O
experimentation, -X- _ O
allowing -X- _ O
us -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
overall -X- _ O
quality -X- _ O
and -X- _ O
quantity -X- _ O
of -X- _ O
data -X- _ O
as -X- _ O
appropriate -X- _ O
for -X- _ O
each -X- _ O
comparison. -X- _ O
We -X- _ O
consider -X- _ O
five -X- _ O
English-language -X- _ O
corpora -X- _ O
of -X- _ O
varying -X- _ O
sizes -X- _ O
and -X- _ O
domains, -X- _ O
totaling -X- _ O
over -X- _ O
160GB -X- _ O
of -X- _ O
uncompressed -X- _ O
text. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
following -X- _ O
text -X- _ O
corpora: -X- _ O
• -X- _ O
BOOKCORPUS -X- _ B-DatasetName
(Zhu -X- _ O
et -X- _ O
al., -X- _ O
2015) -X- _ O
plus -X- _ O
English -X- _ B-DatasetName
WIKIPEDIA. -X- _ I-DatasetName
This -X- _ O
is -X- _ O
the -X- _ O
original -X- _ O
data -X- _ O
used -X- _ O
to -X- _ O
train -X- _ O
BERT. -X- _ B-MethodName
(16GB). -X- _ O
• -X- _ O
CC-NEWS, -X- _ B-DatasetName
which -X- _ O
we -X- _ O
collected -X- _ O
from -X- _ O
the -X- _ O
English -X- _ O
portion -X- _ O
of -X- _ O
the -X- _ O
CommonCrawl -X- _ B-DatasetName
News -X- _ I-DatasetName
dataset -X- _ I-DatasetName
(Nagel, -X- _ O
2016). -X- _ O
The -X- _ O
data -X- _ O
contains -X- _ O
63 -X- _ B-HyperparameterName
million -X- _ I-HyperparameterName
English -X- _ I-HyperparameterName
news -X- _ I-HyperparameterName
articles -X- _ I-HyperparameterName
crawled -X- _ O
between -X- _ O
September -X- _ O
2016 -X- _ O
and -X- _ O
February -X- _ O
2019. -X- _ O
(76GB -X- _ O
after -X- _ O
filtering). -X- _ O
4 -X- _ O
• -X- _ O
OPENWEBTEXT -X- _ B-DatasetName
(Gokaslan -X- _ O
and -X- _ O
Cohen, -X- _ O
2019), -X- _ O
an -X- _ O
open-source -X- _ O
recreation -X- _ O
of -X- _ O
the -X- _ O
WebText -X- _ O
cor-pus -X- _ O
described -X- _ O
in -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
(2019). -X- _ O
The -X- _ O
text -X- _ O
is -X- _ O
web -X- _ O
content -X- _ O
extracted -X- _ O
from -X- _ O
URLs -X- _ O
shared -X- _ O
on -X- _ O
Reddit -X- _ O
with -X- _ O
at -X- _ O
least -X- _ O
three -X- _ O
upvotes. -X- _ O
(38GB). -X- _ O
5 -X- _ O
• -X- _ O
STORIES, -X- _ B-DatasetName
a -X- _ O
dataset -X- _ O
introduced -X- _ O
in -X- _ O
Trinh -X- _ O
and -X- _ O
Le -X- _ O
(2018) -X- _ O
containing -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
CommonCrawl -X- _ B-DatasetName
data -X- _ O
filtered -X- _ O
to -X- _ O
match -X- _ O
the -X- _ O
story-like -X- _ O
style -X- _ O
of -X- _ O
Winograd -X- _ O
schemas. -X- _ O
(31GB). -X- _ O

We -X- _ O
reimplement -X- _ O
BERT -X- _ B-MethodName
in -X- _ O
FAIRSEQ -X- _ O
(Ott -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O
We -X- _ O
primarily -X- _ O
follow -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
optimization -X- _ O
hyperparameters, -X- _ O
given -X- _ O
in -X- _ O
Section -X- _ O
2, -X- _ O
except -X- _ O
for -X- _ O
the -X- _ O
peak -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
and -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
warmup -X- _ I-HyperparameterName
steps, -X- _ I-HyperparameterName
which -X- _ O
are -X- _ O
tuned -X- _ O
separately -X- _ O
for -X- _ O
each -X- _ O
setting. -X- _ O
We -X- _ O
additionally -X- _ O
found -X- _ O
training -X- _ O
to -X- _ O
be -X- _ O
very -X- _ O
sensitive -X- _ O
to -X- _ O
the -X- _ O
Adam -X- _ B-HyperparameterValue
epsilon -X- _ O
term, -X- _ O
and -X- _ O
in -X- _ O
some -X- _ O
cases -X- _ O
we -X- _ O
obtained -X- _ O
better -X- _ O
performance -X- _ O
or -X- _ O
improved -X- _ O
stability -X- _ O
after -X- _ O
tuning -X- _ O
it. -X- _ O
Similarly, -X- _ O
we -X- _ O
found -X- _ O
setting -X- _ O
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
= -X- _ O
0.98 -X- _ B-HyperparameterValue
to -X- _ O
improve -X- _ O
stability -X- _ O
when -X- _ O
training -X- _ O
with -X- _ O
large -X- _ O
batch -X- _ O
sizes. -X- _ O
We -X- _ O
pretrain -X- _ O
with -X- _ O
sequences -X- _ O
of -X- _ O
at -X- _ O
most -X- _ O
T -X- _ O
= -X- _ O
512 -X- _ O
tokens. -X- _ O
Unlike -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
(2019), -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
randomly -X- _ O
inject -X- _ O
short -X- _ O
sequences, -X- _ O
and -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
train -X- _ O
with -X- _ O
a -X- _ O
reduced -X- _ O
sequence -X- _ O
length -X- _ O
for -X- _ O
the -X- _ O
first -X- _ O
90% -X- _ B-MetricValue
of -X- _ O
updates. -X- _ O
We -X- _ O
train -X- _ O
only -X- _ O
with -X- _ O
full-length -X- _ O
sequences. -X- _ O
We -X- _ O
train -X- _ O
with -X- _ O
mixed -X- _ O
precision -X- _ O
floating -X- _ O
point -X- _ O
arithmetic -X- _ O
on -X- _ O
DGX-1 -X- _ O
machines, -X- _ O
each -X- _ O
with -X- _ O
8 -X- _ O
× -X- _ O
32GB -X- _ O
Nvidia -X- _ O
V100 -X- _ O
GPUs -X- _ O
interconnected -X- _ O
by -X- _ O
Infiniband -X- _ O
(Micikevicius -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
describe -X- _ O
the -X- _ O
experimental -X- _ O
setup -X- _ O
for -X- _ O
our -X- _ O
replication -X- _ O
study -X- _ O
of -X- _ O
BERT. -X- _ B-MethodName

BERT -X- _ B-MethodName
is -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
combination -X- _ O
of -X- _ O
BOOKCOR-PUS -X- _ B-DatasetName
(Zhu -X- _ O
et -X- _ O
al., -X- _ O
2015) -X- _ O
plus -X- _ O
English -X- _ B-DatasetName
WIKIPEDIA, -X- _ I-DatasetName
which -X- _ O
totals -X- _ O
16GB -X- _ O
of -X- _ O
uncompressed -X- _ O
text. -X- _ O
3 -X- _ O

BERT -X- _ B-MethodName
is -X- _ O
optimized -X- _ O
with -X- _ O
Adam -X- _ B-HyperparameterValue
(Kingma -X- _ O
and -X- _ O
Ba, -X- _ O
2015) -X- _ O
using -X- _ O
the -X- _ O
following -X- _ O
parameters: -X- _ O
β -X- _ B-HyperparameterName
1 -X- _ I-HyperparameterName
= -X- _ O
0.9, -X- _ B-HyperparameterValue
β -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
= -X- _ O
0.999, -X- _ B-HyperparameterValue
ǫ -X- _ B-HyperparameterName
= -X- _ O
1e-6 -X- _ B-HyperparameterValue
and -X- _ O
L -X- _ B-HyperparameterName
2 -X- _ I-HyperparameterName
weight -X- _ I-HyperparameterName
decay -X- _ I-HyperparameterName
of -X- _ O
0.01. -X- _ B-HyperparameterValue
The -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
warmed -X- _ O
up -X- _ O
over -X- _ O
the -X- _ O
first -X- _ O
10,000 -X- _ O
steps -X- _ O
to -X- _ O
a -X- _ O
peak -X- _ O
value -X- _ O
of -X- _ O
1e-4, -X- _ B-HyperparameterValue
and -X- _ O
then -X- _ O
linearly -X- _ O
decayed. -X- _ O
BERT -X- _ B-MethodName
trains -X- _ O
with -X- _ O
a -X- _ O
dropout -X- _ B-HyperparameterName
of -X- _ O
0.1 -X- _ B-HyperparameterValue
on -X- _ O
all -X- _ O
layers -X- _ O
and -X- _ O
attention -X- _ O
weights, -X- _ O
and -X- _ O
a -X- _ O
GELU -X- _ B-HyperparameterValue
activation -X- _ B-HyperparameterName
function -X- _ I-HyperparameterName
(Hendrycks -X- _ O
and -X- _ O
Gimpel, -X- _ O
2016). -X- _ O
Models -X- _ O
are -X- _ O
pretrained -X- _ O
for -X- _ O
S -X- _ B-HyperparameterName
= -X- _ O
1,000,000 -X- _ B-HyperparameterValue
updates, -X- _ O
with -X- _ O
minibatches -X- _ B-HyperparameterName
containing -X- _ O
B -X- _ O
= -X- _ O
256 -X- _ B-HyperparameterValue
sequences -X- _ O
of -X- _ O
maximum -X- _ O
length -X- _ O
T -X- _ O
= -X- _ O
512 -X- _ O
tokens. -X- _ O

During -X- _ O
pretraining, -X- _ O
BERT -X- _ B-MethodName
uses -X- _ O
two -X- _ O
objectives: -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
and -X- _ O
next -X- _ B-TaskName
sentence -X- _ I-TaskName
prediction. -X- _ I-TaskName
Masked -X- _ O
Language -X- _ O
Model -X- _ O
(MLM) -X- _ O
A -X- _ O
random -X- _ O
sample -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
is -X- _ O
selected -X- _ O
and -X- _ O
replaced -X- _ O
with -X- _ O
the -X- _ O
special -X- _ O
token -X- _ O
[MASK -X- _ O
]. -X- _ O
The -X- _ O
MLM -X- _ O
objective -X- _ O
is -X- _ O
a -X- _ O
cross-entropy -X- _ B-MetricName
loss -X- _ O
on -X- _ O
predicting -X- _ O
the -X- _ O
masked -X- _ O
tokens. -X- _ O
BERT -X- _ B-MethodName
uniformly -X- _ O
selects -X- _ O
15% -X- _ B-MetricValue
of -X- _ O
the -X- _ O
input -X- _ O
tokens -X- _ O
for -X- _ O
possible -X- _ O
replacement. -X- _ O
Of -X- _ O
the -X- _ O
selected -X- _ O
tokens, -X- _ O
80% -X- _ B-MetricValue
are -X- _ O
replaced -X- _ O
with -X- _ O
[MASK -X- _ O
], -X- _ O
10% -X- _ B-MetricValue
are -X- _ O
left -X- _ O
unchanged, -X- _ O
and -X- _ O
10% -X- _ B-MetricValue
are -X- _ O
replaced -X- _ O
by -X- _ O
a -X- _ O
randomly -X- _ O
selected -X- _ O
vocabulary -X- _ O
token. -X- _ O
In -X- _ O
the -X- _ O
original -X- _ O
implementation, -X- _ O
random -X- _ O
masking -X- _ O
and -X- _ O
replacement -X- _ O
is -X- _ O
performed -X- _ O
once -X- _ O
in -X- _ O
the -X- _ O
beginning -X- _ O
and -X- _ O
saved -X- _ O
for -X- _ O
the -X- _ O
duration -X- _ O
of -X- _ O
training, -X- _ O
although -X- _ O
in -X- _ O
practice, -X- _ O
data -X- _ O
is -X- _ O
duplicated -X- _ O
so -X- _ O
the -X- _ O
mask -X- _ O
is -X- _ O
not -X- _ O
always -X- _ O
the -X- _ O
same -X- _ O
for -X- _ O
every -X- _ O
training -X- _ O
sentence -X- _ O
(see -X- _ O
Section -X- _ O
4.1). -X- _ O
Next -X- _ B-TaskName
Sentence -X- _ I-TaskName
Prediction -X- _ I-TaskName
(NSP) -X- _ O
NSP -X- _ B-TaskName
is -X- _ O
a -X- _ O
binary -X- _ O
classification -X- _ O
loss -X- _ O
for -X- _ O
predicting -X- _ O
whether -X- _ O
two -X- _ O
segments -X- _ O
follow -X- _ O
each -X- _ O
other -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
text. -X- _ O
Positive -X- _ O
examples -X- _ O
are -X- _ O
created -X- _ O
by -X- _ O
taking -X- _ O
consecutive -X- _ O
sentences -X- _ O
from -X- _ O
the -X- _ O
text -X- _ O
corpus. -X- _ O
Negative -X- _ O
examples -X- _ O
are -X- _ O
created -X- _ O
by -X- _ O
pairing -X- _ O
segments -X- _ O
from -X- _ O
different -X- _ O
documents. -X- _ O
Positive -X- _ O
and -X- _ O
negative -X- _ O
examples -X- _ O
are -X- _ O
sampled -X- _ O
with -X- _ O
equal -X- _ O
probability. -X- _ O
The -X- _ O
NSP -X- _ B-TaskName
objective -X- _ O
was -X- _ O
designed -X- _ O
to -X- _ O
improve -X- _ O
performance -X- _ O
on -X- _ O
downstream -X- _ O
tasks, -X- _ O
such -X- _ O
as -X- _ O
Natural -X- _ O
Language -X- _ O
Inference -X- _ O
(Bowman -X- _ O
et -X- _ O
al., -X- _ O
2015), -X- _ O
which -X- _ O
require -X- _ O
reasoning -X- _ O
about -X- _ O
the -X- _ O
relationships -X- _ O
between -X- _ O
pairs -X- _ O
of -X- _ O
sentences. -X- _ O

BERT -X- _ B-MethodName
uses -X- _ O
the -X- _ O
now -X- _ O
ubiquitous -X- _ O
transformer -X- _ O
architecture -X- _ O
(Vaswani -X- _ O
et -X- _ O
al., -X- _ O
2017), -X- _ O
which -X- _ O
we -X- _ O
will -X- _ O
not -X- _ O
review -X- _ O
in -X- _ O
detail. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
transformer -X- _ O
architecture -X- _ O
with -X- _ O
L -X- _ O
layers. -X- _ O
Each -X- _ O
block -X- _ O
uses -X- _ O
A -X- _ O
self-attention -X- _ O
heads -X- _ O
and -X- _ O
hidden -X- _ O
dimension -X- _ O
H. -X- _ O

BERT -X- _ B-MethodName
takes -X- _ O
as -X- _ O
input -X- _ O
a -X- _ O
concatenation -X- _ O
of -X- _ O
two -X- _ O
segments -X- _ O
(sequences -X- _ O
of -X- _ O
tokens), -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
x -X- _ O
N -X- _ O
and -X- _ O
y -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
y -X- _ O
M -X- _ O
. -X- _ O
Segments -X- _ O
usually -X- _ O
consist -X- _ O
of -X- _ O
more -X- _ O
than -X- _ O
one -X- _ O
natural -X- _ O
sentence. -X- _ O
The -X- _ O
two -X- _ O
segments -X- _ O
are -X- _ O
presented -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
input -X- _ O
sequence -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
special -X- _ O
tokens -X- _ O
delimiting -X- _ O
them: -X- _ O
[CLS -X- _ O
], -X- _ O
x -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
x -X- _ O
N -X- _ O
, -X- _ O
[SEP -X- _ O
], -X- _ O
y -X- _ O
1 -X- _ O
, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
y -X- _ O
M -X- _ O
, -X- _ O
[EOS -X- _ O
]. -X- _ O
M -X- _ O
and -X- _ O
N -X- _ O
are -X- _ O
constrained -X- _ O
such -X- _ O
that -X- _ O
M -X- _ O
+ -X- _ O
N -X- _ O
< -X- _ O
T -X- _ O
, -X- _ O
where -X- _ O
T -X- _ O
is -X- _ O
a -X- _ O
parameter -X- _ O
that -X- _ O
controls -X- _ O
the -X- _ O
maximum -X- _ O
sequence -X- _ O
length -X- _ O
during -X- _ O
training. -X- _ O
The -X- _ O
model -X- _ O
is -X- _ O
first -X- _ O
pretrained -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
unlabeled -X- _ O
text -X- _ O
corpus -X- _ O
and -X- _ O
subsequently -X- _ O
finetuned -X- _ O
using -X- _ O
end-task -X- _ O
labeled -X- _ O
data. -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
give -X- _ O
a -X- _ O
brief -X- _ O
overview -X- _ O
of -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
pretraining -X- _ O
approach -X- _ O
and -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
choices -X- _ O
that -X- _ O
we -X- _ O
will -X- _ O
examine -X- _ O
experimentally -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
section. -X- _ O

Self-training -X- _ O
methods -X- _ O
such -X- _ O
as -X- _ O
ELMo -X- _ B-MethodName
(Peters -X- _ O
et -X- _ O
al., -X- _ O
2018), -X- _ O
GPT -X- _ B-MethodName
(Radford -X- _ O
et -X- _ O
al., -X- _ O
2018), -X- _ O
BERT -X- _ B-MethodName
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
XLM -X- _ B-MethodName
(Lample -X- _ O
and -X- _ O
Conneau, -X- _ O
2019), -X- _ O
and -X- _ O
XLNet -X- _ B-MethodName
(Yang -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
have -X- _ O
brought -X- _ O
significant -X- _ O
performance -X- _ O
gains, -X- _ O
but -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
challenging -X- _ O
to -X- _ O
determine -X- _ O
which -X- _ O
aspects -X- _ O
of -X- _ O
the -X- _ O
methods -X- _ O
contribute -X- _ O
the -X- _ O
most. -X- _ O
Training -X- _ O
is -X- _ O
computationally -X- _ O
expensive, -X- _ O
limiting -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
tuning -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
done, -X- _ O
and -X- _ O
is -X- _ O
often -X- _ O
done -X- _ O
with -X- _ O
private -X- _ O
training -X- _ O
data -X- _ O
of -X- _ O
varying -X- _ O
sizes, -X- _ O
limiting -X- _ O
our -X- _ O
ability -X- _ O
to -X- _ O
measure -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
the -X- _ O
modeling -X- _ O
advances. -X- _ O
We -X- _ O
present -X- _ O
a -X- _ O
replication -X- _ O
study -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
pretraining -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
which -X- _ O
includes -X- _ O
a -X- _ O
careful -X- _ O
evaluation -X- _ O
of -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
hyperparmeter -X- _ O
tuning -X- _ O
and -X- _ O
training -X- _ O
set -X- _ O
size. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
was -X- _ O
significantly -X- _ O
undertrained -X- _ O
and -X- _ O
propose -X- _ O
an -X- _ O
improved -X- _ O
recipe -X- _ O
for -X- _ O
training -X- _ O
BERT -X- _ B-MethodName
models, -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
RoBERTa, -X- _ B-MethodName
that -X- _ O
can -X- _ O
match -X- _ O
or -X- _ O
exceed -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
post-BERT -X- _ O
methods. -X- _ O
Our -X- _ O
modifications -X- _ O
are -X- _ O
simple, -X- _ O
they -X- _ O
include: -X- _ O
(1) -X- _ O
training -X- _ O
the -X- _ O
model -X- _ O
longer, -X- _ O
with -X- _ O
bigger -X- _ O
batches, -X- _ O
over -X- _ O
more -X- _ O
data; -X- _ O
(2) -X- _ O
removing -X- _ O
the -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
objective; -X- _ O
(3) -X- _ O
training -X- _ O
on -X- _ O
longer -X- _ O
sequences; -X- _ O
and -X- _ O
(4) -X- _ O
dynamically -X- _ O
changing -X- _ O
the -X- _ O
masking -X- _ O
pattern -X- _ O
applied -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
data. -X- _ O
We -X- _ O
also -X- _ O
collect -X- _ O
a -X- _ O
large -X- _ O
new -X- _ O
dataset -X- _ O
(CC-NEWS) -X- _ B-DatasetName
of -X- _ O
comparable -X- _ O
size -X- _ O
to -X- _ O
other -X- _ O
privately -X- _ O
used -X- _ O
datasets, -X- _ O
to -X- _ O
better -X- _ O
control -X- _ O
for -X- _ O
training -X- _ O
set -X- _ O
size -X- _ O
effects. -X- _ O
When -X- _ O
controlling -X- _ O
for -X- _ O
training -X- _ O
data, -X- _ O
our -X- _ O
improved -X- _ O
training -X- _ O
procedure -X- _ O
improves -X- _ O
upon -X- _ O
the -X- _ O
published -X- _ O
BERT -X- _ B-MethodName
results -X- _ O
on -X- _ O
both -X- _ O
GLUE -X- _ B-DatasetName
and -X- _ O
SQuAD. -X- _ B-DatasetName
When -X- _ O
trained -X- _ O
for -X- _ O
longer -X- _ O
over -X- _ O
additional -X- _ O
data, -X- _ O
our -X- _ O
model -X- _ O
achieves -X- _ O
a -X- _ O
score -X- _ O
of -X- _ O
88.5 -X- _ B-MetricValue
on -X- _ O
the -X- _ O
public -X- _ O
GLUE -X- _ B-DatasetName
leaderboard, -X- _ O
matching -X- _ O
the -X- _ O
88.4 -X- _ B-MetricValue
reported -X- _ O
by -X- _ O
Yang -X- _ O
et -X- _ O
al. -X- _ O
(2019). -X- _ O
Our -X- _ O
model -X- _ O
establishes -X- _ O
a -X- _ O
new -X- _ O
state-of-the-art -X- _ O
on -X- _ O
4/9 -X- _ O
of -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
tasks: -X- _ O
MNLI, -X- _ B-DatasetName
QNLI, -X- _ B-DatasetName
RTE -X- _ B-DatasetName
and -X- _ O
STS-B. -X- _ B-DatasetName
We -X- _ O
also -X- _ O
match -X- _ O
state-of-the-art -X- _ O
results -X- _ O
on -X- _ O
SQuAD -X- _ B-DatasetName
and -X- _ O
RACE. -X- _ B-DatasetName
Overall, -X- _ O
we -X- _ O
re-establish -X- _ O
that -X- _ O
BERT's -X- _ B-MethodName
masked -X- _ O
language -X- _ O
model -X- _ O
training -X- _ O
objective -X- _ O
is -X- _ O
competitive -X- _ O
with -X- _ O
other -X- _ O
recently -X- _ O
proposed -X- _ O
training -X- _ O
objectives -X- _ O
such -X- _ O
as -X- _ O
perturbed -X- _ O
autoregressive -X- _ O
language -X- _ O
modeling -X- _ O
(Yang -X- _ O
et -X- _ O
al., -X- _ O
2019). -X- _ O
2 -X- _ O
In -X- _ O
summary, -X- _ O
the -X- _ O
contributions -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
are: -X- _ O
(1) -X- _ O
We -X- _ O
present -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
important -X- _ O
BERT -X- _ B-MethodName
design -X- _ O
choices -X- _ O
and -X- _ O
training -X- _ O
strategies -X- _ O
and -X- _ O
introduce -X- _ O
alternatives -X- _ O
that -X- _ O
lead -X- _ O
to -X- _ O
better -X- _ O
downstream -X- _ O
task -X- _ O
performance; -X- _ O
(2) -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
novel -X- _ O
dataset, -X- _ O
CC-NEWS, -X- _ B-DatasetName
and -X- _ O
confirm -X- _ O
that -X- _ O
using -X- _ O
more -X- _ O
data -X- _ O
for -X- _ O
pretraining -X- _ O
further -X- _ O
improves -X- _ O
performance -X- _ O
on -X- _ O
downstream -X- _ O
tasks; -X- _ O
(3) -X- _ O
Our -X- _ O
training -X- _ O
improvements -X- _ O
show -X- _ O
that -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
pretraining, -X- _ O
under -X- _ O
the -X- _ O
right -X- _ O
design -X- _ O
choices, -X- _ O
is -X- _ O
competitive -X- _ O
with -X- _ O
all -X- _ O
other -X- _ O
recently -X- _ O
published -X- _ O
methods. -X- _ O
We -X- _ O
release -X- _ O
our -X- _ O
model, -X- _ O
pretraining -X- _ O
and -X- _ O
fine-tuning -X- _ O
code -X- _ O
implemented -X- _ O
in -X- _ O
PyTorch -X- _ O
(Paszke -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O

Language -X- _ O
model -X- _ O
pretraining -X- _ O
has -X- _ O
led -X- _ O
to -X- _ O
significant -X- _ O
performance -X- _ O
gains -X- _ O
but -X- _ O
careful -X- _ O
comparison -X- _ O
between -X- _ O
different -X- _ O
approaches -X- _ O
is -X- _ O
challenging. -X- _ O
Training -X- _ O
is -X- _ O
computationally -X- _ O
expensive, -X- _ O
often -X- _ O
done -X- _ O
on -X- _ O
private -X- _ O
datasets -X- _ O
of -X- _ O
different -X- _ O
sizes, -X- _ O
and, -X- _ O
as -X- _ O
we -X- _ O
will -X- _ O
show, -X- _ O
hyperparameter -X- _ O
choices -X- _ O
have -X- _ O
significant -X- _ O
impact -X- _ O
on -X- _ O
the -X- _ O
final -X- _ O
results. -X- _ O
We -X- _ O
present -X- _ O
a -X- _ O
replication -X- _ O
study -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
pretraining -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
that -X- _ O
carefully -X- _ O
measures -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
many -X- _ O
key -X- _ O
hyperparameters -X- _ O
and -X- _ O
training -X- _ O
data -X- _ O
size. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
was -X- _ O
significantly -X- _ O
undertrained, -X- _ O
and -X- _ O
can -X- _ O
match -X- _ O
or -X- _ O
exceed -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
every -X- _ O
model -X- _ O
published -X- _ O
after -X- _ O
it. -X- _ O
Our -X- _ O
best -X- _ O
model -X- _ O
achieves -X- _ O
state-of-the-art -X- _ O
results -X- _ O
on -X- _ O
GLUE, -X- _ B-DatasetName
RACE -X- _ B-DatasetName
and -X- _ O
SQuAD. -X- _ B-DatasetName
These -X- _ O
results -X- _ O
highlight -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
previously -X- _ O
overlooked -X- _ O
design -X- _ O
choices, -X- _ O
and -X- _ O
raise -X- _ O
questions -X- _ O
about -X- _ O
the -X- _ O
source -X- _ O
of -X- _ O
recently -X- _ O
reported -X- _ O
improvements. -X- _ O
We -X- _ O
release -X- _ O
our -X- _ O
models -X- _ O
and -X- _ O
code. -X- _ O
1 -X- _ O

In -X- _ O
Table -X- _ O
8 -X- _ O
we -X- _ O
present -X- _ O
the -X- _ O
full -X- _ O
set -X- _ O
of -X- _ O
development -X- _ O
set -X- _ O
results -X- _ O
for -X- _ O
RoBERTa. -X- _ B-MethodName
We -X- _ O
present -X- _ O
results -X- _ O
for -X- _ O
a -X- _ O
LARGE -X- _ O
configuration -X- _ O
that -X- _ O
follows -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
a -X- _ O
BASE -X- _ O
configuration -X- _ O
that -X- _ O
follows -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
. -X- _ O

Appendix -X- _ O
for -X- _ O
"RoBERTa: -X- _ B-MethodName
A -X- _ O
Robustly -X- _ O
Optimized -X- _ O
BERT -X- _ O
Pretraining -X- _ O
Approach" -X- _ O


-DOCSTART- -X- O
According -X- _ O
to -X- _ O
the -X- _ O
comparison -X- _ O
above, -X- _ O
AR -X- _ O
language -X- _ O
modeling -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
possess -X- _ O
their -X- _ O
unique -X- _ O
advantages -X- _ O
over -X- _ O
the -X- _ O
other. -X- _ O
A -X- _ O
natural -X- _ O
question -X- _ O
to -X- _ O
ask -X- _ O
is -X- _ O
whether -X- _ O
there -X- _ O
exists -X- _ O
a -X- _ O
pretraining -X- _ O
objective -X- _ O
that -X- _ O
brings -X- _ O
the -X- _ O
advantages -X- _ O
of -X- _ O
both -X- _ O
while -X- _ O
avoiding -X- _ O
their -X- _ O
weaknesses. -X- _ O
Borrowing -X- _ O
ideas -X- _ O
from -X- _ O
orderless -X- _ O
NADE -X- _ O
, -X- _ O
we -X- _ O
propose -X- _ O
the -X- _ O
permutation -X- _ B-TaskName
language -X- _ I-TaskName
modeling -X- _ I-TaskName
objective -X- _ O
that -X- _ O
not -X- _ O
only -X- _ O
retains -X- _ O
the -X- _ O
benefits -X- _ O
of -X- _ O
AR -X- _ O
models -X- _ O
but -X- _ O
also -X- _ O
allows -X- _ O
models -X- _ O
to -X- _ O
capture -X- _ O
bidirectional -X- _ O
contexts. -X- _ O
Specifically, -X- _ O
for -X- _ O
a -X- _ O
sequence -X- _ O
x -X- _ O
of -X- _ O
length -X- _ O
T -X- _ O
, -X- _ O
there -X- _ O
are -X- _ O
T -X- _ O
! -X- _ O
different -X- _ O
orders -X- _ O
to -X- _ O
perform -X- _ O
a -X- _ O
valid -X- _ O
autoregressive -X- _ O
factorization. -X- _ O
Intuitively, -X- _ O
if -X- _ O
model -X- _ O
parameters -X- _ O
are -X- _ O
shared -X- _ O
across -X- _ O
all -X- _ O
factorization -X- _ O
orders, -X- _ O
in -X- _ O
expectation, -X- _ O
the -X- _ O
model -X- _ O
will -X- _ O
learn -X- _ O
to -X- _ O
gather -X- _ O
information -X- _ O
from -X- _ O
all -X- _ O
positions -X- _ O
on -X- _ O
both -X- _ O
sides. -X- _ O
To -X- _ O
formalize -X- _ O
the -X- _ O
idea, -X- _ O
let -X- _ O
Z -X- _ O
T -X- _ O
be -X- _ O
the -X- _ O
set -X- _ O
of -X- _ O
all -X- _ O
possible -X- _ O
permutations -X- _ O
of -X- _ O
the -X- _ O
length-T -X- _ O
index -X- _ O
sequence -X- _ O
[1, -X- _ O
2, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
T -X- _ O
]. -X- _ O
We -X- _ O
use -X- _ O
z -X- _ O
t -X- _ O
and -X- _ O
z -X- _ O
<t -X- _ O
to -X- _ O
denote -X- _ O
the -X- _ O
t-th -X- _ O
element -X- _ O
and -X- _ O
the -X- _ O
first -X- _ O
t−1 -X- _ O
elements -X- _ O
of -X- _ O
a -X- _ O
permutation -X- _ O
z -X- _ O
∈ -X- _ O
Z -X- _ O
T -X- _ O
. -X- _ O
Then, -X- _ O
our -X- _ O
proposed -X- _ O
permutation -X- _ B-TaskName
language -X- _ I-TaskName
modeling -X- _ I-TaskName
objective -X- _ O
can -X- _ O
be -X- _ O
expressed -X- _ O
as -X- _ O
follows: -X- _ O
max -X- _ O
θ -X- _ O
E -X- _ O
z∼Z -X- _ O
T -X- _ O
T -X- _ O
t=1 -X- _ O
log -X- _ O
p -X- _ O
θ -X- _ O
(x -X- _ O
zt -X- _ O
| -X- _ O
x -X- _ O
z<t -X- _ O
) -X- _ O
.(3) -X- _ O
Essentially, -X- _ O
for -X- _ O
a -X- _ O
text -X- _ O
sequence -X- _ O
x, -X- _ O
we -X- _ O
sample -X- _ O
a -X- _ O
factorization -X- _ O
order -X- _ O
z -X- _ O
at -X- _ O
a -X- _ O
time -X- _ O
and -X- _ O
decompose -X- _ O
the -X- _ O
likelihood -X- _ O
p -X- _ O
θ -X- _ O
(x) -X- _ O
according -X- _ O
to -X- _ O
factorization -X- _ O
order. -X- _ O
Since -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
parameter -X- _ O
θ -X- _ O
is -X- _ O
shared -X- _ O
across -X- _ O
all -X- _ O
factorization -X- _ O
orders -X- _ O
during -X- _ O
training, -X- _ O
in -X- _ O
expectation, -X- _ O
x -X- _ O
t -X- _ O
has -X- _ O
seen -X- _ O
every -X- _ O
possible -X- _ O
element -X- _ O
x -X- _ O
i -X- _ O
= -X- _ O
x -X- _ O
t -X- _ O
in -X- _ O
the -X- _ O
sequence, -X- _ O
hence -X- _ O
being -X- _ O
able -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
bidirectional -X- _ O
context. -X- _ O
Moreover, -X- _ O
as -X- _ O
this -X- _ O
objective -X- _ O
fits -X- _ O
into -X- _ O
the -X- _ O
AR -X- _ O
framework, -X- _ O
it -X- _ O
naturally -X- _ O
avoids -X- _ O
the -X- _ O
independence -X- _ O
assumption -X- _ O
and -X- _ O
the -X- _ O
pretrain-finetune -X- _ O
discrepancy -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
2.1. -X- _ O

The -X- _ O
hyperparameters -X- _ O
used -X- _ O
for -X- _ O
finetuning -X- _ O
XLNet -X- _ B-MethodName
on -X- _ O
various -X- _ O
tasks -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
8. -X- _ O
"Layer-wise -X- _ B-HyperparameterName
decay" -X- _ I-HyperparameterName
means -X- _ O
exponentially -X- _ O
decaying -X- _ O
the -X- _ O
learning -X- _ O
rates -X- _ O
of -X- _ O
individual -X- _ O
layers -X- _ O
in -X- _ O
a -X- _ O
top-down -X- _ O
manner. -X- _ O
For -X- _ O
example, -X- _ O
suppose -X- _ O
the -X- _ O
24-th -X- _ O
layer -X- _ O
uses -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
l, -X- _ B-HyperparameterName
and -X- _ O
the -X- _ O
Layer-wise -X- _ B-HyperparameterName
decay -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
α, -X- _ B-HyperparameterName
then -X- _ O
the -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
layer -X- _ O
m -X- _ O
is -X- _ O
lα -X- _ B-HyperparameterName
24−m -X- _ O
. -X- _ O
A.5 -X- _ O
Discussion -X- _ O
and -X- _ O
Analysis -X- _ O

To -X- _ O
prove -X- _ O
a -X- _ O
general -X- _ O
point -X- _ O
beyond -X- _ O
one -X- _ O
example, -X- _ O
we -X- _ O
now -X- _ O
turn -X- _ O
to -X- _ O
more -X- _ O
formal -X- _ O
expressions. -X- _ O
Inspired -X- _ O
by -X- _ O
previous -X- _ O
work -X- _ O
, -X- _ O
given -X- _ O
a -X- _ O
sequence -X- _ O
x -X- _ O
= -X- _ O
[x -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
x -X- _ O
T -X- _ O
], -X- _ O
we -X- _ O
define -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
target-context -X- _ O
pairs -X- _ O
of -X- _ O
interest, -X- _ O
I -X- _ O
= -X- _ O
{(x, -X- _ O
U)}, -X- _ O
where -X- _ O
U -X- _ O
is -X- _ O
a -X- _ O
set -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
x -X- _ O
that -X- _ O
form -X- _ O
a -X- _ O
context -X- _ O
of -X- _ O
x. -X- _ O
Intuitively, -X- _ O
we -X- _ O
want -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
dependency -X- _ O
of -X- _ O
x -X- _ O
on -X- _ O
U -X- _ O
through -X- _ O
a -X- _ O
pretraining -X- _ O
loss -X- _ O
term -X- _ O
log -X- _ O
p(x -X- _ O
| -X- _ O
U). -X- _ O
For -X- _ O
example, -X- _ O
given -X- _ O
the -X- _ O
above -X- _ O
sentence, -X- _ O
the -X- _ O
pairs -X- _ O
of -X- _ O
interest -X- _ O
I -X- _ O
could -X- _ O
be -X- _ O
instantiated -X- _ O
as: -X- _ O
I -X- _ O
= -X- _ O
x -X- _ O
= -X- _ O
York, -X- _ O
U -X- _ O
= -X- _ O
{New} -X- _ O
, -X- _ O
x -X- _ O
= -X- _ O
York, -X- _ O
U -X- _ O
= -X- _ O
{city} -X- _ O
, -X- _ O
x -X- _ O
= -X- _ O
York, -X- _ O
U -X- _ O
= -X- _ O
{New, -X- _ O
city} -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
. -X- _ O
Note -X- _ O
that -X- _ O
I -X- _ O
is -X- _ O
merely -X- _ O
a -X- _ O
virtual -X- _ O
notion -X- _ O
without -X- _ O
unique -X- _ O
ground -X- _ O
truth, -X- _ O
and -X- _ O
our -X- _ O
analysis -X- _ O
will -X- _ O
hold -X- _ O
regardless -X- _ O
of -X- _ O
how -X- _ O
I -X- _ O
is -X- _ O
instantiated. -X- _ O
Given -X- _ O
the -X- _ O
definition, -X- _ O
let's -X- _ O
consider -X- _ O
two -X- _ O
cases: -X- _ O
• -X- _ O
If -X- _ O
U -X- _ O
⊆ -X- _ O
N -X- _ O
, -X- _ O
the -X- _ O
dependency -X- _ O
(x, -X- _ O
U) -X- _ O
is -X- _ O
covered -X- _ O
by -X- _ O
both -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
XLNet. -X- _ B-MethodName
• -X- _ O
If -X- _ O
U -X- _ O
⊆ -X- _ O
N -X- _ O
∪ -X- _ O
T -X- _ O
<x -X- _ O
and -X- _ O
U -X- _ O
∩ -X- _ O
T -X- _ O
<x -X- _ O
= -X- _ O
∅, -X- _ O
the -X- _ O
dependency -X- _ O
can -X- _ O
only -X- _ O
be -X- _ O
covered -X- _ O
by -X- _ O
XLNet -X- _ B-MethodName
but -X- _ O
not -X- _ O
BERT. -X- _ B-MethodName
As -X- _ O
a -X- _ O
result, -X- _ O
XLNet -X- _ B-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
cover -X- _ O
more -X- _ O
dependencies -X- _ O
than -X- _ O
BERT. -X- _ B-MethodName
In -X- _ O
other -X- _ O
words, -X- _ O
the -X- _ O
XLNet -X- _ B-MethodName
objective -X- _ O
contains -X- _ O
more -X- _ O
effective -X- _ O
training -X- _ O
signals, -X- _ O
which -X- _ O
empirically -X- _ O
leads -X- _ O
to -X- _ O
better -X- _ O
performance -X- _ O
in -X- _ O
Section -X- _ O
3. -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
provide -X- _ O
a -X- _ O
detailed -X- _ O
visualization -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
permutation -X- _ O
language -X- _ O
modeling -X- _ O
objective, -X- _ O
including -X- _ O
the -X- _ O
mechanism -X- _ O
of -X- _ O
reusing -X- _ O
memory -X- _ O
(aka -X- _ O
the -X- _ O
recurrence -X- _ O
mechanism), -X- _ O
how -X- _ O
we -X- _ O
use -X- _ O
attention -X- _ O
masks -X- _ O
to -X- _ O
permute -X- _ O
the -X- _ O
factorization -X- _ O
order, -X- _ O
and -X- _ O
the -X- _ O
difference -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
attention -X- _ O
streams. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
5 -X- _ O
and -X- _ O
6, -X- _ O
given -X- _ O
the -X- _ O
current -X- _ O
position -X- _ O
z -X- _ O
t -X- _ O
, -X- _ O
the -X- _ O
attention -X- _ O
mask -X- _ O
is -X- _ O
decided -X- _ O
by -X- _ O
the -X- _ O
permutation -X- _ O
(or -X- _ O
factorization -X- _ O
order) -X- _ O
z -X- _ O
such -X- _ O
that -X- _ O
only -X- _ O
tokens -X- _ O
the -X- _ O
occur -X- _ O
before -X- _ O
z -X- _ O
t -X- _ O
in -X- _ O
the -X- _ O
permutation -X- _ O
can -X- _ O
be -X- _ O
attended; -X- _ O
i.e., -X- _ O
positions -X- _ O
z -X- _ O
i -X- _ O
with -X- _ O
i -X- _ O
< -X- _ O
t. -X- _ O
Moreover, -X- _ O
comparing -X- _ O
Figure -X- _ O
5 -X- _ O
and -X- _ O
6, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
how -X- _ O
the -X- _ O
query -X- _ O
stream -X- _ O
and -X- _ O
the -X- _ O
content -X- _ O
stream -X- _ O
work -X- _ O
differently -X- _ O
with -X- _ O
a -X- _ O
specific -X- _ O
permutation -X- _ O
through -X- _ O
attention -X- _ O
masks. -X- _ O
The -X- _ O
main -X- _ O
difference -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
query -X- _ O
stream -X- _ O
cannot -X- _ O
do -X- _ O
self-attention -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
have -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
token -X- _ O
at -X- _ O
the -X- _ O
position, -X- _ O
while -X- _ O
the -X- _ O
content -X- _ O
stream -X- _ O
performs -X- _ O
normal -X- _ O
self-attention. -X- _ O
mem -X- _ O
(+) -X- _ O
mem -X- _ O
(%) -X- _ O
x -X- _ O
mem -X- _ O
(+) -X- _ O
mem -X- _ O
(%) -X- _ O
x -X- _ O
mem -X- _ O
(+) -X- _ O
mem -X- _ O
(%) -X- _ O
x -X- _ O
mem -X- _ O
(+) -X- _ O
mem -X- _ O
(%) -X- _ O
x -X- _ O
Note -X- _ O
that -X- _ O
if -X- _ O
we -X- _ O
ignore -X- _ O
the -X- _ O
query -X- _ O
representation, -X- _ O
the -X- _ O
computation -X- _ O
in -X- _ O
this -X- _ O
figure -X- _ O
is -X- _ O
simply -X- _ O
the -X- _ O
standard -X- _ O
self-attention, -X- _ O
though -X- _ O
with -X- _ O
a -X- _ O
particular -X- _ O
attention -X- _ O
mask. -X- _ O
mem -X- _ O
(+) -X- _ O
mem -X- _ O
(%) -X- _ O
x -X- _ O
w -X- _ O
w -X- _ O
w -X- _ O
w -X- _ O
mem -X- _ O
(+) -X- _ O
mem -X- _ O
(%) -X- _ O
x -X- _ O
mem -X- _ O
(+) -X- _ O
mem -X- _ O
(%) -X- _ O
x -X- _ O
mem -X- _ O
(+) -X- _ O
mem -X- _ O
(%) -X- _ O
x -X- _ O

Factorization -X- _ O
order: -X- _ O
3 -X- _ O
à -X- _ O
2 -X- _ O
à -X- _ O
4 -X- _ O
à -X- _ O
1 -X- _ O
mem -X- _ O
(+) -X- _ O
mem -X- _ O
(+) -X- _ O
x -X- _ O
" -X- _ O
x -X- _ O
# -X- _ O
x -X- _ O
$ -X- _ O
x -X- _ O
% -X- _ O
h -X- _ O
" -X- _ O
Factorization -X- _ O
order: -X- _ O
4 -X- _ O
à -X- _ O
3 -X- _ O
à -X- _ O
1 -X- _ O
à -X- _ O
2 -X- _ O
mem -X- _ O
(+) -X- _ O
mem -X- _ O
(#) -X- _ O
mem -X- _ O
(#) -X- _ O
mem -X- _ O
(#) -X- _ O
mem -X- _ O
(+) -X- _ O
x -X- _ O
% -X- _ O
x -X- _ O
% -X- _ O
x -X- _ O
% -X- _ O
x -X- _ O
% -X- _ O
Figure -X- _ O
4: -X- _ O
Illustration -X- _ O
of -X- _ O
the -X- _ O
permutation -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
for -X- _ O
predicting -X- _ O
x -X- _ O
3 -X- _ O
given -X- _ O
the -X- _ O
same -X- _ O
input -X- _ O
sequence -X- _ O
x -X- _ O
but -X- _ O
with -X- _ O
different -X- _ O
factorization -X- _ O
orders. -X- _ O

The -X- _ O
authors -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
thank -X- _ O
Qizhe -X- _ O
Xie -X- _ O
and -X- _ O
Adams -X- _ O
Wei -X- _ O
Yu -X- _ O
for -X- _ O
providing -X- _ O
useful -X- _ O
feedback -X- _ O
on -X- _ O
the -X- _ O
project, -X- _ O
Jamie -X- _ O
Callan -X- _ O
for -X- _ O
providing -X- _ O
the -X- _ O
ClueWeb -X- _ O
dataset, -X- _ O
Youlong -X- _ O
Cheng, -X- _ O
Yanping -X- _ O
Huang -X- _ O
and -X- _ O
Shibo -X- _ O
Wang -X- _ O
for -X- _ O
providing -X- _ O
ideas -X- _ O
to -X- _ O
improve -X- _ O
our -X- _ O
TPU -X- _ O
implementation, -X- _ O
Chenyan -X- _ O
Xiong -X- _ O
and -X- _ O
Zhuyun -X- _ O
Dai -X- _ O
for -X- _ O
clarifying -X- _ O
the -X- _ O
setting -X- _ O
of -X- _ O
the -X- _ O
document -X- _ O
ranking -X- _ O
task. -X- _ O
ZY -X- _ O
and -X- _ O
RS -X- _ O
were -X- _ O
supported -X- _ O
by -X- _ O
the -X- _ O
Office -X- _ O
of -X- _ O
Naval -X- _ O
Research -X- _ O
grant -X- _ O
N000141812861, -X- _ O
the -X- _ O
National -X- _ O
Science -X- _ O
Foundation -X- _ O
(NSF) -X- _ O
grant -X- _ O
IIS1763562, -X- _ O
the -X- _ O
Nvidia -X- _ O
fellowship, -X- _ O
and -X- _ O
the -X- _ O
Siebel -X- _ O
scholarship. -X- _ O
ZD -X- _ O
and -X- _ O
YY -X- _ O
were -X- _ O
supported -X- _ O
in -X- _ O
part -X- _ O
by -X- _ O
NSF -X- _ O
under -X- _ O
the -X- _ O
grant -X- _ O
IIS-1546329 -X- _ O
and -X- _ O
by -X- _ O
the -X- _ O
DOE-Office -X- _ O
of -X- _ O
Science -X- _ O
under -X- _ O
the -X- _ O
grant -X- _ O
ASCR -X- _ O
#KJ040201. -X- _ O

We -X- _ O
compare -X- _ O
the -X- _ O
attention -X- _ O
pattern -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
XLNet -X- _ B-MethodName
without -X- _ O
finetuning. -X- _ O
Firstly, -X- _ O
we -X- _ O
found -X- _ O
4 -X- _ O
typical -X- _ O
patterns -X- _ O
shared -X- _ O
by -X- _ O
both, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Fig. -X- _ O
2. -X- _ O
More -X- _ O
interestingly, -X- _ O
in -X- _ O
Fig. -X- _ O
3, -X- _ O
we -X- _ O
present -X- _ O
3 -X- _ O
patterns -X- _ O
that -X- _ O
only -X- _ O
appear -X- _ O
in -X- _ O
XLNet -X- _ B-MethodName
but -X- _ O
not -X- _ O
BERT: -X- _ B-MethodName
(a) -X- _ O
The -X- _ O
self-exclusion -X- _ O
pattern -X- _ O
attends -X- _ O
to -X- _ O
all -X- _ O
other -X- _ O
tokens -X- _ O
but -X- _ O
itself, -X- _ O
probably -X- _ O
offering -X- _ O
a -X- _ O
fast -X- _ O
way -X- _ O
to -X- _ O
gather -X- _ O
global -X- _ O
information; -X- _ O
(b) -X- _ O
The -X- _ O
relative-stride -X- _ O
pattern -X- _ O
attends -X- _ O
to -X- _ O
positions -X- _ O
every -X- _ O
a -X- _ O
few -X- _ O
stride -X- _ O
apart -X- _ O
relative -X- _ O
to -X- _ O
the -X- _ O
query -X- _ O
position; -X- _ O
(c) -X- _ O
The -X- _ O
one-side -X- _ O
masked -X- _ O
pattern -X- _ O
is -X- _ O
very -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
lower-left -X- _ O
part -X- _ O
of -X- _ O
Fig. -X- _ O
1-(d), -X- _ O
with -X- _ O
the -X- _ O
upper-right -X- _ O
triangle -X- _ O
masked -X- _ O
out. -X- _ O
It -X- _ O
seems -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
learns -X- _ O
not -X- _ O
to -X- _ O
attend -X- _ O
the -X- _ O
relative -X- _ O
right -X- _ O
half. -X- _ O
Note -X- _ O
that -X- _ O
all -X- _ O
these -X- _ O
three -X- _ O
unique -X- _ O
patterns -X- _ O
involve -X- _ O
the -X- _ O
relative -X- _ O
positions -X- _ O
rather -X- _ O
than -X- _ O
absolute -X- _ O
ones, -X- _ O
and -X- _ O
hence -X- _ O
are -X- _ O
likely -X- _ O
enabled -X- _ O
by -X- _ O
the -X- _ O
"relative -X- _ O
attention" -X- _ O
mechanism -X- _ O
in -X- _ O
XLNet. -X- _ B-MethodName
We -X- _ O
conjecture -X- _ O
these -X- _ O
unique -X- _ O
patterns -X- _ O
contribute -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
advantage -X- _ O
of -X- _ O
XLNet. -X- _ B-MethodName
On -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
the -X- _ O
proposed -X- _ O
permutation -X- _ B-TaskName
LM -X- _ I-TaskName
objective -X- _ O
mostly -X- _ O
contributes -X- _ O
to -X- _ O
a -X- _ O
better -X- _ O
data -X- _ O
efficiency, -X- _ O
whose -X- _ O
effects -X- _ O
may -X- _ O
not -X- _ O
be -X- _ O
obvious -X- _ O
from -X- _ O
qualitative -X- _ O
visualization. -X- _ O

With -X- _ O
a -X- _ O
deep -X- _ O
root -X- _ O
in -X- _ O
density -X- _ O
estimation -X- _ O
4 -X- _ O
, -X- _ O
language -X- _ O
modeling -X- _ O
has -X- _ O
been -X- _ O
a -X- _ O
rapidly-developing -X- _ O
research -X- _ O
area -X- _ O
. -X- _ O
However, -X- _ O
there -X- _ O
has -X- _ O
been -X- _ O
a -X- _ O
gap -X- _ O
between -X- _ O
language -X- _ O
modeling -X- _ O
and -X- _ O
pretraining -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
lack -X- _ O
of -X- _ O
the -X- _ O
capability -X- _ O
of -X- _ O
bidirectional -X- _ O
context -X- _ O
modeling, -X- _ O
as -X- _ O
analyzed -X- _ O
in -X- _ O
Section -X- _ O
A.5.2. -X- _ O
It -X- _ O
has -X- _ O
even -X- _ O
been -X- _ O
challenged -X- _ O
by -X- _ O
some -X- _ O
machine -X- _ O
learning -X- _ O
practitioners -X- _ O
whether -X- _ O
language -X- _ O
modeling -X- _ O
is -X- _ O
a -X- _ O
meaningful -X- _ O
pursuit -X- _ O
if -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
directly -X- _ O
improve -X- _ O
downstream -X- _ O
tasks -X- _ O
5 -X- _ O
. -X- _ O
XLNet -X- _ B-MethodName
generalizes -X- _ O
language -X- _ O
modeling -X- _ O
and -X- _ O
bridges -X- _ O
such -X- _ O
a -X- _ O
gap. -X- _ O
As -X- _ O
a -X- _ O
result, -X- _ O
it -X- _ O
further -X- _ O
"justifies" -X- _ O
language -X- _ O
modeling -X- _ O
research. -X- _ O
Moreover, -X- _ O
it -X- _ O
becomes -X- _ O
possible -X- _ O
to -X- _ O
leverage -X- _ O
the -X- _ O
rapid -X- _ O
progress -X- _ O
of -X- _ O
language -X- _ O
modeling -X- _ O
research -X- _ O
for -X- _ O
pretraining. -X- _ O
As -X- _ O
an -X- _ O
example, -X- _ O
we -X- _ O
integrate -X- _ O
Transformer-XL -X- _ O
into -X- _ O
XLNet -X- _ B-MethodName
to -X- _ O
demonstrate -X- _ O
the -X- _ O
usefulness -X- _ O
of -X- _ O
the -X- _ O
latest -X- _ O
language -X- _ O
modeling -X- _ O
progress. -X- _ O

Borrowing -X- _ O
examples -X- _ O
and -X- _ O
notations -X- _ O
from -X- _ O
Section -X- _ O
A.5.1, -X- _ O
a -X- _ O
standard -X- _ O
AR -X- _ O
language -X- _ O
model -X- _ O
like -X- _ O
GPT -X- _ O
is -X- _ O
only -X- _ O
able -X- _ O
to -X- _ O
cover -X- _ O
the -X- _ O
dependency -X- _ O
(x -X- _ O
= -X- _ O
York, -X- _ O
U -X- _ O
= -X- _ O
{New}) -X- _ O
but -X- _ O
not -X- _ O
(x -X- _ O
= -X- _ O
New, -X- _ O
U -X- _ O
= -X- _ O
{York}). -X- _ O
XLNet, -X- _ B-MethodName
on -X- _ O
the -X- _ O
other -X- _ O
hand, -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
cover -X- _ O
both -X- _ O
in -X- _ O
expectation -X- _ O
over -X- _ O
all -X- _ O
factorization -X- _ O
orders. -X- _ O
Such -X- _ O
a -X- _ O
limitation -X- _ O
of -X- _ O
AR -X- _ O
language -X- _ O
modeling -X- _ O
can -X- _ O
be -X- _ O
critical -X- _ O
in -X- _ O
real-world -X- _ O
applications. -X- _ O
For -X- _ O
example, -X- _ O
consider -X- _ O
a -X- _ O
span -X- _ O
extraction -X- _ O
question -X- _ O
answering -X- _ O
task -X- _ O
with -X- _ O
the -X- _ O
context -X- _ O
"Thom -X- _ O
Yorke -X- _ O
is -X- _ O
the -X- _ O
singer -X- _ O
of -X- _ O
Radiohead" -X- _ O
and -X- _ O
the -X- _ O
question -X- _ O
"Who -X- _ O
is -X- _ O
the -X- _ O
singer -X- _ O
of -X- _ O
Radiohead". -X- _ O
The -X- _ O
representations -X- _ O
of -X- _ O
"Thom -X- _ O
Yorke" -X- _ O
are -X- _ O
not -X- _ O
dependent -X- _ O
on -X- _ O
"Radiohead" -X- _ O
with -X- _ O
AR -X- _ O
language -X- _ O
modeling -X- _ O
and -X- _ O
thus -X- _ O
they -X- _ O
will -X- _ O
not -X- _ O
be -X- _ O
chosen -X- _ O
as -X- _ O
the -X- _ O
answer -X- _ O
by -X- _ O
the -X- _ O
standard -X- _ O
approach -X- _ O
that -X- _ O
employs -X- _ O
softmax -X- _ O
over -X- _ O
all -X- _ O
token -X- _ O
representations. -X- _ O
More -X- _ O
formally, -X- _ O
consider -X- _ O
a -X- _ O
context-target -X- _ O
pair -X- _ O
(x, -X- _ O
U): -X- _ O
• -X- _ O
If -X- _ O
U -X- _ O
⊆ -X- _ O
T -X- _ O
<x -X- _ O
, -X- _ O
where -X- _ O
T -X- _ O
<x -X- _ O
denotes -X- _ O
the -X- _ O
tokens -X- _ O
prior -X- _ O
to -X- _ O
x -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
sequence, -X- _ O
AR -X- _ O
language -X- _ O
modeling -X- _ O
is -X- _ O
not -X- _ O
able -X- _ O
to -X- _ O
cover -X- _ O
the -X- _ O
dependency. -X- _ O
• -X- _ O
In -X- _ O
comparison, -X- _ O
XLNet -X- _ B-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
cover -X- _ O
all -X- _ O
dependencies -X- _ O
in -X- _ O
expectation. -X- _ O
Approaches -X- _ O
like -X- _ O
ELMo -X- _ O
concatenate -X- _ O
forward -X- _ O
and -X- _ O
backward -X- _ O
language -X- _ O
models -X- _ O
in -X- _ O
a -X- _ O
shallow -X- _ O
manner, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
sufficient -X- _ O
for -X- _ O
modeling -X- _ O
deep -X- _ O
interactions -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
directions. -X- _ O

Following -X- _ O
the -X- _ O
setting -X- _ O
in -X- _ O
previous -X- _ O
work -X- _ O
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
ClueWeb09-B -X- _ B-DatasetName
dataset -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
on -X- _ O
document -X- _ O
ranking. -X- _ O
The -X- _ O
queries -X- _ O
were -X- _ O
created -X- _ O
by -X- _ O
the -X- _ O
TREC -X- _ O
2009-2012 -X- _ O
Web -X- _ O
Tracks -X- _ O
based -X- _ O
on -X- _ O
50M -X- _ O
documents -X- _ O
and -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
rerank -X- _ O
the -X- _ O
top -X- _ O
100 -X- _ O
documents -X- _ O
retrieved -X- _ O
using -X- _ O
a -X- _ O
standard -X- _ O
retrieval -X- _ O
method. -X- _ O
Since -X- _ O
document -X- _ O
ranking, -X- _ O
or -X- _ O
ad-hoc -X- _ O
retrieval, -X- _ O
mainly -X- _ O
concerns -X- _ O
the -X- _ O
low-level -X- _ O
representations -X- _ O
instead -X- _ O
of -X- _ O
high-level -X- _ O
semantics, -X- _ O
this -X- _ O
dataset -X- _ O
serves -X- _ O
as -X- _ O
a -X- _ O
testbed -X- _ O
for -X- _ O
evaluating -X- _ O
the -X- _ O
quality -X- _ O
of -X- _ O
word -X- _ O
embeddings. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
pretrained -X- _ O
XLNet -X- _ B-MethodName
to -X- _ O
extract -X- _ O
word -X- _ O
embeddings -X- _ O
for -X- _ O
the -X- _ O
documents -X- _ O
and -X- _ O
queries -X- _ O
without -X- _ O
finetuning, -X- _ O
and -X- _ O
employ -X- _ O
a -X- _ O
kernel -X- _ O
pooling -X- _ O
network -X- _ O
to -X- _ O
rank -X- _ O
the -X- _ O
documents. -X- _ O
A. -X- _ O
The -X- _ O
hyperparameters -X- _ O
used -X- _ O
for -X- _ O
pretraining -X- _ O
XLNet -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
7. -X- _ O

The -X- _ O
GLUE -X- _ B-DatasetName
dataset -X- _ O
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
9 -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
tasks. -X- _ O
The -X- _ O
test -X- _ O
set -X- _ O
labels -X- _ O
are -X- _ O
removed -X- _ O
from -X- _ O
the -X- _ O
publicly -X- _ O
released -X- _ O
version, -X- _ O
and -X- _ O
all -X- _ O
the -X- _ O
practitioners -X- _ O
must -X- _ O
submit -X- _ O
their -X- _ O
predictions -X- _ O
on -X- _ O
the -X- _ O
evaluation -X- _ O
server -X- _ O
to -X- _ O
obtain -X- _ O
test -X- _ O
set -X- _ O
results. -X- _ O
In -X- _ O
Table -X- _ O
5, -X- _ O
we -X- _ O
present -X- _ O
results -X- _ O
of -X- _ O
multiple -X- _ O
settings, -X- _ O
including -X- _ O
single-task -X- _ O
and -X- _ O
multi-task, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
single -X- _ O
models -X- _ O
and -X- _ O
ensembles. -X- _ O
In -X- _ O
the -X- _ O
multi-task -X- _ O
setting, -X- _ O
we -X- _ O
jointly -X- _ O
train -X- _ O
an -X- _ O
XLNet -X- _ B-MethodName
on -X- _ O
the -X- _ O
four -X- _ O
largest -X- _ O
datasets-MNLI, -X- _ B-DatasetName
SST-2, -X- _ B-DatasetName
QNLI, -X- _ B-DatasetName
and -X- _ O
QQP-and -X- _ B-DatasetName
finetune -X- _ O
the -X- _ O
network -X- _ O
on -X- _ O
the -X- _ O
other -X- _ O
datasets. -X- _ O
Only -X- _ O
single-task -X- _ O
training -X- _ O
is -X- _ O
employed -X- _ O
for -X- _ O
the -X- _ O
four -X- _ O
large -X- _ O
datasets. -X- _ O
For -X- _ O
QNLI, -X- _ B-DatasetName
we -X- _ O
employed -X- _ O
a -X- _ O
pairwise -X- _ O
relevance -X- _ O
ranking -X- _ O
scheme -X- _ O
as -X- _ O
in -X- _ O
for -X- _ O
our -X- _ O
test -X- _ O
set -X- _ O
submission. -X- _ O
However, -X- _ O
for -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
BERT, -X- _ B-MethodName
our -X- _ O
result -X- _ O
on -X- _ O
the -X- _ O
QNLI -X- _ B-DatasetName
dev -X- _ O
set -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
standard -X- _ O
classification -X- _ O
paradigm. -X- _ O
For -X- _ O
WNLI, -X- _ B-DatasetName
we -X- _ O
use -X- _ O
the -X- _ O
loss -X- _ O
described -X- _ O
in -X- _ O
. -X- _ O

Following -X- _ O
previous -X- _ O
work -X- _ O
on -X- _ O
text -X- _ O
classification -X- _ O
, -X- _ O
we -X- _ O
evaluate -X- _ O
XLNet -X- _ B-MethodName
on -X- _ O
the -X- _ O
following -X- _ O
benchmarks: -X- _ O
IMDB, -X- _ B-DatasetName
Yelp-2, -X- _ B-DatasetName
Yelp-5, -X- _ B-DatasetName
DBpedia, -X- _ B-DatasetName
AG, -X- _ B-DatasetName
Amazon-2, -X- _ B-DatasetName
and -X- _ O
Amazon-5. -X- _ B-DatasetName

SQuAD -X- _ B-DatasetName
is -X- _ O
a -X- _ O
large-scale -X- _ O
reading -X- _ O
comprehension -X- _ O
dataset -X- _ O
with -X- _ O
two -X- _ O
tasks. -X- _ O
SQuAD1.1 -X- _ B-DatasetName
contains -X- _ O
questions -X- _ O
that -X- _ O
always -X- _ O
have -X- _ O
a -X- _ O
corresponding -X- _ O
answer -X- _ O
in -X- _ O
the -X- _ O
given -X- _ O
passages, -X- _ O
while -X- _ O
SQuAD2.0 -X- _ B-DatasetName
introduces -X- _ O
unanswerable -X- _ O
questions. -X- _ O
To -X- _ O
finetune -X- _ O
an -X- _ O
XLNet -X- _ B-MethodName
on -X- _ O
SQuAD2.0, -X- _ B-DatasetName
we -X- _ O
jointly -X- _ O
apply -X- _ O
a -X- _ O
logistic -X- _ O
regression -X- _ O
loss -X- _ O
for -X- _ O
answerability -X- _ O
prediction -X- _ O
similar -X- _ O
to -X- _ O
classification -X- _ O
tasks -X- _ O
and -X- _ O
a -X- _ O
standard -X- _ O
span -X- _ O
extraction -X- _ O
loss -X- _ O
for -X- _ O
question -X- _ O
answering -X- _ O
. -X- _ O

Here, -X- _ O
we -X- _ O
provide -X- _ O
the -X- _ O
implementation -X- _ O
details -X- _ O
of -X- _ O
the -X- _ O
two-stream -X- _ O
attention -X- _ O
with -X- _ O
a -X- _ O
Transformer-XL -X- _ O
backbone. -X- _ O
Initial -X- _ O
represetation: -X- _ O
∀t -X- _ O
= -X- _ O
1, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
T -X- _ O
: -X- _ O
h -X- _ O
t -X- _ O
= -X- _ O
e(x -X- _ O
t -X- _ O
) -X- _ O
and -X- _ O
g -X- _ O
t -X- _ O
= -X- _ O
w -X- _ O
Cached -X- _ O
layer-m -X- _ O
content -X- _ O
represetation -X- _ O
(memory) -X- _ O
from -X- _ O
previous -X- _ O
segment:h -X- _ O
(m) -X- _ O
For -X- _ O
the -X- _ O
Transformer-XL -X- _ O
layer -X- _ O
m -X- _ O
= -X- _ O
1, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
M -X- _ O
, -X- _ O
attention -X- _ O
with -X- _ O
relative -X- _ O
positional -X- _ O
encoding -X- _ O
and -X- _ O
position-wise -X- _ O
feed-forward -X- _ O
are -X- _ O
consecutively -X- _ O
employed -X- _ O
to -X- _ O
update -X- _ O
the -X- _ O
represetntations: -X- _ O
∀t -X- _ O
= -X- _ O
1, -X- _ O
. -X- _ O
. -X- _ O
. -X- _ O
, -X- _ O
T -X- _ O
:ĥ -X- _ O
(m) -X- _ O
zt -X- _ O
= -X- _ O
LayerNorm -X- _ O
h -X- _ O
(m−1) -X- _ O
zt -X- _ O
+ -X- _ O
RelAttn -X- _ O
h -X- _ O
(m−1) -X- _ O
zt -X- _ O
, -X- _ O
h -X- _ O
(m−1) -X- _ O
, -X- _ O
h -X- _ O
(m−1) -X- _ O
z -X- _ O
≤t -X- _ O
h -X- _ O
(m) -X- _ O
zt -X- _ O
= -X- _ O
LayerNorm -X- _ O
ĥ -X- _ O
(m) -X- _ O
zt -X- _ O
+ -X- _ O
PosFF -X- _ O
ĥ -X- _ O
(m) -X- _ O
zt -X- _ O
ĝ -X- _ O
(m) -X- _ O
zt -X- _ O
= -X- _ O
LayerNorm -X- _ O
g -X- _ O
(m−1) -X- _ O
zt -X- _ O
+ -X- _ O
RelAttn -X- _ O
g -X- _ O
(m−1) -X- _ O
zt -X- _ O
, -X- _ O
h -X- _ O
(m−1) -X- _ O
, -X- _ O
h -X- _ O
(m−1) -X- _ O
z<t -X- _ O
g -X- _ O
(m) -X- _ O
zt -X- _ O
= -X- _ O
LayerNorm -X- _ O
ĝ -X- _ O
(m) -X- _ O
zt -X- _ O
+ -X- _ O
PosFF -X- _ O
ĝ -X- _ O
(m) -X- _ O
zt -X- _ O
Target-aware -X- _ O
prediction -X- _ O
distribution: -X- _ O
p -X- _ O
θ -X- _ O
(X -X- _ O
zt -X- _ O
= -X- _ O
x -X- _ O
| -X- _ O
x -X- _ O
z<t -X- _ O
) -X- _ O
= -X- _ O
exp -X- _ O
e(x) -X- _ O
g -X- _ O
(M -X- _ O
) -X- _ O
zt -X- _ O
x -X- _ O
exp -X- _ O
e(x -X- _ O
) -X- _ O
g -X- _ O
(M -X- _ O
) -X- _ O
zt -X- _ O
, -X- _ O
A.3 -X- _ O
Datasets -X- _ O
A.3.1 -X- _ O
RACE -X- _ B-DatasetName
Dataset -X- _ O
The -X- _ O
RACE -X- _ B-DatasetName
dataset -X- _ O
contains -X- _ O
near -X- _ O
100K -X- _ O
questions -X- _ O
taken -X- _ O
from -X- _ O
the -X- _ O
English -X- _ O
exams -X- _ O
for -X- _ O
middle -X- _ O
and -X- _ O
high -X- _ O
school -X- _ O
Chinese -X- _ O
students -X- _ O
in -X- _ O
the -X- _ O
age -X- _ O
range -X- _ O
between -X- _ O
12 -X- _ O
to -X- _ O
18, -X- _ O
with -X- _ O
the -X- _ O
answers -X- _ O
generated -X- _ O
by -X- _ O
human -X- _ O
experts. -X- _ O
This -X- _ O
is -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
most -X- _ O
difficult -X- _ O
reading -X- _ O
comprehension -X- _ O
datasets -X- _ O
that -X- _ O
involve -X- _ O
challenging -X- _ O
reasoning -X- _ O
questions. -X- _ O
Moreover, -X- _ O
the -X- _ O
average -X- _ O
length -X- _ O
of -X- _ O
the -X- _ O
passages -X- _ O
in -X- _ O
RACE -X- _ B-DatasetName
are -X- _ O
longer -X- _ O
than -X- _ O
300, -X- _ O
which -X- _ O
is -X- _ O
significantly -X- _ O
longer -X- _ O
than -X- _ O
other -X- _ O
popular -X- _ O
reading -X- _ O
comprehension -X- _ O
datasets -X- _ O
such -X- _ O
as -X- _ O
SQuAD -X- _ O
. -X- _ O
As -X- _ O
a -X- _ O
result, -X- _ O
this -X- _ O
dataset -X- _ O
serves -X- _ O
as -X- _ O
a -X- _ O
challenging -X- _ O
benchmark -X- _ O
for -X- _ O
long -X- _ O
text -X- _ O
understanding. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
sequence -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
512 -X- _ B-HyperparameterValue
during -X- _ O
finetuning. -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
provide -X- _ O
a -X- _ O
concrete -X- _ O
example -X- _ O
to -X- _ O
show -X- _ O
how -X- _ O
the -X- _ O
standard -X- _ O
language -X- _ O
model -X- _ O
parameterization -X- _ O
fails -X- _ O
under -X- _ O
the -X- _ O
permutation -X- _ O
objective, -X- _ O
as -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
2.3. -X- _ O
Specifically, -X- _ O
let's -X- _ O
consider -X- _ O
two -X- _ O
different -X- _ O
permutations -X- _ O
z -X- _ O
(1) -X- _ O
and -X- _ O
z -X- _ O
(2) -X- _ O
satisfying -X- _ O
the -X- _ O
following -X- _ O
relationship -X- _ O
z -X- _ O
(1) -X- _ O
<t -X- _ O
= -X- _ O
z -X- _ O
(2) -X- _ O
<t -X- _ O
= -X- _ O
z -X- _ O
<t -X- _ O
but -X- _ O
z -X- _ O
(1) -X- _ O
t -X- _ O
= -X- _ O
i -X- _ O
= -X- _ O
j -X- _ O
= -X- _ O
z(2) -X- _ O
t -X- _ O
. -X- _ O
Then, -X- _ O
substituting -X- _ O
the -X- _ O
two -X- _ O
permutations -X- _ O
respectively -X- _ O
into -X- _ O
the -X- _ O
naive -X- _ O
parameterization, -X- _ O
we -X- _ O
have -X- _ O
p -X- _ O
θ -X- _ O
(X -X- _ O
i -X- _ O
= -X- _ O
x -X- _ O
| -X- _ O
x -X- _ O
z<t -X- _ O
) -X- _ O
z -X- _ O
(1) -X- _ O
t -X- _ O
=i, -X- _ O
z -X- _ O
(1) -X- _ O
<t -X- _ O
=z<t -X- _ O
= -X- _ O
p -X- _ O
θ -X- _ O
(X -X- _ O
j -X- _ O
= -X- _ O
x -X- _ O
| -X- _ O
x -X- _ O
z<t -X- _ O
) -X- _ O
z -X- _ O
(1) -X- _ O
t -X- _ O
=j, -X- _ O
z(2) -X- _ O
<t -X- _ O
=z<t -X- _ O
= -X- _ O
exp -X- _ O
e(x) -X- _ O
h(x -X- _ O
z<t -X- _ O
) -X- _ O
x -X- _ O
exp -X- _ O
(e(x -X- _ O
) -X- _ O
h(x -X- _ O
z<t -X- _ O
)) -X- _ O
. -X- _ O
Effectively, -X- _ O
two -X- _ O
different -X- _ O
target -X- _ O
positions -X- _ O
i -X- _ O
and -X- _ O
j -X- _ O
share -X- _ O
exactly -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
prediction. -X- _ O
However, -X- _ O
the -X- _ O
ground-truth -X- _ O
distribution -X- _ O
of -X- _ O
two -X- _ O
positions -X- _ O
should -X- _ O
certainly -X- _ O
be -X- _ O
different. -X- _ O

XLNet -X- _ B-MethodName
is -X- _ O
a -X- _ O
generalized -X- _ O
AR -X- _ O
pretraining -X- _ O
method -X- _ O
that -X- _ O
uses -X- _ O
a -X- _ O
permutation -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
to -X- _ O
combine -X- _ O
the -X- _ O
advantages -X- _ O
of -X- _ O
AR -X- _ O
and -X- _ O
AE -X- _ O
methods. -X- _ O
The -X- _ O
neural -X- _ O
architecture -X- _ O
of -X- _ O
XLNet -X- _ B-MethodName
is -X- _ O
developed -X- _ O
to -X- _ O
work -X- _ O
seamlessly -X- _ O
with -X- _ O
the -X- _ O
AR -X- _ O
objective, -X- _ O
including -X- _ O
integrating -X- _ O
Transformer-XL -X- _ O
and -X- _ O
the -X- _ O
careful -X- _ O
design -X- _ O
of -X- _ O
the -X- _ O
two-stream -X- _ O
attention -X- _ O
mechanism. -X- _ O
XLNet -X- _ B-MethodName
achieves -X- _ O
substantial -X- _ O
improvement -X- _ O
over -X- _ O
previous -X- _ O
pretraining -X- _ O
objectives -X- _ O
on -X- _ O
various -X- _ O
tasks. -X- _ O
A -X- _ O
Target-Aware -X- _ O
Representation -X- _ O
via -X- _ O
Two-Stream -X- _ O
Self-Attention -X- _ O

We -X- _ O
perform -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
each -X- _ O
design -X- _ O
choice -X- _ O
based -X- _ O
on -X- _ O
four -X- _ O
datasets -X- _ O
with -X- _ O
diverse -X- _ O
characteristics. -X- _ O
Specifically, -X- _ O
there -X- _ O
are -X- _ O
three -X- _ O
main -X- _ O
aspects -X- _ O
we -X- _ O
hope -X- _ O
to -X- _ O
study: -X- _ O
• -X- _ O
The -X- _ O
effectiveness -X- _ O
of -X- _ O
the -X- _ O
permutation -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
alone, -X- _ O
especially -X- _ O
compared -X- _ O
to -X- _ O
the -X- _ O
denoising -X- _ O
auto-encoding -X- _ O
objective -X- _ O
used -X- _ O
by -X- _ O
BERT. -X- _ B-MethodName
• -X- _ O
The -X- _ O
importance -X- _ O
of -X- _ O
using -X- _ O
Transformer-XL -X- _ O
as -X- _ O
the -X- _ O
backbone -X- _ O
neural -X- _ O
architecture. -X- _ O
• -X- _ O
The -X- _ O
necessity -X- _ O
of -X- _ O
some -X- _ O
implementation -X- _ O
details -X- _ O
including -X- _ O
span-based -X- _ O
prediction, -X- _ O
the -X- _ O
bidirectional -X- _ O
input -X- _ O
pipeline, -X- _ O
and -X- _ O
next-sentence -X- _ O
prediction. -X- _ O
With -X- _ O
these -X- _ O
purposes -X- _ O
in -X- _ O
mind, -X- _ O
in -X- _ O
Table -X- _ O
6, -X- _ O
we -X- _ O
compare -X- _ O
6 -X- _ O
XLNet-Base -X- _ B-MethodName
variants -X- _ O
with -X- _ O
different -X- _ O
implementation -X- _ O
details -X- _ O
(rows -X- _ O
3 -X- _ O
-8), -X- _ O
the -X- _ O
original -X- _ O
BERT-Base -X- _ O
model -X- _ O
(row -X- _ O
1), -X- _ O
and -X- _ O
an -X- _ O
additional -X- _ O
Transformer-XL -X- _ O
baseline -X- _ O
trained -X- _ O
with -X- _ O
the -X- _ O
denoising -X- _ O
auto-encoding -X- _ O
(DAE) -X- _ O
objective -X- _ O
used -X- _ O
in -X- _ O
BERT -X- _ B-MethodName
but -X- _ O
with -X- _ O
the -X- _ O
bidirectional -X- _ O
input -X- _ O
pipeline -X- _ O
(row -X- _ O
2). -X- _ O
For -X- _ O
fair -X- _ O
comparison, -X- _ O
all -X- _ O
models -X- _ O
are -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
12-layer -X- _ B-HyperparameterValue
architecture -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
hyper-parameters -X- _ O
as -X- _ O
BERT-Base -X- _ O
and -X- _ O
are -X- _ O
trained -X- _ O
on -X- _ O
only -X- _ O
Wikipedia -X- _ B-DatasetName
and -X- _ O
the -X- _ O
BooksCorpus. -X- _ B-DatasetName
All -X- _ O
results -X- _ O
reported -X- _ O
are -X- _ O
the -X- _ O
median -X- _ O
of -X- _ O
5 -X- _ O
runs. -X- _ O
Table -X- _ O
6: -X- _ O
The -X- _ O
results -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
RACE -X- _ O
are -X- _ O
taken -X- _ O
from -X- _ O
. -X- _ O
We -X- _ O
run -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
the -X- _ O
other -X- _ O
datasets -X- _ O
using -X- _ O
the -X- _ O
official -X- _ O
implementation -X- _ O
and -X- _ O
the -X- _ O
same -X- _ O
hyperparameter -X- _ O
search -X- _ O
space -X- _ O
as -X- _ O
XLNet. -X- _ B-MethodName
K -X- _ B-HyperparameterName
is -X- _ O
a -X- _ O
hyperparameter -X- _ O
to -X- _ O
control -X- _ O
the -X- _ O
optimization -X- _ O
difficulty -X- _ O
(see -X- _ O
Section -X- _ O
2.3). -X- _ O
Examining -X- _ O
rows -X- _ O
1 -X- _ O
-4 -X- _ O
of -X- _ O
Table -X- _ O
6, -X- _ O
we -X- _ O
can -X- _ O
see -X- _ O
both -X- _ O
Transformer-XL -X- _ O
and -X- _ O
the -X- _ O
permutation -X- _ O
LM -X- _ O
clearly -X- _ O
contribute -X- _ O
the -X- _ O
superior -X- _ O
performance -X- _ O
of -X- _ O
XLNet -X- _ B-MethodName
over -X- _ O
BERT. -X- _ B-MethodName
Moreover, -X- _ O
if -X- _ O
we -X- _ O
remove -X- _ O
the -X- _ O
memory -X- _ O
caching -X- _ O
mechanism -X- _ O
(row -X- _ O
5), -X- _ O
the -X- _ O
performance -X- _ O
clearly -X- _ O
drops, -X- _ O
especially -X- _ O
for -X- _ O
RACE -X- _ O
which -X- _ O
involves -X- _ O
the -X- _ O
longest -X- _ O
context -X- _ O
among -X- _ O
the -X- _ O
4 -X- _ O
tasks. -X- _ O
In -X- _ O
addition, -X- _ O
rows -X- _ O
6 -X- _ O
-7 -X- _ O
show -X- _ O
that -X- _ O
both -X- _ O
span-based -X- _ O
prediction -X- _ O
and -X- _ O
the -X- _ O
bidirectional -X- _ O
input -X- _ O
pipeline -X- _ O
play -X- _ O
important -X- _ O
roles -X- _ O
in -X- _ O
XLNet. -X- _ B-MethodName
Finally, -X- _ O
we -X- _ O
unexpectedly -X- _ O
find -X- _ O
the -X- _ O
the -X- _ O
next-sentence -X- _ O
prediction -X- _ O
objective -X- _ O
proposed -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
BERT -X- _ B-MethodName
does -X- _ O
not -X- _ O
necessarily -X- _ O
lead -X- _ O
to -X- _ O
an -X- _ O
improvement -X- _ O
in -X- _ O
our -X- _ O
setting. -X- _ O
Hence, -X- _ O
we -X- _ O
exclude -X- _ O
the -X- _ O
next-sentence -X- _ O
prediction -X- _ O
objective -X- _ O
from -X- _ O
XLNet. -X- _ B-MethodName
Finally, -X- _ O
we -X- _ O
also -X- _ O
perform -X- _ O
a -X- _ O
qualitative -X- _ O
study -X- _ O
of -X- _ O
the -X- _ O
attention -X- _ O
patterns, -X- _ O
which -X- _ O
is -X- _ O
included -X- _ O
in -X- _ O
Appendix -X- _ O
A.6 -X- _ O
due -X- _ O
to -X- _ O
page -X- _ O
limit. -X- _ O

BERT. -X- _ B-MethodName
We -X- _ O
use -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
3 -X- _ O
BERT -X- _ B-MethodName
variants -X- _ O
for -X- _ O
comparison; -X- _ O
i.e., -X- _ O
the -X- _ O
original -X- _ O
BERT, -X- _ B-MethodName
BERT -X- _ B-MethodName
with -X- _ O
whole -X- _ O
word -X- _ O
masking, -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
without -X- _ O
next -X- _ O
sentence -X- _ O
prediction. -X- _ O
Here, -X- _ O
we -X- _ O
first -X- _ O
compare -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
XLNet -X- _ B-MethodName
in -X- _ O
a -X- _ O
fair -X- _ O
setting -X- _ O
to -X- _ O
decouple -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
using -X- _ O
more -X- _ O
data -X- _ O
and -X- _ O
the -X- _ O
improvement -X- _ O
from -X- _ O
BERT -X- _ B-MethodName
to -X- _ O
XLNet. -X- _ B-MethodName
In -X- _ O
After -X- _ O
the -X- _ O
initial -X- _ O
publication -X- _ O
of -X- _ O
our -X- _ O
manuscript, -X- _ O
a -X- _ O
few -X- _ O
other -X- _ O
pretrained -X- _ O
models -X- _ O
were -X- _ O
released -X- _ O
such -X- _ O
as -X- _ O
RoBERTa -X- _ B-MethodName
and -X- _ O
ALBERT -X- _ O
. -X- _ O
Since -X- _ O
ALBERT -X- _ O
involves -X- _ O
increasing -X- _ O
the -X- _ O
model -X- _ O
hidden -X- _ O
size -X- _ O
from -X- _ O
1024 -X- _ O
to -X- _ O
2048/4096 -X- _ O
and -X- _ O
thus -X- _ O
substantially -X- _ O
increases -X- _ O
the -X- _ O
amount -X- _ O
of -X- _ O
computation -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
FLOPs, -X- _ O
we -X- _ O
exclude -X- _ O
ALBERT -X- _ O
from -X- _ O
the -X- _ O
following -X- _ O
results -X- _ O
as -X- _ O
it -X- _ O
is -X- _ O
hard -X- _ O
to -X- _ O
lead -X- _ O
to -X- _ O
scientific -X- _ O
conclusions. -X- _ O
To -X- _ O
obtain -X- _ O
relatively -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
RoBERTa, -X- _ O
the -X- _ O
experiment -X- _ O
in -X- _ O
this -X- _ O
section -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
full -X- _ O
data -X- _ O
and -X- _ O
reuses -X- _ O
the -X- _ O
hyper-parameters -X- _ O
of -X- _ O
RoBERTa, -X- _ B-MethodName
as -X- _ O
described -X- _ O
in -X- _ O
section -X- _ O
3.1. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Tables -X- _ O
2 -X- _ O
(reading -X- _ B-TaskName
comprehension -X- _ I-TaskName
& -X- _ O
document -X- _ B-TaskName
ranking), -X- _ I-TaskName
3 -X- _ O
(question -X- _ B-TaskName
answering), -X- _ I-TaskName
4 -X- _ O
(text -X- _ B-TaskName
classification) -X- _ I-TaskName
and -X- _ O
5 -X- _ O
(natural -X- _ B-TaskName
language -X- _ I-TaskName
understanding), -X- _ I-TaskName
where -X- _ O
XLNet -X- _ B-MethodName
generally -X- _ O
outperforms -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
RoBERTa. -X- _ B-MethodName
In -X- _ O
addition, -X- _ O
we -X- _ O
make -X- _ O
two -X- _ O
more -X- _ O
interesting -X- _ O
observations: -X- _ O
All -X- _ O
dev -X- _ O
results -X- _ O
are -X- _ O
the -X- _ O
median -X- _ O
of -X- _ O
10 -X- _ O
runs. -X- _ O
The -X- _ O
upper -X- _ O
section -X- _ O
shows -X- _ O
direct -X- _ O
comparison -X- _ O
on -X- _ O
dev -X- _ O
data -X- _ O
and -X- _ O
the -X- _ O
lower -X- _ O
section -X- _ O
shows -X- _ O
comparison -X- _ O
with -X- _ O
state-of-the-art -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
public -X- _ O
leaderboard. -X- _ O
SQuAD2.0 -X- _ B-DatasetName
EM -X- _ O
F1 -X- _ B-MetricName
SQuAD1.1 -X- _ B-DatasetName
EM -X- _ O
F1 -X- _ B-MetricName
• -X- _ O
For -X- _ O
explicit -X- _ O
reasoning -X- _ O
tasks -X- _ O
like -X- _ O
SQuAD -X- _ B-DatasetName
and -X- _ O
RACE -X- _ B-DatasetName
that -X- _ O
involve -X- _ O
longer -X- _ O
context, -X- _ O
the -X- _ O
performance -X- _ O
gain -X- _ O
of -X- _ O
XLNet -X- _ B-MethodName
is -X- _ O
usually -X- _ O
larger. -X- _ O
This -X- _ O
superiority -X- _ O
at -X- _ O
dealing -X- _ O
with -X- _ O
longer -X- _ O
context -X- _ O
could -X- _ O
come -X- _ O
from -X- _ O
the -X- _ O
Transformer-XL -X- _ O
backbone -X- _ O
in -X- _ O
XLNet. -X- _ B-MethodName
• -X- _ O
For -X- _ O
classification -X- _ O
tasks -X- _ O
that -X- _ O
already -X- _ O
have -X- _ O
abundant -X- _ O
supervised -X- _ O
examples -X- _ O
such -X- _ O
as -X- _ O
MNLI -X- _ B-DatasetName
(>390K), -X- _ O
Yelp -X- _ B-DatasetName
(>560K) -X- _ O
and -X- _ O
Amazon -X- _ B-DatasetName
(>3M), -X- _ O
XLNet -X- _ B-MethodName
still -X- _ O
lead -X- _ O
to -X- _ O
substantial -X- _ O
gains. -X- _ O

Following -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
BooksCorpus -X- _ B-DatasetName
and -X- _ O
English -X- _ B-DatasetName
Wikipedia -X- _ I-DatasetName
as -X- _ O
part -X- _ O
of -X- _ O
our -X- _ O
pretraining -X- _ O
data, -X- _ O
which -X- _ O
have -X- _ O
13GB -X- _ O
plain -X- _ O
text -X- _ O
combined. -X- _ O
In -X- _ O
addition, -X- _ O
we -X- _ O
include -X- _ O
Giga5 -X- _ B-DatasetName
(16GB -X- _ O
text) -X- _ O
, -X- _ O
ClueWeb -X- _ B-DatasetName
2012-B -X- _ I-DatasetName
(extended -X- _ O
from -X- _ O
), -X- _ O
and -X- _ O
Common -X- _ B-DatasetName
Crawl -X- _ I-DatasetName
for -X- _ O
pretraining. -X- _ O
We -X- _ O
use -X- _ O
heuristics -X- _ O
to -X- _ O
aggressively -X- _ O
filter -X- _ O
out -X- _ O
short -X- _ O
or -X- _ O
low-quality -X- _ O
articles -X- _ O
for -X- _ O
ClueWeb -X- _ B-DatasetName
2012-B -X- _ I-DatasetName
and -X- _ O
Common -X- _ B-DatasetName
Crawl, -X- _ I-DatasetName
which -X- _ O
results -X- _ O
in -X- _ O
19GB -X- _ O
and -X- _ O
110GB -X- _ O
text -X- _ O
respectively. -X- _ O
After -X- _ O
tokenization -X- _ O
with -X- _ O
SentencePiece -X- _ O
, -X- _ O
we -X- _ O
obtain -X- _ O
2.78B, -X- _ O
1.09B, -X- _ O
4.75B, -X- _ O
4.30B, -X- _ O
and -X- _ O
19.97B -X- _ O
subword -X- _ O
pieces -X- _ O
for -X- _ O
Wikipedia, -X- _ B-DatasetName
BooksCorpus, -X- _ B-DatasetName
Giga5, -X- _ B-DatasetName
ClueWeb, -X- _ B-DatasetName
and -X- _ O
Common -X- _ B-DatasetName
Crawl -X- _ I-DatasetName
respectively, -X- _ O
which -X- _ O
are -X- _ O
32.89B -X- _ O
in -X- _ O
total. -X- _ O
Our -X- _ O
largest -X- _ O
model -X- _ O
XLNet-Large -X- _ B-MethodName
has -X- _ O
the -X- _ O
same -X- _ O
architecture -X- _ O
hyperparameters -X- _ O
as -X- _ O
BERT-Large, -X- _ O
which -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
similar -X- _ O
model -X- _ O
size. -X- _ O
During -X- _ O
pretraining, -X- _ O
we -X- _ O
always -X- _ O
use -X- _ O
a -X- _ O
full -X- _ O
sequence -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
512. -X- _ B-HyperparameterValue
Firstly, -X- _ O
to -X- _ O
provide -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
BERT -X- _ B-MethodName
(section -X- _ O
3.2), -X- _ O
we -X- _ O
also -X- _ O
trained -X- _ O
XLNet-Large-wikibooks -X- _ B-MethodName
on -X- _ O
BooksCorpus -X- _ B-DatasetName
and -X- _ O
Wikipedia -X- _ B-DatasetName
only, -X- _ O
where -X- _ O
we -X- _ O
reuse -X- _ O
all -X- _ O
pretraining -X- _ O
hyper-parameters -X- _ O
as -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
BERT. -X- _ B-MethodName
Then, -X- _ O
we -X- _ O
scale -X- _ O
up -X- _ O
the -X- _ O
training -X- _ O
of -X- _ O
XLNet-Large -X- _ B-MethodName
by -X- _ O
using -X- _ O
all -X- _ O
the -X- _ O
datasets -X- _ O
described -X- _ O
above. -X- _ O
Specifically, -X- _ O
we -X- _ O
train -X- _ O
on -X- _ O
512 -X- _ O
TPU -X- _ O
v3 -X- _ O
chips -X- _ O
for -X- _ O
500K -X- _ O
steps -X- _ O
with -X- _ O
an -X- _ O
Adam -X- _ O
weight -X- _ O
decay -X- _ O
optimizer, -X- _ O
linear -X- _ O
learning -X- _ O
rate -X- _ O
decay, -X- _ O
and -X- _ O
a -X- _ O
batch -X- _ O
size -X- _ O
of -X- _ O
8192, -X- _ O
which -X- _ O
takes -X- _ O
about -X- _ O
5.5 -X- _ O
days. -X- _ O
It -X- _ O
was -X- _ O
observed -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
still -X- _ O
underfits -X- _ O
the -X- _ O
data -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
training. -X- _ O
Finally, -X- _ O
we -X- _ O
perform -X- _ O
ablation -X- _ O
study -X- _ O
(section -X- _ O
3.4) -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
XLNet-Base-wikibooks. -X- _ B-MethodName
Since -X- _ O
the -X- _ O
recurrence -X- _ O
mechanism -X- _ O
is -X- _ O
introduced, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
bidirectional -X- _ O
data -X- _ O
input -X- _ O
pipeline -X- _ O
where -X- _ O
each -X- _ O
of -X- _ O
the -X- _ O
forward -X- _ O
and -X- _ O
backward -X- _ O
directions -X- _ O
takes -X- _ O
half -X- _ O
of -X- _ O
the -X- _ O
batch -X- _ O
size. -X- _ O
For -X- _ O
training -X- _ O
XLNet-Large, -X- _ B-MethodName
we -X- _ O
set -X- _ O
the -X- _ O
partial -X- _ O
prediction -X- _ O
constant -X- _ O
K -X- _ B-HyperparameterName
as -X- _ O
6 -X- _ B-HyperparameterValue
(see -X- _ O
Section -X- _ O
2.3). -X- _ O
Our -X- _ O
finetuning -X- _ O
procedure -X- _ O
follows -X- _ O
BERT -X- _ B-MethodName
except -X- _ O
otherwise -X- _ O
specified -X- _ O
3 -X- _ O
. -X- _ O
We -X- _ O
employ -X- _ O
an -X- _ O
idea -X- _ O
of -X- _ O
span-based -X- _ O
prediction, -X- _ O
where -X- _ O
we -X- _ O
first -X- _ O
sample -X- _ O
a -X- _ O
length -X- _ O
L -X- _ O
∈ -X- _ O
[1, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
5], -X- _ O
and -X- _ O
then -X- _ O
randomly -X- _ O
select -X- _ O
a -X- _ O
consecutive -X- _ O
span -X- _ O
of -X- _ O
L -X- _ O
tokens -X- _ O
as -X- _ O
prediction -X- _ O
targets -X- _ O
within -X- _ O
a -X- _ O
context -X- _ O
of -X- _ O
(KL) -X- _ O
tokens. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
datasets -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
method. -X- _ O
Detailed -X- _ O
descriptions -X- _ O
of -X- _ O
the -X- _ O
settings -X- _ O
for -X- _ O
all -X- _ O
the -X- _ O
datasets -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.3. -X- _ O

Comparing -X- _ O
Eq. -X- _ O
(2) -X- _ O
and -X- _ O
( -X- _ O
5), -X- _ O
we -X- _ O
observe -X- _ O
that -X- _ O
both -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
XLNet -X- _ B-MethodName
perform -X- _ O
partial -X- _ O
prediction, -X- _ O
i.e., -X- _ O
only -X- _ O
predicting -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
sequence. -X- _ O
This -X- _ O
is -X- _ O
a -X- _ O
necessary -X- _ O
choice -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
because -X- _ O
if -X- _ O
all -X- _ O
tokens -X- _ O
are -X- _ O
masked, -X- _ O
it -X- _ O
is -X- _ O
impossible -X- _ O
to -X- _ O
make -X- _ O
any -X- _ O
meaningful -X- _ O
predictions. -X- _ O
In -X- _ O
addition, -X- _ O
for -X- _ O
both -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
XLNet, -X- _ B-MethodName
partial -X- _ O
prediction -X- _ O
plays -X- _ O
a -X- _ O
role -X- _ O
of -X- _ O
reducing -X- _ O
optimization -X- _ O
difficulty -X- _ O
by -X- _ O
only -X- _ O
predicting -X- _ O
tokens -X- _ O
with -X- _ O
sufficient -X- _ O
context. -X- _ O
However, -X- _ O
the -X- _ O
independence -X- _ O
assumption -X- _ O
discussed -X- _ O
in -X- _ O
Section -X- _ O
2.1 -X- _ O
disables -X- _ O
BERT -X- _ B-MethodName
to -X- _ O
model -X- _ O
dependency -X- _ O
between -X- _ O
targets. -X- _ O
To -X- _ O
better -X- _ O
understand -X- _ O
the -X- _ O
difference, -X- _ O
let's -X- _ O
consider -X- _ O
a -X- _ O
concrete -X- _ O
example -X- _ O
[New, -X- _ O
York, -X- _ O
is, -X- _ O
a, -X- _ O
city]. -X- _ O
Suppose -X- _ O
both -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
XLNet -X- _ B-MethodName
select -X- _ O
the -X- _ O
two -X- _ O
tokens -X- _ O
[New, -X- _ O
York] -X- _ O
as -X- _ O
the -X- _ O
prediction -X- _ O
targets -X- _ O
and -X- _ O
maximize -X- _ O
log -X- _ O
p(New -X- _ O
York -X- _ O
| -X- _ O
is -X- _ O
a -X- _ O
city). -X- _ O
Also -X- _ O
suppose -X- _ O
that -X- _ O
XLNet -X- _ B-MethodName
samples -X- _ O
the -X- _ O
factorization -X- _ O
order -X- _ O
[is, -X- _ O
a, -X- _ O
city, -X- _ O
New, -X- _ O
York]. -X- _ O
In -X- _ O
this -X- _ O
case, -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
XLNet -X- _ B-MethodName
respectively -X- _ O
reduce -X- _ O
to -X- _ O
the -X- _ O
following -X- _ O
objectives: -X- _ O
J -X- _ O
BERT -X- _ O
= -X- _ O
log -X- _ O
p(New -X- _ O
| -X- _ O
is -X- _ O
a -X- _ O
city) -X- _ O
+ -X- _ O
log -X- _ O
p(York -X- _ O
| -X- _ O
is -X- _ O
a -X- _ O
city), -X- _ O
J -X- _ O
XLNet -X- _ O
= -X- _ O
log -X- _ O
p(New -X- _ O
| -X- _ O
is -X- _ O
a -X- _ O
city) -X- _ O
+ -X- _ O
log -X- _ O
p(York -X- _ O
| -X- _ O
New, -X- _ O
is -X- _ O
a -X- _ O
city). -X- _ O
Notice -X- _ O
that -X- _ O
XLNet -X- _ B-MethodName
is -X- _ O
able -X- _ O
to -X- _ O
capture -X- _ O
the -X- _ O
dependency -X- _ O
between -X- _ O
the -X- _ O
pair -X- _ O
(New, -X- _ O
York), -X- _ O
which -X- _ O
is -X- _ O
omitted -X- _ O
by -X- _ O
BERT. -X- _ O
Although -X- _ O
in -X- _ O
this -X- _ O
example, -X- _ O
BERT -X- _ B-MethodName
learns -X- _ O
some -X- _ O
dependency -X- _ O
pairs -X- _ O
such -X- _ O
as -X- _ O
(New, -X- _ O
city) -X- _ O
and -X- _ O
(York, -X- _ O
city), -X- _ O
it -X- _ O
is -X- _ O
obvious -X- _ O
that -X- _ O
XLNet -X- _ B-MethodName
always -X- _ O
learns -X- _ O
more -X- _ O
dependency -X- _ O
pairs -X- _ O
given -X- _ O
the -X- _ O
same -X- _ O
target -X- _ O
and -X- _ O
contains -X- _ O
"denser" -X- _ O
effective -X- _ O
training -X- _ O
signals. -X- _ O
For -X- _ O
more -X- _ O
formal -X- _ O
analysis -X- _ O
and -X- _ O
further -X- _ O
discussion, -X- _ O
please -X- _ O
refer -X- _ O
to -X- _ O
Appendix -X- _ O
A.5. -X- _ O
3 -X- _ O
Experiments -X- _ O

Many -X- _ O
downstream -X- _ O
tasks -X- _ O
have -X- _ O
multiple -X- _ O
input -X- _ O
segments, -X- _ O
e.g., -X- _ O
a -X- _ O
question -X- _ O
and -X- _ O
a -X- _ O
context -X- _ O
paragraph -X- _ O
in -X- _ O
question -X- _ O
answering. -X- _ O
We -X- _ O
now -X- _ O
discuss -X- _ O
how -X- _ O
we -X- _ O
pretrain -X- _ O
XLNet -X- _ B-MethodName
to -X- _ O
model -X- _ O
multiple -X- _ O
segments -X- _ O
in -X- _ O
the -X- _ O
autoregressive -X- _ O
framework. -X- _ O
During -X- _ O
the -X- _ O
pretraining -X- _ O
phase, -X- _ O
following -X- _ O
BERT, -X- _ B-MethodName
we -X- _ O
randomly -X- _ O
sample -X- _ O
two -X- _ O
segments -X- _ O
(either -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
context -X- _ O
or -X- _ O
not) -X- _ O
and -X- _ O
treat -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
two -X- _ O
segments -X- _ O
as -X- _ O
one -X- _ O
sequence -X- _ O
to -X- _ O
perform -X- _ O
permutation -X- _ O
language -X- _ B-TaskName
modeling. -X- _ I-TaskName
We -X- _ O
only -X- _ O
reuse -X- _ O
the -X- _ O
memory -X- _ O
that -X- _ O
belongs -X- _ O
to -X- _ O
the -X- _ O
same -X- _ O
context. -X- _ O
Specifically, -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
BERT: -X- _ B-MethodName
[CLS, -X- _ O
A, -X- _ O
SEP, -X- _ O
B, -X- _ O
SEP], -X- _ O
where -X- _ O
"SEP" -X- _ O
and -X- _ O
"CLS" -X- _ O
are -X- _ O
two -X- _ O
special -X- _ O
symbols -X- _ O
and -X- _ O
"A" -X- _ O
and -X- _ O
"B" -X- _ O
are -X- _ O
the -X- _ O
two -X- _ O
segments. -X- _ O
Although -X- _ O
we -X- _ O
follow -X- _ O
the -X- _ O
two-segment -X- _ O
data -X- _ O
format, -X- _ O
XLNet-Large -X- _ B-MethodName
does -X- _ O
not -X- _ O
use -X- _ O
the -X- _ O
objective -X- _ O
of -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
as -X- _ O
it -X- _ O
does -X- _ O
not -X- _ O
show -X- _ O
consistent -X- _ O
improvement -X- _ O
in -X- _ O
our -X- _ O
ablation -X- _ O
study -X- _ O
(see -X- _ O
Section -X- _ O
3.4). -X- _ O
Relative -X- _ O
Segment -X- _ O
Encodings -X- _ O
Architecturally, -X- _ O
different -X- _ O
from -X- _ O
BERT -X- _ B-MethodName
that -X- _ O
adds -X- _ O
an -X- _ O
absolute -X- _ O
segment -X- _ O
embedding -X- _ O
to -X- _ O
the -X- _ O
word -X- _ O
embedding -X- _ O
at -X- _ O
each -X- _ O
position, -X- _ O
we -X- _ O
extend -X- _ O
the -X- _ O
idea -X- _ O
of -X- _ O
relative -X- _ O
encodings -X- _ O
from -X- _ O
Transformer-XL -X- _ O
to -X- _ O
also -X- _ O
encode -X- _ O
the -X- _ O
segments. -X- _ O
Given -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
positions -X- _ O
i -X- _ O
and -X- _ O
j -X- _ O
in -X- _ O
the -X- _ O
sequence, -X- _ O
if -X- _ O
i -X- _ O
and -X- _ O
j -X- _ O
are -X- _ O
from -X- _ O
the -X- _ O
same -X- _ O
segment, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
segment -X- _ O
encoding -X- _ O
s -X- _ O
ij -X- _ O
= -X- _ O
s -X- _ O
+ -X- _ O
or -X- _ O
otherwise -X- _ O
s -X- _ O
ij -X- _ O
= -X- _ O
s -X- _ O
− -X- _ O
, -X- _ O
where -X- _ O
s -X- _ O
+ -X- _ O
and -X- _ O
s -X- _ O
− -X- _ O
are -X- _ O
learnable -X- _ O
model -X- _ O
parameters -X- _ O
for -X- _ O
each -X- _ O
attention -X- _ O
head. -X- _ O
In -X- _ O
other -X- _ O
words, -X- _ O
we -X- _ O
only -X- _ O
consider -X- _ O
whether -X- _ O
the -X- _ O
two -X- _ O
positions -X- _ O
are -X- _ O
within -X- _ O
the -X- _ O
same -X- _ O
segment, -X- _ O
as -X- _ O
opposed -X- _ O
to -X- _ O
considering -X- _ O
which -X- _ O
specific -X- _ O
segments -X- _ O
they -X- _ O
are -X- _ O
from. -X- _ O
This -X- _ O
is -X- _ O
consistent -X- _ O
with -X- _ O
the -X- _ O
core -X- _ O
idea -X- _ O
of -X- _ O
relative -X- _ O
encodings; -X- _ O
i.e., -X- _ O
only -X- _ O
modeling -X- _ O
the -X- _ O
relationships -X- _ O
between -X- _ O
positions. -X- _ O
When -X- _ O
i -X- _ O
attends -X- _ O
to -X- _ O
j, -X- _ O
the -X- _ O
segment -X- _ O
encoding -X- _ O
s -X- _ O
ij -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
compute -X- _ O
an -X- _ O
attention -X- _ O
weight -X- _ O
a -X- _ O
ij -X- _ O
= -X- _ O
(q -X- _ O
i -X- _ O
+ -X- _ O
b) -X- _ O
s -X- _ O
ij -X- _ O
, -X- _ O
where -X- _ O
q -X- _ O
i -X- _ O
is -X- _ O
the -X- _ O
query -X- _ O
vector -X- _ O
as -X- _ O
in -X- _ O
a -X- _ O
standard -X- _ O
attention -X- _ O
operation -X- _ O
and -X- _ O
b -X- _ O
is -X- _ O
a -X- _ O
learnable -X- _ O
head-specific -X- _ O
bias -X- _ O
vector. -X- _ O
Finally, -X- _ O
the -X- _ O
value -X- _ O
a -X- _ O
ij -X- _ O
is -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
normal -X- _ O
attention -X- _ O
weight. -X- _ O
There -X- _ O
are -X- _ O
two -X- _ O
benefits -X- _ O
of -X- _ O
using -X- _ O
relative -X- _ O
segment -X- _ O
encodings. -X- _ O
First, -X- _ O
the -X- _ O
inductive -X- _ O
bias -X- _ O
of -X- _ O
relative -X- _ O
encodings -X- _ O
improves -X- _ O
generalization -X- _ O
. -X- _ O
Second, -X- _ O
it -X- _ O
opens -X- _ O
the -X- _ O
possibility -X- _ O
of -X- _ O
finetuning -X- _ O
on -X- _ O
tasks -X- _ O
that -X- _ O
have -X- _ O
more -X- _ O
than -X- _ O
two -X- _ O
input -X- _ O
segments, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
possible -X- _ O
using -X- _ O
absolute -X- _ O
segment -X- _ O
encodings. -X- _ O

Since -X- _ O
our -X- _ O
objective -X- _ O
function -X- _ O
fits -X- _ O
in -X- _ O
the -X- _ O
AR -X- _ O
framework, -X- _ O
we -X- _ O
incorporate -X- _ O
the -X- _ O
state-of-the-art -X- _ O
AR -X- _ O
language -X- _ O
model, -X- _ O
Transformer-XL -X- _ O
, -X- _ O
into -X- _ O
our -X- _ O
pretraining -X- _ O
framework, -X- _ O
and -X- _ O
name -X- _ O
our -X- _ O
method -X- _ O
after -X- _ O
it. -X- _ O
We -X- _ O
integrate -X- _ O
two -X- _ O
important -X- _ O
techniques -X- _ O
in -X- _ O
Transformer-XL, -X- _ O
namely -X- _ O
the -X- _ O
relative -X- _ O
positional -X- _ O
encoding -X- _ O
scheme -X- _ O
and -X- _ O
the -X- _ O
segment -X- _ O
recurrence -X- _ O
mechanism. -X- _ O
We -X- _ O
apply -X- _ O
relative -X- _ O
positional -X- _ O
encodings -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
sequence -X- _ O
as -X- _ O
discussed -X- _ O
earlier, -X- _ O
which -X- _ O
is -X- _ O
straightforward. -X- _ O
Now -X- _ O
we -X- _ O
discuss -X- _ O
how -X- _ O
to -X- _ O
integrate -X- _ O
the -X- _ O
recurrence -X- _ O
mechanism -X- _ O
into -X- _ O
the -X- _ O
proposed -X- _ O
permutation -X- _ O
setting -X- _ O
and -X- _ O
enable -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
reuse -X- _ O
hidden -X- _ O
states -X- _ O
from -X- _ O
previous -X- _ O
segments. -X- _ O
Without -X- _ O
loss -X- _ O
of -X- _ O
generality, -X- _ O
suppose -X- _ O
we -X- _ O
have -X- _ O
two -X- _ O
segments -X- _ O
taken -X- _ O
from -X- _ O
a -X- _ O
long -X- _ O
sequence -X- _ O
s; -X- _ O
i.e.,x -X- _ O
= -X- _ O
s -X- _ O
1:T -X- _ O
and -X- _ O
x -X- _ O
= -X- _ O
s -X- _ O
T -X- _ O
+1:2T -X- _ O
. -X- _ O
Letz -X- _ O
and -X- _ O
z -X- _ O
be -X- _ O
permutations -X- _ O
of -X- _ O
[1 -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
T -X- _ O
] -X- _ O
and -X- _ O
[T -X- _ O
+ -X- _ O
1 -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
2T -X- _ O
] -X- _ O
respectively. -X- _ O
Then, -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
permutationz, -X- _ O
we -X- _ O
process -X- _ O
the -X- _ O
first -X- _ O
segment, -X- _ O
and -X- _ O
then -X- _ O
cache -X- _ O
the -X- _ O
obtained -X- _ O
content -X- _ O
representationsh -X- _ O
(m) -X- _ O
for -X- _ O
each -X- _ O
layer -X- _ O
m. -X- _ O
Then, -X- _ O
for -X- _ O
the -X- _ O
next -X- _ O
segment -X- _ O
x, -X- _ O
the -X- _ O
attention -X- _ O
update -X- _ O
with -X- _ O
memory -X- _ O
can -X- _ O
be -X- _ O
written -X- _ O
as -X- _ O
h -X- _ O
(m) -X- _ O
zt -X- _ O
← -X- _ O
Attention(Q -X- _ O
= -X- _ O
h -X- _ O
(m−1) -X- _ O
zt -X- _ O
, -X- _ O
KV -X- _ O
= -X- _ O
h -X- _ O
(m−1) -X- _ O
, -X- _ O
h -X- _ O
(m−1) -X- _ O
z -X- _ O
≤t -X- _ O
; -X- _ O
θ) -X- _ O
where -X- _ O
[., -X- _ O
.] -X- _ O
denotes -X- _ O
concatenation -X- _ O
along -X- _ O
the -X- _ O
sequence -X- _ O
dimension. -X- _ O
Notice -X- _ O
that -X- _ O
positional -X- _ O
encodings -X- _ O
only -X- _ O
depend -X- _ O
on -X- _ O
the -X- _ O
actual -X- _ O
positions -X- _ O
in -X- _ O
the -X- _ O
original -X- _ O
sequence. -X- _ O
Thus, -X- _ O
the -X- _ O
above -X- _ O
attention -X- _ O
update -X- _ O
is -X- _ O
independent -X- _ O
ofz -X- _ O
once -X- _ O
the -X- _ O
representationsh -X- _ O
(m) -X- _ O
are -X- _ O
obtained. -X- _ O
This -X- _ O
allows -X- _ O
caching -X- _ O
and -X- _ O
reusing -X- _ O
the -X- _ O
memory -X- _ O
without -X- _ O
knowing -X- _ O
the -X- _ O
factorization -X- _ O
order -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
segment. -X- _ O
In -X- _ O
expectation, -X- _ O
the -X- _ O
model -X- _ O
learns -X- _ O
to -X- _ O
utilize -X- _ O
the -X- _ O
memory -X- _ O
over -X- _ O
all -X- _ O
factorization -X- _ O
orders -X- _ O
of -X- _ O
the -X- _ O
last -X- _ O
segment. -X- _ O
The -X- _ O
query -X- _ O
stream -X- _ O
can -X- _ O
be -X- _ O
computed -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
way. -X- _ O
Finally, -X- _ O
Figure -X- _ O
1 -X- _ O
(c) -X- _ O
presents -X- _ O
an -X- _ O
overview -X- _ O
of -X- _ O
the -X- _ O
proposed -X- _ O
permutation -X- _ O
language -X- _ O
modeling -X- _ O
with -X- _ O
two-stream -X- _ O
attention -X- _ O
(see -X- _ O
Appendix -X- _ O
A.7 -X- _ O
for -X- _ O
more -X- _ O
detailed -X- _ O
illustration). -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
first -X- _ O
review -X- _ O
and -X- _ O
compare -X- _ O
the -X- _ O
conventional -X- _ O
AR -X- _ O
language -X- _ O
modeling -X- _ O
and -X- _ O
BERT -X- _ O
for -X- _ O
language -X- _ O
pretraining. -X- _ O
Given -X- _ O
a -X- _ O
text -X- _ O
sequence -X- _ O
x -X- _ O
= -X- _ O
[x -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
x -X- _ O
T -X- _ O
], -X- _ O
AR -X- _ O
language -X- _ O
modeling -X- _ O
performs -X- _ O
pretraining -X- _ O
by -X- _ O
maximizing -X- _ O
the -X- _ O
likelihood -X- _ O
under -X- _ O
the -X- _ O
forward -X- _ O
autoregressive -X- _ O
factorization: -X- _ O
max -X- _ O
θ -X- _ O
log -X- _ O
p -X- _ O
θ -X- _ O
(x) -X- _ O
= -X- _ O
T -X- _ O
t=1 -X- _ O
log -X- _ O
p -X- _ O
θ -X- _ O
(x -X- _ O
t -X- _ O
| -X- _ O
x -X- _ O
<t -X- _ O
) -X- _ O
= -X- _ O
T -X- _ O
t=1 -X- _ O
log -X- _ O
exp -X- _ O
h -X- _ O
θ -X- _ O
(x -X- _ O
1:t−1 -X- _ O
) -X- _ O
e(x -X- _ O
t -X- _ O
) -X- _ O
x -X- _ O
exp -X- _ O
(h -X- _ O
θ -X- _ O
(x -X- _ O
1:t−1 -X- _ O
) -X- _ O
e(x -X- _ O
)) -X- _ O
,(1) -X- _ O
where -X- _ O
h -X- _ O
θ -X- _ O
(x -X- _ O
1:t−1 -X- _ O
) -X- _ O
is -X- _ O
a -X- _ O
context -X- _ O
representation -X- _ O
produced -X- _ O
by -X- _ O
neural -X- _ O
models, -X- _ O
such -X- _ O
as -X- _ O
RNNs -X- _ O
or -X- _ O
Transformers, -X- _ O
and -X- _ O
e(x) -X- _ O
denotes -X- _ O
the -X- _ O
embedding -X- _ O
of -X- _ O
x. -X- _ O
In -X- _ O
comparison, -X- _ O
BERT -X- _ O
is -X- _ O
based -X- _ O
on -X- _ O
denoising -X- _ O
auto-encoding. -X- _ O
Specifically, -X- _ O
for -X- _ O
a -X- _ O
text -X- _ O
sequence -X- _ O
x, -X- _ O
BERT -X- _ O
first -X- _ O
constructs -X- _ O
a -X- _ O
corrupted -X- _ O
versionx -X- _ O
by -X- _ O
randomly -X- _ O
setting -X- _ O
a -X- _ O
portion -X- _ O
(e.g. -X- _ O
15%) -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
x -X- _ O
to -X- _ O
a -X- _ O
special -X- _ O
symbol -X- _ O
[MASK]. -X- _ O
Let -X- _ O
the -X- _ O
masked -X- _ O
tokens -X- _ O
bex. -X- _ O
The -X- _ O
training -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
reconstructx -X- _ O
fromx: -X- _ O
max -X- _ O
θ -X- _ O
log -X- _ O
p -X- _ O
θ -X- _ O
(x -X- _ O
|x) -X- _ O
≈ -X- _ O
T -X- _ O
t=1 -X- _ O
m -X- _ O
t -X- _ O
log -X- _ O
p -X- _ O
θ -X- _ O
(x -X- _ O
t -X- _ O
|x) -X- _ O
= -X- _ O
T -X- _ O
t=1 -X- _ O
m -X- _ O
t -X- _ O
log -X- _ O
exp -X- _ O
H -X- _ O
θ -X- _ O
(x) -X- _ O
t -X- _ O
e(x -X- _ O
t -X- _ O
) -X- _ O
x -X- _ O
exp -X- _ O
H -X- _ O
θ -X- _ O
(x) -X- _ O
t -X- _ O
e(x -X- _ O
) -X- _ O
,(2) -X- _ O
where -X- _ O
m -X- _ O
t -X- _ O
= -X- _ O
1 -X- _ O
indicates -X- _ O
x -X- _ O
t -X- _ O
is -X- _ O
masked, -X- _ O
and -X- _ O
H -X- _ O
θ -X- _ O
is -X- _ O
a -X- _ O
Transformer -X- _ O
that -X- _ O
maps -X- _ O
a -X- _ O
length-T -X- _ O
text -X- _ O
sequence -X- _ O
x -X- _ O
into -X- _ O
a -X- _ O
sequence -X- _ O
of -X- _ O
hidden -X- _ O
vectors -X- _ O
H -X- _ O
θ -X- _ O
(x) -X- _ O
= -X- _ O
[H -X- _ O
θ -X- _ O
(x) -X- _ O
1 -X- _ O
, -X- _ O
H -X- _ O
θ -X- _ O
(x) -X- _ O
2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
H -X- _ O
θ -X- _ O
(x) -X- _ O
T -X- _ O
]. -X- _ O
The -X- _ O
pros -X- _ O
and -X- _ O
cons -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
pretraining -X- _ O
objectives -X- _ O
are -X- _ O
compared -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
aspects: -X- _ O
• -X- _ O
Independence -X- _ O
Assumption: -X- _ O
As -X- _ O
emphasized -X- _ O
by -X- _ O
the -X- _ O
≈ -X- _ O
sign -X- _ O
in -X- _ O
Eq. -X- _ O
(2), -X- _ O
BERT -X- _ O
factorizes -X- _ O
the -X- _ O
joint -X- _ O
conditional -X- _ O
probability -X- _ O
p(x -X- _ O
|x) -X- _ O
based -X- _ O
on -X- _ O
an -X- _ O
independence -X- _ O
assumption -X- _ O
that -X- _ O
all -X- _ O
masked -X- _ O
tokensx -X- _ O
are -X- _ O
separately -X- _ O
reconstructed. -X- _ O
In -X- _ O
comparison, -X- _ O
the -X- _ O
AR -X- _ O
language -X- _ O
modeling -X- _ O
objective -X- _ O
(1) -X- _ O
factorizes -X- _ O
p -X- _ O
θ -X- _ O
(x) -X- _ O
using -X- _ O
the -X- _ O
product -X- _ O
rule -X- _ O
that -X- _ O
holds -X- _ O
universally -X- _ O
without -X- _ O
such -X- _ O
an -X- _ O
independence -X- _ O
assumption. -X- _ O
• -X- _ O
Input -X- _ O
noise: -X- _ O
The -X- _ O
input -X- _ O
to -X- _ O
BERT -X- _ O
contains -X- _ O
artificial -X- _ O
symbols -X- _ O
like -X- _ O
[MASK] -X- _ O
that -X- _ O
never -X- _ O
occur -X- _ O
in -X- _ O
downstream -X- _ O
tasks, -X- _ O
which -X- _ O
creates -X- _ O
a -X- _ O
pretrain-finetune -X- _ O
discrepancy. -X- _ O
Replacing -X- _ O
[MASK] -X- _ O
with -X- _ O
original -X- _ O
tokens -X- _ O
as -X- _ O
in -X- _ O
does -X- _ O
not -X- _ O
solve -X- _ O
the -X- _ O
problem -X- _ O
because -X- _ O
original -X- _ O
tokens -X- _ O
can -X- _ O
be -X- _ O
only -X- _ O
used -X- _ O
with -X- _ O
a -X- _ O
small -X- _ O
probability -X- _ O
-otherwise -X- _ O
Eq. -X- _ O
(2) -X- _ O
will -X- _ O
be -X- _ O
trivial -X- _ O
to -X- _ O
optimize. -X- _ O
In -X- _ O
comparison, -X- _ O
AR -X- _ O
language -X- _ O
modeling -X- _ O
does -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
any -X- _ O
input -X- _ O
corruption -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
suffer -X- _ O
from -X- _ O
this -X- _ O
issue. -X- _ O
• -X- _ O
Context -X- _ O
dependency: -X- _ O
The -X- _ O
AR -X- _ O
representation -X- _ O
h -X- _ O
θ -X- _ O
(x -X- _ O
1:t−1 -X- _ O
) -X- _ O
is -X- _ O
only -X- _ O
conditioned -X- _ O
on -X- _ O
the -X- _ O
tokens -X- _ O
up -X- _ O
to -X- _ O
position -X- _ O
t -X- _ O
(i.e. -X- _ O
tokens -X- _ O
to -X- _ O
the -X- _ O
left), -X- _ O
while -X- _ O
the -X- _ O
BERT -X- _ O
representation -X- _ O
H -X- _ O
θ -X- _ O
(x) -X- _ O
t -X- _ O
has -X- _ O
access -X- _ O
to -X- _ O
the -X- _ O
contextual -X- _ O
information -X- _ O
on -X- _ O
both -X- _ O
sides. -X- _ O
As -X- _ O
a -X- _ O
result, -X- _ O
the -X- _ O
BERT -X- _ O
objective -X- _ O
allows -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
be -X- _ O
pretrained -X- _ O
to -X- _ O
better -X- _ O
capture -X- _ O
bidirectional -X- _ O
context. -X- _ O

The -X- _ O
idea -X- _ O
of -X- _ O
permutation-based -X- _ O
AR -X- _ B-TaskName
modeling -X- _ I-TaskName
has -X- _ O
been -X- _ O
explored -X- _ O
in -X- _ O
, -X- _ O
but -X- _ O
there -X- _ O
are -X- _ O
several -X- _ O
key -X- _ O
differences. -X- _ O
Firstly, -X- _ O
previous -X- _ O
models -X- _ O
aim -X- _ O
to -X- _ O
improve -X- _ O
density -X- _ O
estimation -X- _ O
by -X- _ O
baking -X- _ O
an -X- _ O
"orderless" -X- _ O
inductive -X- _ O
bias -X- _ O
into -X- _ O
the -X- _ O
model -X- _ O
while -X- _ O
XLNet -X- _ B-MethodName
is -X- _ O
motivated -X- _ O
by -X- _ O
enabling -X- _ O
AR -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
learn -X- _ O
bidirectional -X- _ O
contexts. -X- _ O
Technically, -X- _ O
to -X- _ O
construct -X- _ O
a -X- _ O
valid -X- _ O
target-aware -X- _ O
prediction -X- _ O
distribution, -X- _ O
XLNet -X- _ B-MethodName
incorporates -X- _ O
the -X- _ O
target -X- _ O
position -X- _ O
into -X- _ O
the -X- _ O
hidden -X- _ O
state -X- _ O
via -X- _ O
two-stream -X- _ O
attention -X- _ O
while -X- _ O
previous -X- _ O
permutation-based -X- _ O
AR -X- _ O
models -X- _ O
relied -X- _ O
on -X- _ O
implicit -X- _ O
position -X- _ O
awareness -X- _ O
inherent -X- _ O
to -X- _ O
their -X- _ O
MLP -X- _ O
architectures. -X- _ O
Finally, -X- _ O
for -X- _ O
both -X- _ O
orderless -X- _ O
NADE -X- _ O
and -X- _ O
XLNet, -X- _ B-MethodName
we -X- _ O
would -X- _ O
like -X- _ O
to -X- _ O
emphasize -X- _ O
that -X- _ O
"orderless" -X- _ O
does -X- _ O
not -X- _ O
mean -X- _ O
that -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
can -X- _ O
be -X- _ O
randomly -X- _ O
permuted -X- _ O
but -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
allows -X- _ O
for -X- _ O
different -X- _ O
factorization -X- _ O
orders -X- _ O
of -X- _ O
the -X- _ O
distribution. -X- _ O
Another -X- _ O
related -X- _ O
idea -X- _ O
is -X- _ O
to -X- _ O
perform -X- _ O
autoregressive -X- _ O
denoising -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
text -X- _ O
generation -X- _ O
, -X- _ O
which -X- _ O
only -X- _ O
considers -X- _ O
a -X- _ O
fixed -X- _ O
order -X- _ O
though. -X- _ O
2 -X- _ O
Proposed -X- _ O
Method -X- _ O

Unsupervised -X- _ O
representation -X- _ O
learning -X- _ O
has -X- _ O
been -X- _ O
highly -X- _ O
successful -X- _ O
in -X- _ O
the -X- _ O
domain -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
. -X- _ O
Typically, -X- _ O
these -X- _ O
methods -X- _ O
first -X- _ O
pretrain -X- _ O
neural -X- _ O
networks -X- _ O
on -X- _ O
large-scale -X- _ O
unlabeled -X- _ O
text -X- _ O
corpora, -X- _ O
and -X- _ O
then -X- _ O
finetune -X- _ O
the -X- _ O
models -X- _ O
or -X- _ O
representations -X- _ O
on -X- _ O
downstream -X- _ O
tasks. -X- _ O
Under -X- _ O
this -X- _ O
shared -X- _ O
high-level -X- _ O
idea, -X- _ O
different -X- _ O
unsupervised -X- _ O
pretraining -X- _ O
objectives -X- _ O
have -X- _ O
been -X- _ O
explored -X- _ O
in -X- _ O
literature. -X- _ O
Among -X- _ O
them, -X- _ O
autoregressive -X- _ B-TaskName
(AR) -X- _ B-TaskName
language -X- _ B-TaskName
modeling -X- _ I-TaskName
and -X- _ O
autoencoding -X- _ B-TaskName
(AE) -X- _ B-TaskName
have -X- _ O
been -X- _ O
the -X- _ O
two -X- _ O
most -X- _ O
successful -X- _ O
pretraining -X- _ O
objectives. -X- _ O
AR -X- _ B-TaskName
language -X- _ I-TaskName
modeling -X- _ I-TaskName
seeks -X- _ O
to -X- _ O
estimate -X- _ O
the -X- _ O
probability -X- _ O
distribution -X- _ O
of -X- _ O
a -X- _ O
text -X- _ O
corpus -X- _ O
with -X- _ O
an -X- _ O
autoregressive -X- _ O
model -X- _ O
. -X- _ O
Specifically, -X- _ O
given -X- _ O
a -X- _ O
text -X- _ O
sequence -X- _ O
x -X- _ O
= -X- _ O
(x -X- _ O
1 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
x -X- _ O
T -X- _ O
), -X- _ O
AR -X- _ B-TaskName
language -X- _ I-TaskName
modeling -X- _ I-TaskName
factorizes -X- _ O
the -X- _ O
likelihood -X- _ O
into -X- _ O
a -X- _ O
forward -X- _ O
product -X- _ O
p(x) -X- _ O
= -X- _ O
T -X- _ O
t=1 -X- _ O
p(x -X- _ O
t -X- _ O
| -X- _ O
x -X- _ O
<t -X- _ O
) -X- _ O
or -X- _ O
a -X- _ O
backward -X- _ O
one -X- _ O
p(x) -X- _ O
= -X- _ O
1 -X- _ O
t=T -X- _ O
p(x -X- _ O
t -X- _ O
| -X- _ O
x -X- _ O
>t -X- _ O
). -X- _ O
A -X- _ O
parametric -X- _ O
model -X- _ O
(e.g. -X- _ O
a -X- _ O
neural -X- _ O
network) -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
model -X- _ O
each -X- _ O
conditional -X- _ O
distribution. -X- _ O
Since -X- _ O
an -X- _ O
AR -X- _ O
language -X- _ O
model -X- _ O
is -X- _ O
only -X- _ O
trained -X- _ O
to -X- _ O
encode -X- _ O
a -X- _ O
uni-directional -X- _ O
context -X- _ O
(either -X- _ O
forward -X- _ O
or -X- _ O
backward), -X- _ O
it -X- _ O
is -X- _ O
not -X- _ O
effective -X- _ O
at -X- _ O
modeling -X- _ O
deep -X- _ O
bidirectional -X- _ O
contexts. -X- _ O
On -X- _ O
the -X- _ O
contrary, -X- _ O
downstream -X- _ O
language -X- _ O
understanding -X- _ O
tasks -X- _ O
often -X- _ O
require -X- _ O
bidirectional -X- _ O
context -X- _ O
information. -X- _ O
This -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
gap -X- _ O
between -X- _ O
AR -X- _ O
language -X- _ O
modeling -X- _ O
and -X- _ O
effective -X- _ O
pretraining. -X- _ O
In -X- _ O
comparison, -X- _ O
AE -X- _ O
based -X- _ O
pretraining -X- _ O
does -X- _ O
not -X- _ O
perform -X- _ O
explicit -X- _ O
density -X- _ O
estimation -X- _ O
but -X- _ O
instead -X- _ O
aims -X- _ O
to -X- _ O
reconstruct -X- _ O
the -X- _ O
original -X- _ O
data -X- _ O
from -X- _ O
corrupted -X- _ O
input. -X- _ O
A -X- _ O
notable -X- _ O
example -X- _ O
is -X- _ O
BERT -X- _ B-MethodName
, -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
the -X- _ O
state-of-the-art -X- _ O
pretraining -X- _ O
approach. -X- _ O
Given -X- _ O
the -X- _ O
input -X- _ O
token -X- _ O
sequence, -X- _ O
a -X- _ O
certain -X- _ O
portion -X- _ O
of -X- _ O
tokens -X- _ O
are -X- _ O
replaced -X- _ O
by -X- _ O
a -X- _ O
special -X- _ O
symbol -X- _ O
[MASK], -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
to -X- _ O
recover -X- _ O
the -X- _ O
original -X- _ O
tokens -X- _ O
from -X- _ O
the -X- _ O
corrupted -X- _ O
version. -X- _ O
Since -X- _ O
density -X- _ O
estimation -X- _ O
is -X- _ O
not -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
objective, -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
allowed -X- _ O
to -X- _ O
utilize -X- _ O
bidirectional -X- _ O
contexts -X- _ O
for -X- _ O
reconstruction. -X- _ O
As -X- _ O
an -X- _ O
immediate -X- _ O
benefit, -X- _ O
this -X- _ O
closes -X- _ O
the -X- _ O
aforementioned -X- _ O
bidirectional -X- _ O
information -X- _ O
gap -X- _ O
in -X- _ O
AR -X- _ O
language -X- _ O
modeling, -X- _ O
leading -X- _ O
to -X- _ O
improved -X- _ O
performance. -X- _ O
However, -X- _ O
the -X- _ O
artificial -X- _ O
symbols -X- _ O
like -X- _ O
[MASK] -X- _ O
used -X- _ O
by -X- _ O
BERT -X- _ B-MethodName
during -X- _ O
pretraining -X- _ O
are -X- _ O
absent -X- _ O
from -X- _ O
real -X- _ O
data -X- _ O
at -X- _ O
finetuning -X- _ O
time, -X- _ O
resulting -X- _ O
in -X- _ O
a -X- _ O
pretrain-finetune -X- _ O
discrepancy. -X- _ O
Moreover, -X- _ O
since -X- _ O
the -X- _ O
predicted -X- _ O
tokens -X- _ O
are -X- _ O
masked -X- _ O
in -X- _ O
the -X- _ O
input, -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
not -X- _ O
able -X- _ O
to -X- _ O
model -X- _ O
the -X- _ O
joint -X- _ O
probability -X- _ O
using -X- _ O
the -X- _ O
product -X- _ O
rule -X- _ O
as -X- _ O
in -X- _ O
AR -X- _ O
language -X- _ O
modeling. -X- _ O
In -X- _ O
other -X- _ O
words, -X- _ O
BERT -X- _ B-MethodName
assumes -X- _ O
the -X- _ O
predicted -X- _ O
tokens -X- _ O
are -X- _ O
independent -X- _ O
of -X- _ O
each -X- _ O
other -X- _ O
given -X- _ O
the -X- _ O
unmasked -X- _ O
tokens, -X- _ O
which -X- _ O
is -X- _ O
oversimplified -X- _ O
as -X- _ O
high-order, -X- _ O
long-range -X- _ O
dependency -X- _ O
is -X- _ O
prevalent -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
. -X- _ O
Faced -X- _ O
with -X- _ O
the -X- _ O
pros -X- _ O
and -X- _ O
cons -X- _ O
of -X- _ O
existing -X- _ O
language -X- _ O
pretraining -X- _ O
objectives, -X- _ O
in -X- _ O
this -X- _ O
work, -X- _ O
we -X- _ O
propose -X- _ O
XLNet, -X- _ B-MethodName
a -X- _ O
generalized -X- _ O
autoregressive -X- _ O
method -X- _ O
that -X- _ O
leverages -X- _ O
the -X- _ O
best -X- _ O
of -X- _ O
both -X- _ O
AR -X- _ B-TaskName
language -X- _ I-TaskName
modeling -X- _ I-TaskName
and -X- _ O
AE -X- _ B-TaskName
while -X- _ O
avoiding -X- _ O
their -X- _ O
limitations. -X- _ O
• -X- _ O
Firstly, -X- _ O
instead -X- _ O
of -X- _ O
using -X- _ O
a -X- _ O
fixed -X- _ O
forward -X- _ O
or -X- _ O
backward -X- _ O
factorization -X- _ O
order -X- _ O
as -X- _ O
in -X- _ O
conventional -X- _ O
AR -X- _ O
models, -X- _ O
XLNet -X- _ B-MethodName
maximizes -X- _ O
the -X- _ O
expected -X- _ O
log -X- _ O
likelihood -X- _ O
of -X- _ O
a -X- _ O
sequence -X- _ O
w.r.t. -X- _ O
all -X- _ O
possible -X- _ O
permutations -X- _ O
of -X- _ O
the -X- _ O
factorization -X- _ O
order. -X- _ O
Thanks -X- _ O
to -X- _ O
the -X- _ O
permutation -X- _ O
operation, -X- _ O
the -X- _ O
context -X- _ O
for -X- _ O
each -X- _ O
position -X- _ O
can -X- _ O
consist -X- _ O
of -X- _ O
tokens -X- _ O
from -X- _ O
both -X- _ O
left -X- _ O
and -X- _ O
right. -X- _ O
In -X- _ O
expectation, -X- _ O
each -X- _ O
position -X- _ O
learns -X- _ O
to -X- _ O
utilize -X- _ O
contextual -X- _ O
information -X- _ O
from -X- _ O
all -X- _ O
positions, -X- _ O
i.e., -X- _ O
capturing -X- _ O
bidirectional -X- _ O
context. -X- _ O
• -X- _ O
Secondly, -X- _ O
as -X- _ O
a -X- _ O
generalized -X- _ O
AR -X- _ O
language -X- _ O
model, -X- _ O
XLNet -X- _ B-MethodName
does -X- _ O
not -X- _ O
rely -X- _ O
on -X- _ O
data -X- _ O
corruption. -X- _ O
Hence, -X- _ O
XLNet -X- _ B-MethodName
does -X- _ O
not -X- _ O
suffer -X- _ O
from -X- _ O
the -X- _ O
pretrain-finetune -X- _ O
discrepancy -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
subject -X- _ O
to. -X- _ O
Meanwhile, -X- _ O
the -X- _ O
autoregressive -X- _ O
objective -X- _ O
also -X- _ O
provides -X- _ O
a -X- _ O
natural -X- _ O
way -X- _ O
to -X- _ O
use -X- _ O
the -X- _ O
product -X- _ O
rule -X- _ O
for -X- _ O
factorizing -X- _ O
the -X- _ O
joint -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
predicted -X- _ O
tokens, -X- _ O
eliminating -X- _ O
the -X- _ O
independence -X- _ O
assumption -X- _ O
made -X- _ O
in -X- _ O
BERT. -X- _ B-MethodName
In -X- _ O
addition -X- _ O
to -X- _ O
a -X- _ O
novel -X- _ O
pretraining -X- _ O
objective, -X- _ O
XLNet -X- _ B-MethodName
improves -X- _ O
architectural -X- _ O
designs -X- _ O
for -X- _ O
pretraining. -X- _ O
• -X- _ O
Inspired -X- _ O
by -X- _ O
the -X- _ O
latest -X- _ O
advancements -X- _ O
in -X- _ O
AR -X- _ O
language -X- _ O
modeling, -X- _ O
XLNet -X- _ B-MethodName
integrates -X- _ O
the -X- _ O
segment -X- _ O
recurrence -X- _ O
mechanism -X- _ O
and -X- _ O
relative -X- _ O
encoding -X- _ O
scheme -X- _ O
of -X- _ O
Transformer-XL -X- _ O
into -X- _ O
pretraining, -X- _ O
which -X- _ O
empirically -X- _ O
improves -X- _ O
the -X- _ O
performance -X- _ O
especially -X- _ O
for -X- _ O
tasks -X- _ O
involving -X- _ O
a -X- _ O
longer -X- _ O
text -X- _ O
sequence. -X- _ O
• -X- _ O
Naively -X- _ O
applying -X- _ O
a -X- _ O
Transformer(-XL) -X- _ O
architecture -X- _ O
to -X- _ O
permutation-based -X- _ O
language -X- _ O
modeling -X- _ O
does -X- _ O
not -X- _ O
work -X- _ O
because -X- _ O
the -X- _ O
factorization -X- _ O
order -X- _ O
is -X- _ O
arbitrary -X- _ O
and -X- _ O
the -X- _ O
target -X- _ O
is -X- _ O
ambiguous. -X- _ O
As -X- _ O
a -X- _ O
solution, -X- _ O
we -X- _ O
propose -X- _ O
to -X- _ O
reparameterize -X- _ O
the -X- _ O
Transformer(-XL) -X- _ O
network -X- _ O
to -X- _ O
remove -X- _ O
the -X- _ O
ambiguity. -X- _ O
Empirically, -X- _ O
under -X- _ O
comparable -X- _ O
experiment -X- _ O
setting, -X- _ O
XLNet -X- _ B-MethodName
consistently -X- _ O
outperforms -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
a -X- _ O
wide -X- _ O
spectrum -X- _ O
of -X- _ O
problems -X- _ O
including -X- _ O
GLUE -X- _ B-DatasetName
language -X- _ B-TaskName
understanding -X- _ I-TaskName
tasks, -X- _ O
reading -X- _ B-TaskName
comprehension -X- _ I-TaskName
tasks -X- _ O
like -X- _ O
SQuAD -X- _ B-DatasetName
and -X- _ O
RACE, -X- _ B-DatasetName
text -X- _ B-TaskName
classification -X- _ I-TaskName
tasks -X- _ O
such -X- _ O
as -X- _ O
Yelp -X- _ B-DatasetName
and -X- _ O
IMDB, -X- _ B-DatasetName
and -X- _ O
the -X- _ O
ClueWeb09-B -X- _ B-DatasetName
document -X- _ B-TaskName
ranking -X- _ I-TaskName
task. -X- _ O

With -X- _ O
the -X- _ O
capability -X- _ O
of -X- _ O
modeling -X- _ O
bidirectional -X- _ O
contexts, -X- _ O
denoising -X- _ O
autoencoding -X- _ O
based -X- _ O
pretraining -X- _ O
like -X- _ O
BERT -X- _ B-MethodName
achieves -X- _ O
better -X- _ O
performance -X- _ O
than -X- _ O
pretraining -X- _ O
approaches -X- _ O
based -X- _ O
on -X- _ O
autoregressive -X- _ O
language -X- _ O
modeling. -X- _ O
However, -X- _ O
relying -X- _ O
on -X- _ O
corrupting -X- _ O
the -X- _ O
input -X- _ O
with -X- _ O
masks, -X- _ O
BERT -X- _ B-MethodName
neglects -X- _ O
dependency -X- _ O
between -X- _ O
the -X- _ O
masked -X- _ O
positions -X- _ O
and -X- _ O
suffers -X- _ O
from -X- _ O
a -X- _ O
pretrain-finetune -X- _ O
discrepancy. -X- _ O
In -X- _ O
light -X- _ O
of -X- _ O
these -X- _ O
pros -X- _ O
and -X- _ O
cons, -X- _ O
we -X- _ O
propose -X- _ O
XLNet, -X- _ B-MethodName
a -X- _ O
generalized -X- _ O
autoregressive -X- _ O
pretraining -X- _ O
method -X- _ O
that -X- _ O
(1) -X- _ O
enables -X- _ O
learning -X- _ O
bidirectional -X- _ O
contexts -X- _ O
by -X- _ O
maximizing -X- _ O
the -X- _ O
expected -X- _ O
likelihood -X- _ O
over -X- _ O
all -X- _ O
permutations -X- _ O
of -X- _ O
the -X- _ O
factorization -X- _ O
order -X- _ O
and -X- _ O
(2) -X- _ O
overcomes -X- _ O
the -X- _ O
limitations -X- _ O
of -X- _ O
BERT -X- _ O
thanks -X- _ O
to -X- _ O
its -X- _ O
autoregressive -X- _ O
formulation. -X- _ O
Furthermore, -X- _ O
XLNet -X- _ B-MethodName
integrates -X- _ O
ideas -X- _ O
from -X- _ O
Transformer-XL, -X- _ O
the -X- _ O
state-of-the-art -X- _ O
autoregressive -X- _ O
model, -X- _ O
into -X- _ O
pretraining. -X- _ O
Empirically, -X- _ O
under -X- _ O
comparable -X- _ O
experiment -X- _ O
settings, -X- _ O
XLNet -X- _ B-MethodName
outperforms -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
20 -X- _ O
tasks, -X- _ O
often -X- _ O
by -X- _ O
a -X- _ O
large -X- _ O
margin, -X- _ O
including -X- _ O
question -X- _ B-TaskName
answering, -X- _ I-TaskName
natural -X- _ B-TaskName
language -X- _ I-TaskName
inference, -X- _ I-TaskName
sentiment -X- _ B-TaskName
analysis, -X- _ I-TaskName
and -X- _ O
document -X- _ B-TaskName
ranking. -X- _ I-TaskName
1 -X- _ O
. -X- _ O


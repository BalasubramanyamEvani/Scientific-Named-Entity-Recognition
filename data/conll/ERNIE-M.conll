-DOCSTART- -X- O
Table -X- _ O
16 -X- _ O
shows -X- _ O
the -X- _ O
details -X- _ O
of -X- _ O
accuracy -X- _ O
on -X- _ O
each -X- _ O
language -X- _ O
in -X- _ O
the -X- _ O
cross-lingual -X- _ O
retrieval -X- _ O
task. -X- _ O
For -X- _ O
a -X- _ O
fair -X- _ O
comparison -X- _ O
with -X- _ O
VECO, -X- _ B-MethodName
we -X- _ O
use -X- _ O
the -X- _ O
averaged -X- _ O
representation -X- _ O
in -X- _ O
the -X- _ O
middle -X- _ O
layer -X- _ O
of -X- _ O
best -X- _ O
XNLI -X- _ B-DatasetName
model -X- _ O
for -X- _ O
cross-lingual -X- _ B-TaskName
retrieval -X- _ I-TaskName
task. -X- _ O
ERNIE-M -X- _ B-MethodName
outperforms -X- _ O
VECO -X- _ B-MethodName
in -X- _ O
most -X- _ O
languages -X- _ O
and -X- _ O
achieves -X- _ O
state-of-the-art -X- _ O
results. -X- _ O
We -X- _ O
also -X- _ O
proposed -X- _ O
a -X- _ O
new -X- _ O
method -X- _ O
for -X- _ O
cross-lingual -X- _ B-TaskName
retrieval. -X- _ I-TaskName
We -X- _ O
use -X- _ O
hardest -X- _ O
negative -X- _ B-MetricName
binary -X- _ I-MetricName
cross-entropy -X- _ I-MetricName
loss -X- _ I-MetricName
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2019b;Faghri -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
to -X- _ O
fine-tune -X- _ O
ERNIE-M -X- _ B-MethodName
with -X- _ O
the -X- _ O
same -X- _ O
bilingual -X- _ O
corpora -X- _ O
in -X- _ O
pre-training. -X- _ O

To -X- _ O
better -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
ERNIE-M, -X- _ B-MethodName
we -X- _ O
train -X- _ O
the -X- _ O
ERNIE-M-15 -X- _ B-MethodName
model -X- _ O
for -X- _ O
15 -X- _ O
languages. -X- _ O
The -X- _ O
languages -X- _ O
of -X- _ O
training -X- _ O
corpora -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
that -X- _ O
of -X- _ O
HICTL -X- _ B-MethodName
. -X- _ O
We -X- _ O
evaluate -X- _ O
ERNIE-M-15 -X- _ B-MethodName
on -X- _ O
the -X- _ O
XNLI -X- _ B-DatasetName
dataset. -X- _ O
Table -X- _ O
15 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
15 -X- _ O
languages -X- _ O
models. -X- _ O
The -X- _ O
ERNIE-M-15 -X- _ B-MethodName
model -X- _ O
outperforms -X- _ O
the -X- _ O
current -X- _ O
best -X- _ O
15-language -X- _ O
cross-lingual -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
XNLI -X- _ B-DatasetName
task, -X- _ O
achieving -X- _ O
a -X- _ O
score -X- _ B-MetricName
of -X- _ O
77.5 -X- _ B-MetricValue
in -X- _ O
the -X- _ O
cross-lingual -X- _ O
transfer -X- _ O
setting, -X- _ O
outperforming -X- _ O
HICTL -X- _ B-MethodName
0.2 -X- _ B-MetricValue
and -X- _ O
a -X- _ O
score -X- _ B-MetricName
of -X- _ O
80.7 -X- _ B-MetricValue
in -X- _ O
the -X- _ O
translate-train-all -X- _ O
setting, -X- _ O
outperforming -X- _ O
HICTL -X- _ B-MethodName
0.7. -X- _ B-MetricValue

Tables -X- _ O
12 -X- _ O
and -X- _ O
13 -X- _ O
list -X- _ O
the -X- _ O
fine-tuning -X- _ O
parameters -X- _ O
on -X- _ O
XNLI, -X- _ B-DatasetName
MLQA, -X- _ B-DatasetName
CoNLL -X- _ B-DatasetName
and -X- _ O
PAWS-X. -X- _ B-DatasetName
For -X- _ O
each -X- _ O
task, -X- _ O
we -X- _ O
select -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
the -X- _ O
best -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
validation -X- _ O
set, -X- _ O
and -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
score -X- _ O
is -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
five -X- _ O
runs -X- _ O
with -X- _ O
different -X- _ O
random -X- _ O
seeds. -X- _ O
Tables -X- _ O
14 -X- _ O
list -X- _ O
the -X- _ O
fine-tuning -X- _ O
parameters -X- _ O
on -X- _ O
Tatoeba. -X- _ O


We -X- _ O
follow -X- _ O

To -X- _ O
learn -X- _ O
the -X- _ O
alignment -X- _ O
of -X- _ O
cross-lingual -X- _ O
semantic -X- _ O
representations -X- _ O
in -X- _ O
parallel -X- _ O
corpora, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
pre-training -X- _ O
objective, -X- _ O
CAMLM. -X- _ B-TaskName
We -X- _ O
denote -X- _ O
a -X- _ O
parallel -X- _ O
sentence -X- _ O
pair -X- _ O
as -X- _ O
<source -X- _ O
sentence, -X- _ O
target -X- _ O
sentence>. -X- _ O
In -X- _ O
CAMLM, -X- _ B-TaskName
we -X- _ O
learn -X- _ O
the -X- _ O
multilingual -X- _ O
semantic -X- _ O
representation -X- _ O
by -X- _ O
restoring -X- _ O
the -X- _ O
MASK -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
sentences. -X- _ O
When -X- _ O
the -X- _ O
model -X- _ O
restores -X- _ O
the -X- _ O
MASK -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
sentence, -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
only -X- _ O
rely -X- _ O
on -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
sentence, -X- _ O
which -X- _ O
means -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
to -X- _ O
learn -X- _ O
how -X- _ O
to -X- _ O
represent -X- _ O
the -X- _ O
source -X- _ O
language -X- _ O
with -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
sentence -X- _ O
and -X- _ O
thus -X- _ O
align -X- _ O
the -X- _ O
semantics -X- _ O
of -X- _ O
multiple -X- _ O
languages. -X- _ O
Figure -X- _ O
1 -X- _ O
(b) -X- _ O
and -X- _ O
(c) -X- _ O
show -X- _ O
the -X- _ O
differences -X- _ O
between -X- _ O
TLM -X- _ O
(Lample -X- _ O
and -X- _ O
Conneau, -X- _ O
2019) -X- _ O
and -X- _ O
CAMLM. -X- _ B-TaskName
TLM -X- _ O
learns -X- _ O
the -X- _ O
semantic -X- _ O
alignment -X- _ O
between -X- _ O
languages -X- _ O
with -X- _ O
both -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sentences -X- _ O
while -X- _ O
CAMLM -X- _ B-TaskName
only -X- _ O
relies -X- _ O
on -X- _ O
one -X- _ O
side -X- _ O
of -X- _ O
the -X- _ O
sentence -X- _ O
to -X- _ O
restore -X- _ O
the -X- _ O
MASK -X- _ O
token. -X- _ O
The -X- _ O
advantage -X- _ O
of -X- _ O
CAMLM -X- _ B-TaskName
is -X- _ O
that -X- _ O
it -X- _ O
avoids -X- _ O
the -X- _ O
information -X- _ O
leakage -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
attend -X- _ O
to -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
input -X- _ O
sentences -X- _ O
at -X- _ O
the -X- _ O
same -X- _ O
time, -X- _ O
which -X- _ O
makes -X- _ O
learning -X- _ O
of -X- _ O
BTMLM -X- _ O
possible. -X- _ O
The -X- _ O
selfattention -X- _ O
matrix -X- _ O
of -X- _ O
the -X- _ O
example -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2. -X- _ O
For -X- _ O
TLM, -X- _ O
the -X- _ O
prediction -X- _ O
of -X- _ O
the -X- _ O
MASK -X- _ O
token -X- _ O
relies -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
sentence -X- _ O
pair. -X- _ O
When -X- _ O
the -X- _ O
model -X- _ O
learns -X- _ O
CAMLM, -X- _ B-TaskName
the -X- _ O
model -X- _ O
can -X- _ O
only -X- _ O
predict -X- _ O
the -X- _ O
MASK -X- _ O
token -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
sentence -X- _ O
of -X- _ O
its -X- _ O
corresponding -X- _ O
parallel -X- _ O
sentence -X- _ O
and -X- _ O
the -X- _ O
MASK -X- _ O
symbol -X- _ O
of -X- _ O
this -X- _ O
sentence, -X- _ O
which -X- _ O
provides -X- _ O
the -X- _ O
position -X- _ O
and -X- _ O
language -X- _ O
information. -X- _ O
Thus, -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
MASK -X- _ O
token -X- _ O
M -X- _ O
2 -X- _ O
is -X- _ O
p(x -X- _ O
2 -X- _ O
|M -X- _ O
2 -X- _ O
, -X- _ O
y -X- _ O
4 -X- _ O
, -X- _ O
y -X- _ O
5 -X- _ O
, -X- _ O
y -X- _ O
6 -X- _ O
, -X- _ O
y -X- _ O
7 -X- _ O
), -X- _ O
p(y -X- _ O
5 -X- _ O
|x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
x -X- _ O
3 -X- _ O
, -X- _ O
M -X- _ O
5 -X- _ O
) -X- _ O
for -X- _ O
M -X- _ O
5 -X- _ O
, -X- _ O
and -X- _ O
p(y -X- _ O
Given -X- _ O
the -X- _ O
input -X- _ O
in -X- _ O
a -X- _ O
bilingual -X- _ O
corpus -X- _ O
6 -X- _ O
|x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
x -X- _ O
3 -X- _ O
, -X- _ O
M -X- _ O
6 -X- _ O
) -X- _ O
for -X- _ O
M -X- _ O
6 -X- _ O
in -X- _ O
CAMLM. -X- _ B-TaskName
x1 -X- _ O
M2 -X- _ O
x -X- _ O
3 -X- _ O
y -X- _ O
4 -X- _ O
y7 -X- _ O
x1 -X- _ O
M -X- _ O
2 -X- _ O
x3 -X- _ O
y4 -X- _ O
M -X- _ O
5 -X- _ O
M -X- _ O
6 -X- _ O
y7 -X- _ O
M5 -X- _ O
M6 -X- _ O
x -X- _ O
2 -X- _ O
y5 -X- _ O
y6 -X- _ O
x2 -X- _ O
y5 -X- _ O
y6 -X- _ O
x1 -X- _ O
M -X- _ O
2 -X- _ O
x3 -X- _ O
y4 -X- _ O
M -X- _ O
5 -X- _ O
M -X- _ O
6 -X- _ O
y7 -X- _ O
x2 -X- _ O
y5 -X- _ O
y6 -X- _ O
x1 -X- _ O
M -X- _ O
2 -X- _ O
x3 -X- _ O
y4 -X- _ O
M -X- _ O
5 -X- _ O
M -X- _ O
6 -X- _ O
y7 -X- _ O
x2 -X- _ O
y5 -X- _ O
y6 -X- _ O
(a) -X- _ O
MMLM -X- _ O
x1 -X- _ O
M2 -X- _ O
x -X- _ O
3 -X- _ O
y -X- _ O
4 -X- _ O
y7 -X- _ O
x1 -X- _ O
M -X- _ O
2 -X- _ O
x3 -X- _ O
y4 -X- _ O
M -X- _ O
5 -X- _ O
M -X- _ O
6 -X- _ O
y7 -X- _ O
M5 -X- _ O
M6 -X- _ O
x -X- _ O
2 -X- _ O
y5 -X- _ O
y6 -X- _ O
x2 -X- _ O
y5 -X- _ O
y6 -X- _ O
x1 -X- _ O
M -X- _ O
2 -X- _ O
x3 -X- _ O
y4 -X- _ O
M -X- _ O
5 -X- _ O
M -X- _ O
6 -X- _ O
y7 -X- _ O
x2 -X- _ O
y5 -X- _ O
y6 -X- _ O
x1 -X- _ O
M -X- _ O
2 -X- _ O
x3 -X- _ O
y4 -X- _ O
M -X- _ O
5 -X- _ O
M -X- _ O
6 -X- _ O
y7 -X- _ O
x2 -X- _ O
y5 -X- _ O
y6 -X- _ O
(b) -X- _ O
TLM -X- _ O
x1 -X- _ O
M2 -X- _ O
x -X- _ O
3 -X- _ O
y -X- _ O
4 -X- _ O
y7 -X- _ O
x1 -X- _ O
M -X- _ O
2 -X- _ O
x3 -X- _ O
y4 -X- _ O
M -X- _ O
5 -X- _ O
M -X- _ O
6 -X- _ O
y7 -X- _ O
M5 -X- _ O
M6 -X- _ O
x -X- _ O
2 -X- _ O
y5 -X- _ O
y6 -X- _ O
x2 -X- _ O
y5 -X- _ O
y6 -X- _ O
x1 -X- _ O
M -X- _ O
2 -X- _ O
x3 -X- _ O
y4 -X- _ O
M -X- _ O
5 -X- _ O
M -X- _ O
6 -X- _ O
y7 -X- _ O
x2 -X- _ O
y5 -X- _ O
y6 -X- _ O
x1 -X- _ O
M -X- _ O
2 -X- _ O
x3 -X- _ O
y4 -X- _ O
M -X- _ O
5 -X- _ O
M -X- _ O
6 -X- _ O
y7 -X- _ O
x2 -X- _ O
y5 -X- _ O
y6 -X- _ O
(c) -X- _ O
CAMLM -X- _ B-TaskName
X -X- _ O
src -X- _ O
= -X- _ O
{x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
x -X- _ O
s -X- _ O
}, -X- _ O
and -X- _ O
its -X- _ O
corresponding -X- _ O
MASK -X- _ O
po- -X- _ O
sition, -X- _ O
M -X- _ O
src -X- _ O
= -X- _ O
{m -X- _ O
1 -X- _ O
, -X- _ O
m -X- _ O
2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
m -X- _ O
ms -X- _ O
}, -X- _ O
the -X- _ O
tar- -X- _ O
get -X- _ O
sentence -X- _ O
is -X- _ O
X -X- _ O
tgt -X- _ O
= -X- _ O
{x -X- _ O
s+1 -X- _ O
, -X- _ O
x -X- _ O
s+2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
x -X- _ O
s+t -X- _ O
}, -X- _ O
and -X- _ O
its -X- _ O
corresponding -X- _ O
MASK -X- _ O
position -X- _ O
is -X- _ O
M -X- _ O
tgt -X- _ O
= -X- _ O
{m -X- _ O
ms+1 -X- _ O
, -X- _ O
m -X- _ O
ms+2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
m -X- _ O
ms+mt -X- _ O
}. -X- _ O
In -X- _ O
TLM, -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
attend -X- _ O
to -X- _ O
the -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
and -X- _ O
target -X- _ O
sentences, -X- _ O
so -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
masked -X- _ O
tokens -X- _ O
is -X- _ O
m∈M -X- _ O
p(x -X- _ O
m -X- _ O
|X/ -X- _ O
M -X- _ O
), -X- _ O
where -X- _ O
M -X- _ O
= -X- _ O
M -X- _ O
src -X- _ O
∪ -X- _ O
M -X- _ O
tgt -X- _ O
. -X- _ O
X/ -X- _ O
M -X- _ O
denotes -X- _ O
all -X- _ O
input -X- _ O
tokens -X- _ O
x -X- _ O
in -X- _ O
X -X- _ O
except -X- _ O
x -X- _ O
in -X- _ O
M -X- _ O
, -X- _ O
where -X- _ O
X -X- _ O
= -X- _ O
X -X- _ O
src -X- _ O
∪ -X- _ O
X -X- _ O
tgt -X- _ O
. -X- _ O
x -X- _ O
m -X- _ O
denotes -X- _ O
the -X- _ O
token -X- _ O
with -X- _ O
position -X- _ O
m. -X- _ O
In -X- _ O
CAMLM, -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
MASK -X- _ O
token -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
is -X- _ O
m∈Msrc -X- _ O
p(x -X- _ O
m -X- _ O
|X/ -X- _ O
M -X- _ O
∪Xsrc -X- _ O
), -X- _ O
which -X- _ O
means -X- _ O
that -X- _ O
when -X- _ O
predicting -X- _ O
the -X- _ O
MASK -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
source -X- _ O
sentence, -X- _ O
we -X- _ O
only -X- _ O
focus -X- _ O
on -X- _ O
the -X- _ O
target -X- _ O
sentence. -X- _ O
As -X- _ O
for -X- _ O
the -X- _ O
target -X- _ O
sentence, -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
MASK -X- _ O
token -X- _ O
is -X- _ O
m∈Mtgt -X- _ O
p(x -X- _ O
m -X- _ O
|X/ -X- _ O
M -X- _ O
∪Xtgt -X- _ O
), -X- _ O
which -X- _ O
means -X- _ O
that -X- _ O
the -X- _ O
MASK -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
target -X- _ O
sentence -X- _ O
will -X- _ O
be -X- _ O
predicted -X- _ O
based -X- _ O
only -X- _ O
on -X- _ O
the -X- _ O
source -X- _ O
sentence. -X- _ O
Therefore, -X- _ O
the -X- _ O
model -X- _ O
must -X- _ O
learn -X- _ O
to -X- _ O
use -X- _ O
the -X- _ O
corresponding -X- _ O
sentence -X- _ O
to -X- _ O
predict -X- _ O
and -X- _ O
learn -X- _ O
the -X- _ O
alignment -X- _ O
across -X- _ O
multiple -X- _ O
languages. -X- _ O
The -X- _ O
pre-training -X- _ O
loss -X- _ O
of -X- _ O
CAMLM -X- _ O
in -X- _ O
the -X- _ O
source/target -X- _ O
sentence -X- _ O
is -X- _ O
L -X- _ O
CAM -X- _ O
LM -X- _ O
(src) -X- _ O
= -X- _ O
− -X- _ O
x∈D -X- _ O
B -X- _ O
log -X- _ O
m∈Msrc -X- _ O
p(x -X- _ O
m -X- _ O
|X/ -X- _ O
M -X- _ O
∪Xsrc -X- _ O
) -X- _ O
L -X- _ O
CAM -X- _ O
LM -X- _ O
(tgt) -X- _ O
= -X- _ O
− -X- _ O
x∈D -X- _ O
B -X- _ O
log -X- _ O
m∈Mtgt -X- _ O
p(x -X- _ O
m -X- _ O
|X/ -X- _ O
M -X- _ O
∪Xtgt -X- _ O
) -X- _ O
where -X- _ O
D -X- _ O
B -X- _ O
is -X- _ O
the -X- _ O
bilingual -X- _ O
training -X- _ O
corpus. -X- _ O
The -X- _ O
CAMLM -X- _ B-TaskName
loss -X- _ O
is -X- _ O
L -X- _ O
CAM -X- _ O
LM -X- _ O
= -X- _ O
L -X- _ O
CAM -X- _ O
LM -X- _ O
(src) -X- _ O
+ -X- _ O
L -X- _ O
CAM -X- _ O
LM -X- _ O
(tgt) -X- _ O

Existing -X- _ O
multilingual -X- _ O
language -X- _ O
models -X- _ O
can -X- _ O
be -X- _ O
classified -X- _ O
into -X- _ O
two -X- _ O
main -X- _ O
categories: -X- _ O
(1) -X- _ O
discriminative -X- _ O
models; -X- _ O
(2) -X- _ O
generative -X- _ O
models. -X- _ O
In -X- _ O
the -X- _ O
first -X- _ O
category, -X- _ O
a -X- _ O
multilingual -X- _ O
bidirectional -X- _ O
encoder -X- _ O
representation -X- _ O
from -X- _ O
transformers -X- _ O
(mBERT; -X- _ B-MethodName
Devlin -X- _ O
et -X- _ O
al. -X- _ O
2018) -X- _ O
is -X- _ O
pre-trained -X- _ O
using -X- _ O
MMLM -X- _ O
on -X- _ O
a -X- _ O
monolingual -X- _ O
corpus, -X- _ O
which -X- _ O
learns -X- _ O
a -X- _ O
shared -X- _ O
language-invariant -X- _ O
feature -X- _ O
space -X- _ O
among -X- _ O
multiple -X- _ O
languages. -X- _ O
The -X- _ O
evaluation -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
the -X- _ O
mBERT -X- _ B-MethodName
achieves -X- _ O
significant -X- _ O
performance -X- _ O
in -X- _ O
downstream -X- _ O
tasks -X- _ O
(Wu -X- _ O
and -X- _ O
Dredze, -X- _ O
2019). -X- _ O
XLM -X- _ B-MethodName
(Lample -X- _ O
and -X- _ O
is -X- _ O
extended -X- _ O
on -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
mBERT -X- _ B-MethodName
using -X- _ O
TLM, -X- _ O
which -X- _ O
enables -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
cross-lingual -X- _ O
token -X- _ O
alignment -X- _ O
from -X- _ O
parallel -X- _ O
corpora. -X- _ O
XLM-R -X- _ B-MethodName
demonstrates -X- _ O
the -X- _ O
effects -X- _ O
of -X- _ O
models -X- _ O
when -X- _ O
trained -X- _ O
on -X- _ O
a -X- _ O
large-scale -X- _ O
corpus. -X- _ O
It -X- _ O
used -X- _ O
2.5T -X- _ O
data -X- _ O
extracted -X- _ O
from -X- _ O
Common -X- _ O
Crawl -X- _ O
that -X- _ O
involves -X- _ O
100 -X- _ O
languages -X- _ O
for -X- _ O
MMLM -X- _ O
training. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
a -X- _ O
large-scale -X- _ O
training -X- _ O
corpus -X- _ O
can -X- _ O
significantly -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
cross-lingual -X- _ O
model. -X- _ O
Unicoder -X- _ O
(Huang -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
achieves -X- _ O
gains -X- _ O
on -X- _ O
downstream -X- _ O
tasks -X- _ O
by -X- _ O
employing -X- _ O
a -X- _ O
multitask -X- _ O
learning -X- _ O
framework -X- _ O
to -X- _ O
learn -X- _ O
cross-lingual -X- _ O
semantic -X- _ O
representations -X- _ O
with -X- _ O
monolingual -X- _ O
and -X- _ O
parallel -X- _ O
corpora. -X- _ O
ALM -X- _ O
(Yang -X- _ O
et -X- _ O
al., -X- _ O
2020) -X- _ O
improves -X- _ O
the -X- _ O
model's -X- _ O
transferability -X- _ O
by -X- _ O
enabling -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
cross-lingual -X- _ O
code-switch -X- _ O
sentences. -X- _ O
IN-FOXLM -X- _ O
(Chi -X- _ O
et -X- _ O
al., -X- _ O
2020b) -X- _ O
adds -X- _ O
a -X- _ O
contrastive -X- _ O
learning -X- _ O
task -X- _ O
for -X- _ O
cross-lingual -X- _ O
model -X- _ O
training. -X- _ O
HICTL -X- _ O
learns -X- _ O
cross-lingual -X- _ O
semantic -X- _ O
representation -X- _ O
from -X- _ O
multiple -X- _ O
facets -X- _ O
(at -X- _ O
word-levels -X- _ O
and -X- _ O
sentence-levels) -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
cross-lingual -X- _ O
models. -X- _ O
VECO -X- _ O
presents -X- _ O
a -X- _ O
variable -X- _ O
encoder-decoder -X- _ O
framework -X- _ O
to -X- _ O
unify -X- _ O
the -X- _ O
understanding -X- _ O
and -X- _ O
generation -X- _ O
tasks -X- _ O
and -X- _ O
achieves -X- _ O
significant -X- _ O
improvement -X- _ O
in -X- _ O
both -X- _ O
downstream -X- _ O
tasks. -X- _ O
The -X- _ O
second -X- _ O
category -X- _ O
includes -X- _ O
MASS -X- _ O
(Song -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
mBART -X- _ O
, -X- _ O
XNLG -X- _ O
(Chi -X- _ O
et -X- _ O
al., -X- _ O
2020a) -X- _ O
and -X- _ O
mT5 -X- _ O
(Xue -X- _ O
et -X- _ O
al., -X- _ O
2020). -X- _ O
MASS -X- _ O
(Vaswani -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
proposed -X- _ O
a -X- _ O
training -X- _ O
objective -X- _ O
for -X- _ O
restore -X- _ O
the -X- _ O
input -X- _ O
sentences -X- _ O
in -X- _ O
which -X- _ O
successive -X- _ O
token -X- _ O
fragments -X- _ O
are -X- _ O
masked -X- _ O
which -X- _ O
improved -X- _ O
the -X- _ O
model's -X- _ O
performance -X- _ O
on -X- _ O
machine -X- _ O
translation. -X- _ O
Similar -X- _ O
to -X- _ O
MASS, -X- _ O
mBART -X- _ O
pre-trains -X- _ O
a -X- _ O
denoised -X- _ O
sequence-to-sequence -X- _ O
model -X- _ O
and -X- _ O
uses -X- _ O
an -X- _ O
autoregressive -X- _ O
task -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
model. -X- _ O
XNLG -X- _ O
focuses -X- _ O
on -X- _ O
multilingual -X- _ O
question -X- _ O
generation -X- _ O
and -X- _ O
abstractive -X- _ O
summarization -X- _ O
and -X- _ O
updates -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
encoder -X- _ O
and -X- _ O
decoder -X- _ O
through -X- _ O
auto-encoding -X- _ O
and -X- _ O
autoregressive -X- _ O
tasks. -X- _ O
mT5 -X- _ O
uses -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
structure -X- _ O
and -X- _ O
pre-training -X- _ O
method -X- _ O
as -X- _ O
T5 -X- _ O
(Raffel -X- _ O
et -X- _ O
al., -X- _ O
2019), -X- _ O
and -X- _ O
extends -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
cross-lingual -X- _ O
model -X- _ O
to -X- _ O
13B, -X- _ O
significantly -X- _ O
improving -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
cross-language -X- _ O
downstream -X- _ O
tasks. -X- _ O

Back -X- _ O
translation -X- _ O
(BT) -X- _ O
is -X- _ O
an -X- _ O
effective -X- _ O
neuralnetwork-based -X- _ O
machine -X- _ O
translation -X- _ O
method -X- _ O
proposed -X- _ O
by -X- _ O
Sennrich -X- _ O
et -X- _ O
al. -X- _ O
(2015). -X- _ O
It -X- _ O
can -X- _ O
significantly -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
both -X- _ O
supervised -X- _ O
and -X- _ O
unsupervised -X- _ O
machine -X- _ O
translation -X- _ O
via -X- _ O
augment -X- _ O
the -X- _ O
parallel -X- _ O
training -X- _ O
corpus -X- _ O
(Lample -X- _ O
et -X- _ O
al., -X- _ O
2017;Edunov -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O
BT -X- _ O
has -X- _ O
been -X- _ O
found -X- _ O
to -X- _ O
particularly -X- _ O
useful -X- _ O
when -X- _ O
the -X- _ O
parallel -X- _ O
corpus -X- _ O
is -X- _ O
sparse -X- _ O
(Karakanta -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O
Predicting -X- _ O
the -X- _ O
token -X- _ O
of -X- _ O
the -X- _ O
target -X- _ O
language -X- _ O
in -X- _ O
one -X- _ O
batch -X- _ O
can -X- _ O
also -X- _ O
improve -X- _ O
the -X- _ O
speed -X- _ O
of -X- _ O
non-auto -X- _ O
regressive -X- _ O
machine -X- _ O
translation -X- _ O
(NAT; -X- _ O
Gu -X- _ O
et -X- _ O
al. -X- _ O
2017;Wang -X- _ O
et -X- _ O
al. -X- _ O
2019a). -X- _ O
Our -X- _ O
work -X- _ O
is -X- _ O
inspired -X- _ O
by -X- _ O
NAT -X- _ O
and -X- _ O
BT. -X- _ O
We -X- _ O
generate -X- _ O
the -X- _ O
tokens -X- _ O
of -X- _ O
another -X- _ O
language -X- _ O
in -X- _ O
batches -X- _ O
and -X- _ O
then -X- _ O
use -X- _ O
these -X- _ O
in -X- _ O
pre-training -X- _ O
to -X- _ O
help -X- _ O
sentence -X- _ O
alignment -X- _ O
learning. -X- _ O

To -X- _ O
overcome -X- _ O
the -X- _ O
constraint -X- _ O
that -X- _ O
the -X- _ O
parallel -X- _ O
corpus -X- _ O
size -X- _ O
places -X- _ O
on -X- _ O
the -X- _ O
model -X- _ O
performance, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
novel -X- _ O
pre-training -X- _ O
objective -X- _ O
inspired -X- _ O
by -X- _ O
NAT -X- _ O
(Gu -X- _ O
et -X- _ O
al., -X- _ O
2017;Wang -X- _ O
et -X- _ O
al., -X- _ O
2019a) -X- _ O
and -X- _ O
BT -X- _ O
methods -X- _ O
called -X- _ O
BTMLM -X- _ O
to -X- _ O
align -X- _ O
cross-lingual -X- _ O
semantics -X- _ O
with -X- _ O
the -X- _ O
monolingual -X- _ O
corpus. -X- _ O
We -X- _ O
use -X- _ O
BTMLM -X- _ O
to -X- _ O
train -X- _ O
our -X- _ O
model, -X- _ O
which -X- _ O
builds -X- _ O
on -X- _ O
the -X- _ O
transferability -X- _ O
learned -X- _ O
through -X- _ O
CAMLM, -X- _ B-TaskName
generating -X- _ O
pseudoparallel -X- _ O
sentences -X- _ O
from -X- _ O
the -X- _ O
monolingual -X- _ O
sentences -X- _ O
and -X- _ O
the -X- _ O
generated -X- _ O
pseudo-parallel -X- _ O
sentences -X- _ O
are -X- _ O
then -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
align -X- _ O
the -X- _ O
cross-lingual -X- _ O
semantics, -X- _ O
thus -X- _ O
enhancing -X- _ O
the -X- _ O
multilingual -X- _ O
representation. -X- _ O
The -X- _ O
training -X- _ O
process -X- _ O
for -X- _ O
BTMLM -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
3. -X- _ O
The -X- _ O
learning -X- _ O
process -X- _ O
for -X- _ O
the -X- _ O
BTMLM -X- _ O
is -X- _ O
divided -X- _ O
into -X- _ O
two -X- _ O
stages. -X- _ O
Stage -X- _ O
1 -X- _ O
involves -X- _ O
the -X- _ O
generation -X- _ O
of -X- _ O
pseudo-parallel -X- _ O
tokens -X- _ O
from -X- _ O
monolingual -X- _ O
corpora. -X- _ O
Specifically, -X- _ O
we -X- _ O
fill -X- _ O
in -X- _ O
several -X- _ O
placeholder -X- _ O
MASK -X- _ O
at -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
monolingual -X- _ O
sentence -X- _ O
to -X- _ O
indicate -X- _ O
the -X- _ O
location -X- _ O
and -X- _ O
the -X- _ O
language -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
generate, -X- _ O
and -X- _ O
let -X- _ O
the -X- _ O
model -X- _ O
generate -X- _ O
its -X- _ O
corresponding -X- _ O
parallel -X- _ O
language -X- _ O
token -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
monolingual -X- _ O
sentence -X- _ O
and -X- _ O
the -X- _ O
corresponding -X- _ O
position -X- _ O
of -X- _ O
the -X- _ O
pseudo-token. -X- _ O
In -X- _ O
this -X- _ O
way, -X- _ O
we -X- _ O
generate -X- _ O
the -X- _ O
tokens -X- _ O
of -X- _ O
another -X- _ O
language -X- _ O
from -X- _ O
the -X- _ O
monolingual -X- _ O
sentence, -X- _ O
which -X- _ O
will -X- _ O
be -X- _ O
used -X- _ O
in -X- _ O
learning -X- _ O
cross-lingual -X- _ O
semantic -X- _ O
alignment -X- _ O
for -X- _ O
multiple -X- _ O
languages. -X- _ O
The -X- _ O
self-attention -X- _ O
matrix -X- _ O
for -X- _ O
generating -X- _ O
pseudotokens -X- _ O
in -X- _ O
Figure -X- _ O
3 -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
4. -X- _ O
In -X- _ O
the -X- _ O
pseudo-token -X- _ O
generating -X- _ O
process, -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
only -X- _ O
attend -X- _ O
to -X- _ O
the -X- _ O
source -X- _ O
sentence -X- _ O
and -X- _ O
the -X- _ O
placeholder -X- _ O
MASK -X- _ O
tokens, -X- _ O
which -X- _ O
indicate -X- _ O
the -X- _ O
language -X- _ O
and -X- _ O
position -X- _ O
we -X- _ O
want -X- _ O
to -X- _ O
predict -X- _ O
by -X- _ O
using -X- _ O
language -X- _ O
embedding -X- _ O
and -X- _ O
position -X- _ O
embedding. -X- _ O
The -X- _ O
probability -X- _ O
of -X- _ O
mask -X- _ O
token -X- _ O
M -X- _ O
5 -X- _ O
is -X- _ O
p(y -X- _ O
5 -X- _ O
|x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
x -X- _ O
3 -X- _ O
, -X- _ O
x -X- _ O
4 -X- _ O
, -X- _ O
M -X- _ O
5 -X- _ O
), -X- _ O
p(y -X- _ O
6 -X- _ O
|x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
x -X- _ O
3 -X- _ O
, -X- _ O
x -X- _ O
4 -X- _ O
, -X- _ O
M -X- _ O
6 -X- _ O
) -X- _ O
for -X- _ O
M -X- _ O
6 -X- _ O
and -X- _ O
p(y -X- _ O
7 -X- _ O
|x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
x -X- _ O
3 -X- _ O
, -X- _ O
x -X- _ O
4 -X- _ O
, -X- _ O
M -X- _ O
7 -X- _ O
) -X- _ O
for -X- _ O
M -X- _ O
7 -X- _ O
. -X- _ O
Stage -X- _ O
2 -X- _ O
uses -X- _ O
the -X- _ O
pseudo-tokens -X- _ O
generated -X- _ O
in -X- _ O
Stage -X- _ O
1 -X- _ O
to -X- _ O
learn -X- _ O
the -X- _ O
cross-lingual -X- _ O
semantics -X- _ O
alignment. -X- _ O
The -X- _ O
process -X- _ O
in -X- _ O
Stage -X- _ O
2 -X- _ O
is -X- _ O
shown -X- _ O
in -X- _ O
the -X- _ O
righthand -X- _ O
diagram -X- _ O
of -X- _ O
Figure -X- _ O
3. -X- _ O
In -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
of -X- _ O
Stage -X- _ O
2, -X- _ O
the -X- _ O
input -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
monolingual -X- _ O
sentences -X- _ O
and -X- _ O
the -X- _ O
generated -X- _ O
pseudo-parallel -X- _ O
tokens, -X- _ O
and -X- _ O
the -X- _ O
learning -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
restore -X- _ O
the -X- _ O
MASK -X- _ O
tokens -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
sentences -X- _ O
and -X- _ O
the -X- _ O
generated -X- _ O
pseudo-parallel -X- _ O
tokens. -X- _ O
Because -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
rely -X- _ O
not -X- _ O
only -X- _ O
on -X- _ O
the -X- _ O
input -X- _ O
monolingual -X- _ O
sentence -X- _ O
but -X- _ O
also -X- _ O
the -X- _ O
generated -X- _ O
pseudo-tokens -X- _ O
in -X- _ O
the -X- _ O
process -X- _ O
of -X- _ O
inference -X- _ O
MASK -X- _ O
to-kens, -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
explicitly -X- _ O
learn -X- _ O
the -X- _ O
alignment -X- _ O
of -X- _ O
the -X- _ O
cross-lingual -X- _ O
semantic -X- _ O
representation -X- _ O
from -X- _ O
the -X- _ O
monolingual -X- _ O
sentences. -X- _ O
The -X- _ O
learning -X- _ O
process -X- _ O
of -X- _ O
the -X- _ O
BTMLM -X- _ O
can -X- _ O
be -X- _ O
interpreted -X- _ O
as -X- _ O
follows: -X- _ O
given -X- _ O
the -X- _ O
input -X- _ O
in -X- _ O
monolin- -X- _ O
gual -X- _ O
corpora -X- _ O
X -X- _ O
= -X- _ O
{x -X- _ O
1 -X- _ O
, -X- _ O
x -X- _ O
2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
x -X- _ O
s -X- _ O
}, -X- _ O
the -X- _ O
positions -X- _ O
of -X- _ O
masked -X- _ O
tokens -X- _ O
M -X- _ O
= -X- _ O
{m -X- _ O
1 -X- _ O
, -X- _ O
m -X- _ O
2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
m -X- _ O
m -X- _ O
} -X- _ O
and -X- _ O
the -X- _ O
position -X- _ O
of -X- _ O
the -X- _ O
pseudo-token -X- _ O
to -X- _ O
be -X- _ O
predicted, -X- _ O
M -X- _ O
pseudo -X- _ O
= -X- _ O
{m -X- _ O
s+1 -X- _ O
, -X- _ O
m -X- _ O
s+2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
m -X- _ O
s+p -X- _ O
}, -X- _ O
we -X- _ O
first -X- _ O
generate -X- _ O
pseudo-tokens -X- _ O
P -X- _ O
= -X- _ O
{h -X- _ O
s+1 -X- _ O
, -X- _ O
h -X- _ O
s+2 -X- _ O
, -X- _ O
• -X- _ O
• -X- _ O
• -X- _ O
, -X- _ O
h -X- _ O
s+p -X- _ O
}, -X- _ O
as -X- _ O
described -X- _ O
earlier; -X- _ O
we -X- _ O
then -X- _ O
concatenate -X- _ O
the -X- _ O
generated -X- _ O
pseudo-token -X- _ O
with -X- _ O
input -X- _ O
monolingual -X- _ O
sentence -X- _ O
as -X- _ O
a -X- _ O
new -X- _ O
parallel -X- _ O
sentence -X- _ O
pair -X- _ O
and -X- _ O
use -X- _ O
it -X- _ O
to -X- _ O
train -X- _ O
our -X- _ O
model. -X- _ O
Thus, -X- _ O
the -X- _ O
probability -X- _ O
of -X- _ O
the -X- _ O
masked -X- _ O
tokens -X- _ O
in -X- _ O
BTMLM -X- _ O
is -X- _ O
m∈M -X- _ O
p(x -X- _ O
m -X- _ O
|X/ -X- _ O
M -X- _ O
, -X- _ O
P -X- _ O
), -X- _ O
where -X- _ O
X/ -X- _ O
M -X- _ O
denotes -X- _ O
all -X- _ O
input -X- _ O
tokens -X- _ O
x -X- _ O
in -X- _ O
X -X- _ O
except -X- _ O
x -X- _ O
in -X- _ O
M -X- _ O
. -X- _ O
The -X- _ O
pre-training -X- _ O
loss -X- _ O
of -X- _ O
BTMLM -X- _ O
is -X- _ O
L -X- _ O
BT -X- _ O
M -X- _ O
LM -X- _ O
= -X- _ O
− -X- _ O
x∈D -X- _ O
M -X- _ O
log -X- _ O
m∈M -X- _ O
p(x -X- _ O
m -X- _ O
|X/ -X- _ O
M -X- _ O
, -X- _ O
P -X- _ O
) -X- _ O
where -X- _ O
D -X- _ O
M -X- _ O
is -X- _ O
the -X- _ O
monolingual -X- _ O
training -X- _ O
corpus. -X- _ O

We -X- _ O
consider -X- _ O
five -X- _ O
cross-lingual -X- _ O
evaluation -X- _ O
benchmarks: -X- _ O
XNLI -X- _ B-DatasetName
for -X- _ O
cross-lingual -X- _ B-TaskName
natural -X- _ I-TaskName
language -X- _ I-TaskName
inference, -X- _ I-TaskName
MLQA -X- _ B-DatasetName
for -X- _ O
cross-lingual -X- _ B-TaskName
question -X- _ I-TaskName
answering, -X- _ I-TaskName
CoNLL -X- _ B-DatasetName
for -X- _ O
cross-lingual -X- _ B-TaskName
named -X- _ I-TaskName
entity -X- _ I-TaskName
recognition, -X- _ I-TaskName
PAWS-X -X- _ B-DatasetName
for -X- _ O
cross-lingual -X- _ B-TaskName
paraphrase -X- _ I-TaskName
identification, -X- _ I-TaskName
and -X- _ O
Tatoeba -X- _ B-DatasetName
for -X- _ O
cross-lingual -X- _ B-TaskName
retrieval. -X- _ I-TaskName
Next, -X- _ O
we -X- _ O
first -X- _ O
describe -X- _ O
the -X- _ O
data -X- _ O
and -X- _ O
pre-training -X- _ O
details -X- _ O
and -X- _ O
then -X- _ O
compare -X- _ O
the -X- _ O
ERNIE-M -X- _ B-MethodName
with -X- _ O
the -X- _ O
existing -X- _ O
state-of-the-art -X- _ O
models. -X- _ O

ERNIE-M -X- _ B-MethodName
is -X- _ O
trained -X- _ O
with -X- _ O
monolingual -X- _ O
and -X- _ O
parallel -X- _ O
corpora -X- _ O
that -X- _ O
involved -X- _ O
96 -X- _ O
languages. -X- _ O
For -X- _ O
the -X- _ O
monolingual -X- _ O
corpus, -X- _ O
we -X- _ O
extract -X- _ O
it -X- _ O
from -X- _ O
CC-100 -X- _ B-DatasetName
according -X- _ O
to -X- _ O
; -X- _ O
. -X- _ O
For -X- _ O
the -X- _ O
bilingual -X- _ O
corpus, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
corpus -X- _ O
as -X- _ O
INFOXLM -X- _ O
(Chi -X- _ O
et -X- _ O
al., -X- _ O
2020b), -X- _ O
including -X- _ O
MultiUN -X- _ B-DatasetName
(Ziemski -X- _ O
et -X- _ O
al., -X- _ O
2016), -X- _ O
IIT -X- _ B-DatasetName
Bombay -X- _ I-DatasetName
(Kunchukuttan -X- _ O
et -X- _ O
al., -X- _ O
2017), -X- _ O
OPUS -X- _ B-DatasetName
(Tiedemann, -X- _ O
2012), -X- _ O
and -X- _ O
WikiMatrix -X- _ B-DatasetName
We -X- _ O
use -X- _ O
a -X- _ O
transformer-encoder -X- _ O
(Vaswani -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
as -X- _ O
the -X- _ O
backbone -X- _ O
of -X- _ O
the -X- _ O
model. -X- _ O
For -X- _ O
the -X- _ O
ERNIE-M -X- _ B-MethodName
BASE -X- _ I-MethodName
model, -X- _ O
we -X- _ O
adopt -X- _ O
a -X- _ O
structure -X- _ O
with -X- _ O
12 -X- _ B-HyperparameterValue
layers, -X- _ B-HyperparameterName
768 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units, -X- _ I-HyperparameterName
12 -X- _ B-HyperparameterValue
heads. -X- _ B-HyperparameterName
For -X- _ O
ERNIE-M -X- _ B-MethodName
LARGE -X- _ I-MethodName
model -X- _ O
, -X- _ O
we -X- _ O
adopt -X- _ O
a -X- _ O
structure -X- _ O
with -X- _ O
24 -X- _ B-HyperparameterValue
layers, -X- _ B-HyperparameterName
1024 -X- _ B-HyperparameterValue
hidden -X- _ B-HyperparameterName
units, -X- _ I-HyperparameterName
16 -X- _ B-HyperparameterValue
heads. -X- _ B-HyperparameterName
The -X- _ O
activation -X- _ B-HyperparameterName
function -X- _ I-HyperparameterName
used -X- _ O
is -X- _ O
GeLU -X- _ B-HyperparameterValue
(Hendrycks -X- _ O
and -X- _ O
Gimpel, -X- _ O
2016). -X- _ O
Following -X- _ O
Chi -X- _ O
et -X- _ O
al. -X- _ O
2020b -X- _ O
and, -X- _ O
we -X- _ O
initialize -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
ERNIE-M -X- _ B-MethodName
with -X- _ O
XLM-R. -X- _ B-MethodName
We -X- _ O
use -X- _ O
the -X- _ O
Adam -X- _ B-HyperparameterValue
optimizer -X- _ B-HyperparameterName
(Kingma -X- _ O
and -X- _ O
Ba, -X- _ O
2014) -X- _ O
to -X- _ O
train -X- _ O
ERNIE-M; -X- _ B-MethodName
the -X- _ O
learning -X- _ O
rate -X- _ O
is -X- _ O
scheduled -X- _ O
with -X- _ O
a -X- _ O
linear -X- _ O
decay -X- _ O
with -X- _ O
10K -X- _ B-HyperparameterValue
warm-up -X- _ B-HyperparameterName
steps, -X- _ I-HyperparameterName
and -X- _ O
the -X- _ O
peak -X- _ B-HyperparameterName
learning -X- _ I-HyperparameterName
rate -X- _ I-HyperparameterName
is -X- _ O
2e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
4 -X- _ I-HyperparameterValue
for -X- _ O
the -X- _ O
base -X- _ O
model -X- _ O
and -X- _ O
1e -X- _ B-HyperparameterValue
− -X- _ I-HyperparameterValue
4 -X- _ I-HyperparameterValue
for -X- _ O
the -X- _ O
large -X- _ O
model. -X- _ O
We -X- _ O
conduct -X- _ O
the -X- _ O
pre-training -X- _ O
experiments -X- _ O
using -X- _ O
64 -X- _ O
Nvidia -X- _ O
V100-32GB -X- _ O
GPUs -X- _ O
with -X- _ O
2048 -X- _ B-HyperparameterValue
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
and -X- _ O
512 -X- _ B-HyperparameterValue
max -X- _ B-HyperparameterName
length. -X- _ I-HyperparameterName

Cross-lingual -X- _ O
Natural -X- _ O
Language -X- _ O
Inference. -X- _ O
The -X- _ O
cross-lingual -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
(XNLI; -X- _ O
Conneau -X- _ O
et -X- _ O
al. -X- _ O
2018) -X- _ O
task -X- _ O
is -X- _ O
a -X- _ O
multilingual -X- _ O
language -X- _ O
inference -X- _ O
task. -X- _ O
The -X- _ O
goal -X- _ O
of -X- _ O
XNLI -X- _ B-DatasetName
is -X- _ O
to -X- _ O
determine -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
the -X- _ O
two -X- _ O
input -X- _ O
sentences. -X- _ O
We -X- _ O
evaluate -X- _ O
ERNIE-M -X- _ B-MethodName
in -X- _ O
(1) -X- _ O
cross-lingual -X- _ B-TaskName
transfer -X- _ I-TaskName
(Conneau -X- _ O
et -X- _ O
al., -X- _ O
2018) -X- _ O
setting: -X- _ O
fine-tune -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
an -X- _ O
English -X- _ O
training -X- _ O
set -X- _ O
and -X- _ O
evaluate -X- _ O
the -X- _ O
foreign -X- _ O
language -X- _ O
XNLI -X- _ O
test -X- _ O
and -X- _ O
(2) -X- _ O
translatetrain-all -X- _ O
(Huang -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
setting: -X- _ O
fine-tune -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
all -X- _ O
other -X- _ O
languages -X- _ O
and -X- _ O
evaluate -X- _ O
on -X- _ O
each -X- _ O
language -X- _ O
test -X- _ O
set. -X- _ O
Table -X- _ O
1 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
ERNIE-M -X- _ B-MethodName
in -X- _ O
XNLI -X- _ B-DatasetName
task. -X- _ O
The -X- _ O
result -X- _ O
shows -X- _ O
that -X- _ O
ERNIE-M -X- _ B-MethodName
outperforms -X- _ O
all -X- _ O
baseline -X- _ O
models -X- _ O
including -X- _ O
XLM -X- _ B-MethodName
(Lample -X- _ O
and -X- _ O
Conneau, -X- _ O
2019) -X- _ O
Named -X- _ B-TaskName
Entity -X- _ I-TaskName
Recognition. -X- _ I-TaskName
For -X- _ O
the -X- _ O
namedentity-recognition -X- _ B-TaskName
task, -X- _ O
we -X- _ O
evaluate -X- _ O
ERNIE-M -X- _ B-MethodName
on -X- _ O
the -X- _ O
CoNLL-2002and -X- _ B-DatasetName
CoNLL-2003datasets -X- _ B-DatasetName
(Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder, -X- _ O
2003, -X- _ O
which -X- _ O
is -X- _ O
a -X- _ O
cross-lingual -X- _ B-TaskName
named-entity-recognition -X- _ I-TaskName
task -X- _ O
including -X- _ O
English, -X- _ O
Dutch, -X- _ O
Spanish -X- _ O
and -X- _ O
German. -X- _ O
We -X- _ O
consider -X- _ O
ERNIE-M -X- _ B-MethodName
in -X- _ O
the -X- _ O
following -X- _ O
setting: -X- _ O
(1) -X- _ O
fine-tune -X- _ O
on -X- _ O
the -X- _ O
, -X- _ O
and -X- _ O
(Wu -X- _ O
and -X- _ O
Dredze, -X- _ O
2019), -X- _ O
respectively. -X- _ O
English -X- _ O
dataset -X- _ O
and -X- _ O
evaluate -X- _ O
on -X- _ O
each -X- _ O
cross-lingual -X- _ O
dataset -X- _ O
to -X- _ O
evaluate -X- _ O
cross-lingual -X- _ O
transfer -X- _ O
and -X- _ O
(2) -X- _ O
fine-tune -X- _ O
on -X- _ O
all -X- _ O
training -X- _ O
datasets -X- _ O
to -X- _ O
evaluate -X- _ O
crosslingual -X- _ O
learning. -X- _ O
For -X- _ O
each -X- _ O
setting, -X- _ O
we -X- _ O
reported -X- _ O
the -X- _ O
F1 -X- _ O
score -X- _ O
for -X- _ O
each -X- _ O
language. -X- _ O
Table -X- _ O
2 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
ERNIE-M, -X- _ B-MethodName
XLM-R, -X- _ B-MethodName
and -X- _ O
mBERT -X- _ B-MethodName
on -X- _ O
CoNLL-2002 -X- _ B-DatasetName
andCoNLL-2003. -X- _ B-DatasetName
The -X- _ O
results -X- _ O
of -X- _ O
XLM-R -X- _ B-MethodName
and -X- _ O
mBERT -X- _ B-MethodName
are -X- _ O
reported -X- _ O
from -X- _ O
. -X- _ O
ERNIE-M -X- _ B-MethodName
model -X- _ O
yields -X- _ O
SoTA -X- _ O
performance -X- _ O
on -X- _ O
both -X- _ O
settings -X- _ O
and -X- _ O
outperforms -X- _ O
XLM-R -X- _ B-MethodName
by -X- _ O
0.45 -X- _ B-MetricValue
F1 -X- _ B-MetricName
when -X- _ O
trained -X- _ O
on -X- _ O
English -X- _ O
and -X- _ O
0.70 -X- _ B-MetricValue
F1 -X- _ B-MetricName
when -X- _ O
trained -X- _ O
on -X- _ O
all -X- _ O
languages -X- _ O
in -X- _ O
the -X- _ O
base -X- _ O
model. -X- _ O
Similar -X- _ O
to -X- _ O
the -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
XNLI -X- _ B-DatasetName
task, -X- _ O
ERNIE-M -X- _ B-MethodName
shows -X- _ O
better -X- _ O
performance -X- _ O
on -X- _ O
low-resource -X- _ O
languages. -X- _ O
For -X- _ O
large -X- _ O
models -X- _ O
and -X- _ O
finetune -X- _ O
in -X- _ O
all -X- _ O
languages -X- _ O
setting, -X- _ O
ERNIE-M -X- _ B-MethodName
is -X- _ O
2.21 -X- _ B-MetricValue
F1 -X- _ B-MetricName
higher -X- _ O
than -X- _ O
SoTA -X- _ O
in -X- _ O
Dutch -X- _ O
(nl) -X- _ O
and -X- _ O
1.6 -X- _ B-MetricValue
F1 -X- _ B-MetricName
higher -X- _ O
than -X- _ O
SoTA -X- _ O
in -X- _ O
German -X- _ O
(de). -X- _ O
Cross-lingual -X- _ B-TaskName
Question -X- _ I-TaskName
Answering. -X- _ I-TaskName
For -X- _ O
the -X- _ O
question -X- _ O
answering -X- _ O
task, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
multilingual -X- _ B-DatasetName
question -X- _ I-DatasetName
answering -X- _ I-DatasetName
(MLQA) -X- _ B-DatasetName
dataset -X- _ O
to -X- _ O
evaluate -X- _ O
ERNIE-M. -X- _ B-MethodName
MLQA -X- _ B-DatasetName
has -X- _ O
the -X- _ O
same -X- _ O
format -X- _ O
as -X- _ O
SQuAD -X- _ O
v1.1 -X- _ O
(Rajpurkar -X- _ O
et -X- _ O
al., -X- _ O
2016) -X- _ O
and -X- _ O
is -X- _ O
a -X- _ O
multilingual -X- _ O
language -X- _ O
question -X- _ O
answering -X- _ O
task -X- _ O
composed -X- _ O
of -X- _ O
seven -X- _ O
languages. -X- _ O
We -X- _ O
fine-tune -X- _ O
ERNIE-M -X- _ B-MethodName
by -X- _ O
training -X- _ O
on -X- _ O
English -X- _ O
data -X- _ O
and -X- _ O
evaluating -X- _ O
on -X- _ O
seven -X- _ O
crosslingual -X- _ O
datasets. -X- _ O
The -X- _ O
fine-tune -X- _ O
method -X- _ O
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
in -X- _ O
Lewis -X- _ O
et -X- _ O
al. -X- _ O
(2019), -X- _ O
which -X- _ O
concatenates -X- _ O
the -X- _ O
question-passage -X- _ O
pair -X- _ O
as -X- _ O
the -X- _ O
input. -X- _ O
Table -X- _ O
3 -X- _ O
presents -X- _ O
a -X- _ O
comparison -X- _ O
of -X- _ O
ERNIE-M -X- _ B-MethodName
and -X- _ O
several -X- _ O
baseline -X- _ O
models -X- _ O
on -X- _ O
MLQA. -X- _ B-DatasetName
We -X- _ O
report -X- _ O
the -X- _ O
F1 -X- _ B-MetricName
and -X- _ O
extract -X- _ B-MetricName
match -X- _ I-MetricName
(EM) -X- _ B-MetricName
scores -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
average -X- _ O
over -X- _ O
five -X- _ O
runs. -X- _ O
The -X- _ O
performance -X- _ O
of -X- _ O
ERNIE-M -X- _ B-MethodName
in -X- _ O
MLQA -X- _ B-DatasetName
is -X- _ O
significantly -X- _ O
better -X- _ O
than -X- _ O
the -X- _ O
previous -X- _ O
models, -X- _ O
and -X- _ O
it -X- _ O
achieves -X- _ O
a -X- _ O
SoTA -X- _ O
score. -X- _ O
We -X- _ O
outperform -X- _ O
INFOXLM -X- _ O
0.8 -X- _ B-MetricValue
in -X- _ O
F1 -X- _ B-MetricName
and -X- _ O
0.5 -X- _ B-MetricValue
in -X- _ O
EM. -X- _ B-MetricName
Cross-lingual -X- _ O
Paraphrase -X- _ O
Identification. -X- _ O
For -X- _ O
cross-lingual -X- _ O
paraphrase -X- _ O
identification -X- _ O
task, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
PAWS-X -X- _ B-DatasetName
dataset -X- _ O
to -X- _ O
evaluate -X- _ O
our -X- _ O
model. -X- _ O
The -X- _ O
goal -X- _ O
of -X- _ O
PAWS-X -X- _ B-DatasetName
was -X- _ O
to -X- _ O
determine -X- _ O
whether -X- _ O
two -X- _ O
sentences -X- _ O
were -X- _ O
paraphrases. -X- _ O
We -X- _ O
evaluate -X- _ O
ERNIE-M -X- _ B-MethodName
on -X- _ O
both -X- _ O
the -X- _ O
cross-lingual -X- _ O
transfer -X- _ O
setting -X- _ O
and -X- _ O
translate-train-all -X- _ O
setting. -X- _ O
Table -X- _ O
4 -X- _ O
shows -X- _ O
a -X- _ O
comparison -X- _ O
of -X- _ O
ERNIE-M -X- _ B-MethodName
and -X- _ O
various -X- _ O
baseline -X- _ O
models -X- _ O
on -X- _ O
PAWS-X. -X- _ B-DatasetName
We -X- _ O
report -X- _ O
the -X- _ O
accuracy -X- _ O
score -X- _ O
on -X- _ O
each -X- _ O
language -X- _ O
test -X- _ O
set -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
average -X- _ O
over -X- _ O
five -X- _ O
runs. -X- _ O
The -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
and -X- _ O
, -X- _ O
respectively. -X- _ O

Cross-lingual -X- _ B-TaskName
Sentence -X- _ I-TaskName
Retrieval. -X- _ I-TaskName
The -X- _ O
goal -X- _ O
of -X- _ O
the -X- _ O
cross-lingual -X- _ B-TaskName
sentence -X- _ I-TaskName
retrieval -X- _ I-TaskName
task -X- _ O
was -X- _ O
to -X- _ O
extract -X- _ O
parallel -X- _ O
sentences -X- _ O
from -X- _ O
bilingual -X- _ O
corpora. -X- _ O
We -X- _ O
used -X- _ O
a -X- _ O
subset -X- _ O
of -X- _ O
the -X- _ O
Tatoeba -X- _ B-DatasetName
dataset, -X- _ O
which -X- _ O
contains -X- _ O
36 -X- _ O
language -X- _ O
pairs -X- _ O
to -X- _ O
evaluate -X- _ O
ERNIE-M. -X- _ B-MethodName
Following -X- _ O
, -X- _ O
we -X- _ O
used -X- _ O
the -X- _ O
averaged -X- _ O
representation -X- _ O
in -X- _ O
the -X- _ O
middle -X- _ O
layer -X- _ O
of -X- _ O
the -X- _ O
best -X- _ O
XNLI -X- _ B-DatasetName
model -X- _ O
to -X- _ O
evaluate -X- _ O
the -X- _ O
retrieval -X- _ O
task. -X- _ O
Table -X- _ O
5 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
ERNIE-M -X- _ B-MethodName
in -X- _ O
the -X- _ O
retrieval -X- _ O
task; -X- _ O
XLM-R -X- _ B-MethodName
results -X- _ O
are -X- _ O
reported -X- _ O
from -X- _ O
. -X- _ O
ERNIE-M -X- _ B-MethodName
achieves -X- _ O
a -X- _ O
score -X- _ O
of -X- _ O
87.9 -X- _ O
in -X- _ O
the -X- _ O
Tatoeba -X- _ B-DatasetName
dataset, -X- _ O
outperforming -X- _ O
VECO -X- _ O
1.0 -X- _ O
and -X- _ O
obtaining -X- _ O
new -X- _ O
SoTA -X- _ O
results. -X- _ O

XLM-R -X- _ B-HyperparameterName
LARGE -X- _ I-HyperparameterName
To -X- _ O
further -X- _ O
evaluate -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
ERNIE-M -X- _ B-HyperparameterName
in -X- _ O
retrieval -X- _ O
task, -X- _ O
we -X- _ O
use -X- _ O
hardest -X- _ O
negative -X- _ B-MetricName
binary -X- _ I-MetricName
cross-entropy -X- _ I-MetricName
loss -X- _ I-MetricName
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2019b;Faghri -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
to -X- _ O
fine-tune -X- _ O
ERNIE-M -X- _ B-MethodName
with -X- _ O
the -X- _ O
same -X- _ O
bilingual -X- _ O
corpus -X- _ O
in -X- _ O
pre-training. -X- _ O
Figure -X- _ O
5 -X- _ O
shows -X- _ O
the -X- _ O
details -X- _ O
of -X- _ O
accuracy -X- _ O
on -X- _ O
each -X- _ O
language -X- _ O
in -X- _ O
Tatoeba. -X- _ B-DatasetName
After -X- _ O
fine-tuning, -X- _ O
ERNIE-M -X- _ B-MethodName
shows -X- _ O
a -X- _ O
significant -X- _ O
improvement -X- _ O
in -X- _ O
all -X- _ O
languages, -X- _ O
with -X- _ O
the -X- _ O
average -X- _ B-MetricName
accuracy -X- _ I-MetricName
in -X- _ O
all -X- _ O
languages -X- _ O
increasing -X- _ O
from -X- _ O
87.9 -X- _ B-MetricValue
to -X- _ O
93.3. -X- _ B-MetricValue

To -X- _ O
understand -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
aligning -X- _ O
semantic -X- _ O
representations -X- _ O
of -X- _ O
multiple -X- _ O
languages -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
of -X- _ O
ERNIE-M, -X- _ B-MethodName
we -X- _ O
conducted -X- _ O
an -X- _ O
ablation -X- _ O
study -X- _ O
as -X- _ O
reported -X- _ O
in -X- _ O
Table -X- _ O
6. -X- _ O
Comparing -X- _ O
exp -X- _ O
0 -X- _ O
and -X- _ O
exp -X- _ O
1 -X- _ O
, -X- _ O
we -X- _ O
can -X- _ O
observer -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
no -X- _ O
gain -X- _ O
in -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
crosslingual -X- _ O
model -X- _ O
by -X- _ O
continuing -X- _ O
pre-training -X- _ O
XLM- -X- _ O
Comparing -X- _ O
exp -X- _ O
3 -X- _ O
to -X- _ O
exp -X- _ O
4 -X- _ O
, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
there -X- _ O
is -X- _ O
a -X- _ O
0.5 -X- _ B-MetricValue
improvement -X- _ O
on -X- _ O
XNLI -X- _ B-DatasetName
and -X- _ O
0.1 -X- _ B-MetricValue
improvement -X- _ O
on -X- _ O
CoNLL -X- _ B-DatasetName
after -X- _ O
the -X- _ O
model -X- _ O
learns -X- _ O
BTMLM. -X- _ B-TaskName
This -X- _ O
demonstrates -X- _ O
that -X- _ O
our -X- _ O
proposed -X- _ O
BTMLM -X- _ B-TaskName
can -X- _ O
learn -X- _ O
cross-lingual -X- _ O
semantic -X- _ O
alignment -X- _ O
and -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
our -X- _ O
model. -X- _ O
To -X- _ O
further -X- _ O
analyze -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
our -X- _ O
strategy, -X- _ O
we -X- _ O
trained -X- _ O
the -X- _ O
small-sized -X- _ O
ERNIE-M -X- _ B-MethodName
model -X- _ O
from -X- _ O
scratch. -X- _ O
Table -X- _ O
8 -X- _ O
shows -X- _ O
the -X- _ O
results -X- _ O
of -X- _ O
XNLI -X- _ B-DatasetName
and -X- _ O
CoNLL. -X- _ B-DatasetName
Both -X- _ O
XNLI -X- _ B-DatasetName
and -X- _ O
CoNLL -X- _ B-DatasetName
results -X- _ O
are -X- _ O
the -X- _ O
average -X- _ O
of -X- _ O
each -X- _ O
languages. -X- _ O
We -X- _ O
observe -X- _ O
that, -X- _ O
ERNIE-M -X- _ B-MethodName
SMALL -X- _ I-MethodName
can -X- _ O
outperform -X- _ O
XLM-R -X- _ B-MethodName
SMALL -X- _ I-MethodName
by -X- _ O
4.4 -X- _ B-MetricValue
in -X- _ O
XNLI -X- _ B-DatasetName
and -X- _ O
6.6 -X- _ B-MetricValue
in -X- _ O
CoNLL. -X- _ B-DatasetName
It -X- _ O
suggests -X- _ O
that -X- _ O
our -X- _ O
models -X- _ O
can -X- _ O
benefit -X- _ O
from -X- _ O
align -X- _ O
cross-lingual -X- _ O
semantic -X- _ O
representation. -X- _ O
Table -X- _ O
7 -X- _ O
shows -X- _ O
the -X- _ O
gap -X- _ B-MetricName
scores -X- _ I-MetricName
for -X- _ O
English -X- _ O
and -X- _ O
other -X- _ O
languages -X- _ O
in -X- _ O
the -X- _ O
downstream -X- _ O
task. -X- _ O
This -X- _ O
gap -X- _ B-MetricName
score -X- _ I-MetricName
is -X- _ O
the -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
English -X- _ O
testset -X- _ O
and -X- _ O
the -X- _ O
average -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
testset -X- _ O
in -X- _ O
other -X- _ O
languages. -X- _ O
So, -X- _ O
a -X- _ O
smaller -X- _ O
gap -X- _ B-MetricName
score -X- _ I-MetricName
represents -X- _ O
a -X- _ O
better -X- _ O
transferability -X- _ O
of -X- _ O
the -X- _ O
model. -X- _ O
We -X- _ O
can -X- _ O
no- -X- _ O
With -X- _ O
the -X- _ O
same -X- _ O
computational -X- _ O
overhead, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
ERNIE-M -X- _ B-MethodName
is -X- _ O
69.9 -X- _ B-MetricValue
in -X- _ O
XNLI -X- _ B-DatasetName
and -X- _ O
69.7 -X- _ B-MetricValue
in -X- _ O
CoNLL, -X- _ B-DatasetName
while -X- _ O
XLM-R's -X- _ O
performance -X- _ O
is -X- _ O
67.3 -X- _ B-MetricValue
in -X- _ O
XNLI -X- _ B-DatasetName
and -X- _ O
65.6 -X- _ B-MetricValue
in -X- _ O
CoNLL. -X- _ B-DatasetName
The -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
ERNIE-M -X- _ B-MethodName
performs -X- _ O
better -X- _ O
than -X- _ O
XLM-R -X- _ B-MethodName
even -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
computational -X- _ O
overhead. -X- _ O
In -X- _ O
addition, -X- _ O
we -X- _ O
explored -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
generated -X- _ O
pseudo-parallel -X- _ O
tokens -X- _ O
on -X- _ O
the -X- _ O
convergence -X- _ O
of -X- _ O
the -X- _ O
model. -X- _ O
In -X- _ O
particular, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
impact -X- _ O
on -X- _ O
the -X- _ O
convergence -X- _ O
speed -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
when -X- _ O
generating -X- _ O
a -X- _ O
5%, -X- _ B-HyperparameterValue
10%, -X- _ B-HyperparameterValue
15%, -X- _ B-HyperparameterValue
and -X- _ O
20% -X- _ B-HyperparameterValue
proportion -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
pseudo-tokens. -X- _ I-HyperparameterName
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
6, -X- _ O
we -X- _ O
can -X- _ O
find -X- _ O
that -X- _ O
the -X- _ O
perplexity -X- _ O
(PPL) -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
decreases -X- _ O
as -X- _ O
the -X- _ O
proportion -X- _ O
of -X- _ O
generated -X- _ O
tokens -X- _ O
increases, -X- _ O
which -X- _ O
indicates -X- _ O
that -X- _ O
the -X- _ O
generated -X- _ O
pseudo-parallel -X- _ O
tokens -X- _ O
are -X- _ O
helpful -X- _ O
for -X- _ O
model -X- _ O
convergence. -X- _ O

To -X- _ O
overcome -X- _ O
the -X- _ O
constraint -X- _ O
that -X- _ O
the -X- _ O
parallel -X- _ O
corpus -X- _ O
size -X- _ O
places -X- _ O
on -X- _ O
the -X- _ O
cross-lingual -X- _ O
models -X- _ O
performance, -X- _ O
we -X- _ O
propose -X- _ O
a -X- _ O
new -X- _ O
cross-lingual -X- _ O
model, -X- _ O
ERNIE-M, -X- _ B-MethodName
which -X- _ O
is -X- _ O
trained -X- _ O
using -X- _ O
both -X- _ O
monolingual -X- _ O
and -X- _ O
parallel -X- _ O
corpora. -X- _ O
The -X- _ O
contribution -X- _ O
of -X- _ O
ERNIE-M -X- _ B-MethodName
is -X- _ O
to -X- _ O
propose -X- _ O
two -X- _ O
training -X- _ O
objectives. -X- _ O
The -X- _ O
first -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
enhance -X- _ O
the -X- _ O
multilingual -X- _ O
representation -X- _ O
on -X- _ O
parallel -X- _ O
corpora -X- _ O
by -X- _ O
applying -X- _ O
CAMLM, -X- _ B-TaskName
and -X- _ O
the -X- _ O
second -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
help -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
align -X- _ O
cross-lingual -X- _ O
semantic -X- _ O
representations -X- _ O
from -X- _ O
a -X- _ O
monolingual -X- _ O
corpus -X- _ O
by -X- _ O
using -X- _ O
BTMLM. -X- _ O
Experiments -X- _ O
show -X- _ O
that -X- _ O
ERNIE-M -X- _ B-MethodName
achieves -X- _ O
SoTA -X- _ O
results -X- _ O
in -X- _ O
various -X- _ O
downstream -X- _ O
tasks -X- _ O
on -X- _ O
the -X- _ O
XNLI, -X- _ B-DatasetName
MLQA, -X- _ B-DatasetName
CoNLL, -X- _ B-DatasetName
PAWS-X, -X- _ B-DatasetName
and -X- _ O
Tatoeba -X- _ B-DatasetName
datasets. -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
first -X- _ O
introduce -X- _ O
the -X- _ O
general -X- _ O
workflow -X- _ O
of -X- _ O
ERNIE-M -X- _ B-MethodName
and -X- _ O
then -X- _ O
present -X- _ O
the -X- _ O
details -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
training. -X- _ O

Recent -X- _ O
studies -X- _ O
have -X- _ O
demonstrated -X- _ O
that -X- _ O
the -X- _ O
pretraining -X- _ O
of -X- _ O
cross-lingual -X- _ O
language -X- _ O
models -X- _ O
can -X- _ O
significantly -X- _ O
improve -X- _ O
their -X- _ O
performance -X- _ O
in -X- _ O
crosslingual -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
tasks -X- _ O
(Devlin -X- _ O
et -X- _ O
al., -X- _ O
2018;Lample -X- _ O
and -X- _ O
Conneau, -X- _ O
2019;. -X- _ O
Existing -X- _ O
pretraining -X- _ O
methods -X- _ O
include -X- _ O
multilingual -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
(MMLM; -X- _ O
Devlin -X- _ O
et -X- _ O
al. -X- _ O
2018) -X- _ O
and -X- _ O
translation -X- _ O
language -X- _ O
modeling -X- _ O
(TLM; -X- _ O
Lample -X- _ O
and -X- _ O
Conneau -X- _ O
2019), -X- _ O
of -X- _ O
which -X- _ O
the -X- _ O
key -X- _ O
point -X- _ O
is -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
shared -X- _ O
language-invariant -X- _ O
feature -X- _ O
space -X- _ O
among -X- _ O
multiple -X- _ O
languages. -X- _ O
MMLM -X- _ O
implicitly -X- _ O
models -X- _ O
the -X- _ O
semantic -X- _ O
representation -X- _ O
of -X- _ O
each -X- _ O
language -X- _ O
in -X- _ O
a -X- _ O
unified -X- _ O
feature -X- _ O
space -X- _ O
by -X- _ O
learning -X- _ O
them -X- _ O
separately. -X- _ O
TLM -X- _ O
is -X- _ O
an -X- _ O
extension -X- _ O
of -X- _ O
MMLM -X- _ O
that -X- _ O
is -X- _ O
trained -X- _ O
with -X- _ O
a -X- _ O
parallel -X- _ O
corpus -X- _ O
and -X- _ O
captures -X- _ O
semantic -X- _ O
alignment -X- _ O
by -X- _ O
learning -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
parallel -X- _ O
sentences -X- _ O
simultaneously. -X- _ O
This -X- _ O
study -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
parallel -X- _ O
corpora -X- _ O
can -X- _ O
significantly -X- _ O
improve -X- _ O
the -X- _ O
performance -X- _ O
in -X- _ O
downstream -X- _ O
cross-lingual -X- _ O
understanding -X- _ O
and -X- _ O
generation -X- _ O
tasks. -X- _ O
However, -X- _ O
the -X- _ O
sizes -X- _ O
of -X- _ O
parallel -X- _ O
corpora -X- _ O
are -X- _ O
limited -X- _ O
(Tran -X- _ O
et -X- _ O
al., -X- _ O
2020), -X- _ O
restricting -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
cross-lingual -X- _ O
language -X- _ O
model. -X- _ O
To -X- _ O
overcome -X- _ O
the -X- _ O
constraint -X- _ O
of -X- _ O
the -X- _ O
parallel -X- _ O
corpus -X- _ O
size -X- _ O
on -X- _ O
the -X- _ O
model -X- _ O
performance, -X- _ O
we -X- _ O
propose -X- _ O
ERNIE-M, -X- _ B-MethodName
a -X- _ O
novel -X- _ O
cross-lingual -X- _ O
pre-training -X- _ O
method -X- _ O
to -X- _ O
learn -X- _ O
semantic -X- _ O
alignment -X- _ O
among -X- _ O
multiple -X- _ O
languages -X- _ O
on -X- _ O
monolingual -X- _ O
corpora. -X- _ O
Specifically, -X- _ O
we -X- _ O
propose -X- _ O
cross-attention -X- _ B-TaskName
masked -X- _ I-TaskName
language -X- _ I-TaskName
modeling -X- _ I-TaskName
(CAMLM) -X- _ B-TaskName
to -X- _ O
improve -X- _ O
the -X- _ O
cross-lingual -X- _ O
transferability -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
on -X- _ O
parallel -X- _ O
corpora, -X- _ O
and -X- _ O
it -X- _ O
trains -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
tokens -X- _ O
of -X- _ O
one -X- _ O
language -X- _ O
by -X- _ O
using -X- _ O
another -X- _ O
language. -X- _ O
Then, -X- _ O
we -X- _ O
utilize -X- _ O
the -X- _ O
transferability -X- _ O
learned -X- _ O
from -X- _ O
parallel -X- _ O
corpora -X- _ O
to -X- _ O
enhance -X- _ O
multilingual -X- _ O
representation. -X- _ O
We -X- _ O
propose -X- _ O
back-translation -X- _ O
masked -X- _ O
language -X- _ O
modeling -X- _ O
(BTMLM) -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
model, -X- _ O
and -X- _ O
this -X- _ O
helps -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
learn -X- _ O
sentence -X- _ O
alignment -X- _ O
from -X- _ O
monolingual -X- _ O
corpora. -X- _ O
In -X- _ O
BTMLM, -X- _ O
a -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
input -X- _ O
monolingual -X- _ O
sentences -X- _ O
is -X- _ O
predicted -X- _ O
into -X- _ O
the -X- _ O
tokens -X- _ O
of -X- _ O
another -X- _ O
language. -X- _ O
We -X- _ O
then -X- _ O
concatenate -X- _ O
the -X- _ O
predicted -X- _ O
tokens -X- _ O
and -X- _ O
the -X- _ O
input -X- _ O
sentences -X- _ O
as -X- _ O
pseudo-parallel -X- _ O
sentences -X- _ O
to -X- _ O
train -X- _ O
the -X- _ O
model. -X- _ O
In -X- _ O
this -X- _ O
way, -X- _ O
the -X- _ O
model -X- _ O
can -X- _ O
learn -X- _ O
sentence -X- _ O
alignment -X- _ O
with -X- _ O
only -X- _ O
monolingual -X- _ O
corpora -X- _ O
and -X- _ O
overcome -X- _ O
the -X- _ O
constraint -X- _ O
of -X- _ O
the -X- _ O
parallel -X- _ O
corpus -X- _ O
size -X- _ O
while -X- _ O
improving -X- _ O
the -X- _ O
model -X- _ O
performance. -X- _ O
ERNIE-M -X- _ B-MethodName
is -X- _ O
implemented -X- _ O
on -X- _ O
the -X- _ O
basis -X- _ O
of -X- _ O
XLM-R -X- _ O
, -X- _ O
and -X- _ O
we -X- _ O
evaluate -X- _ O
its -X- _ O
performance -X- _ O
on -X- _ O
five -X- _ O
widely -X- _ O
used -X- _ O
cross-lingual -X- _ O
benchmarks: -X- _ O
XNLI -X- _ B-DatasetName
(Conneau -X- _ O
et -X- _ O
al., -X- _ O
2018) -X- _ O
for -X- _ O
crosslingual -X- _ B-TaskName
natural -X- _ I-TaskName
language -X- _ I-TaskName
inference, -X- _ I-TaskName
MLQA -X- _ B-DatasetName
(Lewis -X- _ O
et -X- _ O
al., -X- _ O
2019) -X- _ O
for -X- _ O
cross-lingual -X- _ B-TaskName
question -X- _ I-TaskName
answering, -X- _ I-TaskName
CoNLL -X- _ B-DatasetName
(Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder, -X- _ O
2003) -X- _ O
for -X- _ O
named -X- _ B-TaskName
entity -X- _ I-TaskName
recognition, -X- _ I-TaskName
cross-lingual -X- _ B-TaskName
paraphrase -X- _ I-TaskName
adversaries -X- _ I-TaskName
from -X- _ I-TaskName
word -X- _ I-TaskName
scrambling -X- _ I-TaskName
(PAWS-X) -X- _ B-DatasetName
for -X- _ O
cross-lingual -X- _ B-TaskName
paraphrase -X- _ I-TaskName
identification, -X- _ I-TaskName
and -X- _ O
Tatoeba -X- _ B-DatasetName
for -X- _ O
cross-lingual -X- _ B-TaskName
retrieval. -X- _ I-TaskName
The -X- _ O
experimental -X- _ O
results -X- _ O
demonstrate -X- _ O
that -X- _ O
ERNIE-M -X- _ B-MethodName
outperforms -X- _ O
existing -X- _ O
cross-lingual -X- _ O
models -X- _ O
and -X- _ O
achieves -X- _ O
new -X- _ O
state-of-the-art -X- _ O
(SoTA) -X- _ O
results. -X- _ O
2 -X- _ O
Related -X- _ O
Work -X- _ O

Recent -X- _ O
studies -X- _ O
have -X- _ O
demonstrated -X- _ O
that -X- _ O
pretrained -X- _ O
cross-lingual -X- _ O
models -X- _ O
achieve -X- _ O
impressive -X- _ O
performance -X- _ O
in -X- _ O
downstream -X- _ O
cross-lingual -X- _ O
tasks. -X- _ O
This -X- _ O
improvement -X- _ O
benefits -X- _ O
from -X- _ O
learning -X- _ O
a -X- _ O
large -X- _ O
amount -X- _ O
of -X- _ O
monolingual -X- _ O
and -X- _ O
parallel -X- _ O
corpora. -X- _ O
Although -X- _ O
it -X- _ O
is -X- _ O
generally -X- _ O
acknowledged -X- _ O
that -X- _ O
parallel -X- _ O
corpora -X- _ O
are -X- _ O
critical -X- _ O
for -X- _ O
improving -X- _ O
the -X- _ O
model -X- _ O
performance, -X- _ O
existing -X- _ O
methods -X- _ O
are -X- _ O
often -X- _ O
constrained -X- _ O
by -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
parallel -X- _ O
corpora, -X- _ O
especially -X- _ O
for -X- _ O
lowresource -X- _ O
languages. -X- _ O
In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
propose -X- _ O
ERNIE-M, -X- _ B-MethodName
a -X- _ O
new -X- _ O
training -X- _ O
method -X- _ O
that -X- _ O
encourages -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
align -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
multiple -X- _ O
languages -X- _ O
with -X- _ O
monolingual -X- _ O
corpora, -X- _ O
to -X- _ O
overcome -X- _ O
the -X- _ O
constraint -X- _ O
that -X- _ O
the -X- _ O
parallel -X- _ O
corpus -X- _ O
size -X- _ O
places -X- _ O
on -X- _ O
the -X- _ O
model -X- _ O
performance. -X- _ O
Our -X- _ O
key -X- _ O
insight -X- _ O
is -X- _ O
to -X- _ O
integrate -X- _ O
back-translation -X- _ O
into -X- _ O
the -X- _ O
pre-training -X- _ O
process. -X- _ O
We -X- _ O
generate -X- _ O
pseudo-parallel -X- _ O
sentence -X- _ O
pairs -X- _ O
on -X- _ O
a -X- _ O
monolingual -X- _ O
corpus -X- _ O
to -X- _ O
enable -X- _ O
the -X- _ O
learning -X- _ O
of -X- _ O
semantic -X- _ O
alignments -X- _ O
between -X- _ O
different -X- _ O
languages, -X- _ O
thereby -X- _ O
enhancing -X- _ O
the -X- _ O
semantic -X- _ O
modeling -X- _ O
of -X- _ O
cross-lingual -X- _ O
models. -X- _ O
Experimental -X- _ O
results -X- _ O
show -X- _ O
that -X- _ O
ERNIE-M -X- _ B-MethodName
outperforms -X- _ O
existing -X- _ O
cross-lingual -X- _ O
models -X- _ O
and -X- _ O
delivers -X- _ O
new -X- _ O
state-of-the-art -X- _ O
results -X- _ O
in -X- _ O
various -X- _ O
cross-lingual -X- _ O
downstream -X- _ O
tasks. -X- _ O
1 -X- _ O


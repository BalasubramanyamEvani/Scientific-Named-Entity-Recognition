-DOCSTART- -X- O
We -X- _ O
On -X- _ O
LAMBADA, -X- _ B-DatasetName
the -X- _ O
few-shot -X- _ O
capability -X- _ O
of -X- _ O
language -X- _ O
models -X- _ O
results -X- _ O
in -X- _ O
a -X- _ O
strong -X- _ O
boost -X- _ O
to -X- _ O
accuracy. -X- _ O
GPT-3 -X- _ B-MethodName
2.7B -X- _ O
outperforms -X- _ O
the -X- _ O
SOTA -X- _ O
17B -X- _ O
parameter -X- _ O
Turing-NLG -X- _ B-MethodName
[Tur20] -X- _ O
in -X- _ O
this -X- _ O
setting, -X- _ O
and -X- _ O
GPT-3 -X- _ B-MethodName
175B -X- _ O
advances -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
by -X- _ O
18%. -X- _ O
Note -X- _ O
zero-shot -X- _ O
uses -X- _ O
a -X- _ O
different -X- _ O
format -X- _ O
from -X- _ O
one-shot -X- _ O
and -X- _ O
few-shot -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
the -X- _ O
text. -X- _ O
and -X- _ O
[Tur20]) -X- _ O
and -X- _ O
argue -X- _ O
that -X- _ O
"continuing -X- _ O
to -X- _ O
expand -X- _ O
hardware -X- _ O
and -X- _ O
data -X- _ O
sizes -X- _ O
by -X- _ O
orders -X- _ O
of -X- _ O
magnitude -X- _ O
is -X- _ O
not -X- _ O
the -X- _ O
path -X- _ O
forward". -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
path -X- _ O
is -X- _ O
still -X- _ O
promising -X- _ O
and -X- _ O
in -X- _ O
a -X- _ O
zero-shot -X- _ O
setting -X- _ O
GPT-3 -X- _ B-MethodName
achieves -X- _ O
76% -X- _ B-MetricValue
on -X- _ O
LAMBADA, -X- _ B-DatasetName
a -X- _ O
gain -X- _ O
of -X- _ O
8% -X- _ O
over -X- _ O
the -X- _ O
previous -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art. -X- _ O
LAMBADA -X- _ B-DatasetName
is -X- _ O
also -X- _ O
a -X- _ O
demonstration -X- _ O
of -X- _ O
the -X- _ O
flexibility -X- _ O
of -X- _ O
few-shot -X- _ B-TaskName
learning -X- _ O
as -X- _ O
it -X- _ O
provides -X- _ O
a -X- _ O
way -X- _ O
to -X- _ O
address -X- _ O
a -X- _ O
problem -X- _ O
that -X- _ O
classically -X- _ O
occurs -X- _ O
with -X- _ O
this -X- _ O
dataset. -X- _ O
Although -X- _ O
the -X- _ O
completion -X- _ O
in -X- _ O
LAMBADA -X- _ B-DatasetName
is -X- _ O
always -X- _ O
the -X- _ O
last -X- _ O
word -X- _ O
in -X- _ O
a -X- _ O
sentence, -X- _ O
a -X- _ O
standard -X- _ O
language -X- _ O
model -X- _ O
has -X- _ O
no -X- _ O
way -X- _ O
of -X- _ O
knowing -X- _ O
this -X- _ O
detail. -X- _ O
It -X- _ O
thus -X- _ O
assigns -X- _ O
probability -X- _ O
not -X- _ O
only -X- _ O
to -X- _ O
the -X- _ O
correct -X- _ O
ending -X- _ O
but -X- _ O
also -X- _ O
to -X- _ O
other -X- _ O
valid -X- _ O
continuations -X- _ O
of -X- _ O
the -X- _ O
paragraph. -X- _ O
This -X- _ O
problem -X- _ O
has -X- _ O
been -X- _ O
partially -X- _ O
addressed -X- _ O
in -X- _ O
the -X- _ O
past -X- _ O
with -X- _ O
stop-word -X- _ O
filters -X- _ O
[RWC -X- _ O
+ -X- _ O
19] -X- _ O
(which -X- _ O
ban -X- _ O
"continuation" -X- _ O
words). -X- _ O
The -X- _ O
few-shot -X- _ B-TaskName
setting -X- _ O
instead -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
"frame" -X- _ O
the -X- _ O
task -X- _ O
as -X- _ O
a -X- _ O
cloze-test -X- _ O
and -X- _ O
allows -X- _ O
the -X- _ O
language -X- _ O
model -X- _ O
to -X- _ O
infer -X- _ O
from -X- _ O
examples -X- _ O
that -X- _ O
a -X- _ O
completion -X- _ O
of -X- _ O
exactly -X- _ O
one -X- _ O
word -X- _ O
is -X- _ O
desired. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
following -X- _ O
fill-in-the-blank -X- _ O
format: -X- _ O
Alice -X- _ O
was -X- _ O
friends -X- _ O
with -X- _ O
Bob. -X- _ O
Alice -X- _ O
went -X- _ O
to -X- _ O
visit -X- _ O
her -X- _ O
friend -X- _ O
. -X- _ O
→ -X- _ O
Bob -X- _ O
George -X- _ O
bought -X- _ O
some -X- _ O
baseball -X- _ O
equipment, -X- _ O
a -X- _ O
ball, -X- _ O
a -X- _ O
glove, -X- _ O
and -X- _ O
a -X- _ O
. -X- _ O
→ -X- _ O
When -X- _ O
presented -X- _ O
with -X- _ O
examples -X- _ O
formatted -X- _ O
this -X- _ O
way, -X- _ O
GPT-3 -X- _ B-MethodName
achieves -X- _ O
86.4% -X- _ B-MetricValue
accuracy -X- _ B-MetricName
in -X- _ O
the -X- _ O
few-shot -X- _ B-TaskName
setting, -X- _ O
an -X- _ O
increase -X- _ O
of -X- _ O
over -X- _ O
18% -X- _ O
from -X- _ O
the -X- _ O
previous -X- _ O
state-of-the-art. -X- _ O
We -X- _ O
observe -X- _ O
that -X- _ O
few-shot -X- _ O
performance -X- _ O
improves -X- _ O
strongly -X- _ O
with -X- _ O
model -X- _ O
size. -X- _ O
While -X- _ O
this -X- _ O
setting -X- _ O
decreases -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
smallest -X- _ O
model -X- _ O
by -X- _ O
almost -X- _ O
20%, -X- _ O
for -X- _ O
GPT-3 -X- _ B-MethodName
it -X- _ O
improves -X- _ O
accuracy -X- _ O
by -X- _ O
10%. -X- _ O
Finally, -X- _ O
the -X- _ O
fill-in-blank -X- _ O
method -X- _ O
is -X- _ O
not -X- _ O
effective -X- _ O
one-shot, -X- _ B-TaskName
where -X- _ O
it -X- _ O
always -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
zero-shot -X- _ B-TaskName
setting. -X- _ O
Perhaps -X- _ O
this -X- _ O
is -X- _ O
because -X- _ O
all -X- _ O
models -X- _ O
still -X- _ O
require -X- _ O
several -X- _ O
examples -X- _ O
to -X- _ O
recognize -X- _ O
the -X- _ O
pattern. -X- _ O
One -X- _ O
note -X- _ O
of -X- _ O
caution -X- _ O
is -X- _ O
that -X- _ O
an -X- _ O
analysis -X- _ O
of -X- _ O
test -X- _ O
set -X- _ O
contamination -X- _ O
identified -X- _ O
that -X- _ O
a -X- _ O
significant -X- _ O
minority -X- _ O
of -X- _ O
the -X- _ O
LAMBADA -X- _ B-DatasetName
dataset -X- _ O
appears -X- _ O
to -X- _ O
be -X- _ O
present -X- _ O
in -X- _ O
our -X- _ O
training -X- _ O
data -X- _ O
-however -X- _ O
analysis -X- _ O
performed -X- _ O
in -X- _ O
Section -X- _ O
4 -X- _ O
suggests -X- _ O
negligible -X- _ O
impact -X- _ O
on -X- _ O
performance. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
measure -X- _ O
GPT-3's -X- _ B-MethodName
ability -X- _ O
to -X- _ O
answer -X- _ O
questions -X- _ O
about -X- _ O
broad -X- _ O
factual -X- _ O
knowledge. -X- _ O
Due -X- _ O
to -X- _ O
the -X- _ O
immense -X- _ O
amount -X- _ O
of -X- _ O
possible -X- _ O
queries, -X- _ O
this -X- _ O
task -X- _ O
has -X- _ O
normally -X- _ O
been -X- _ O
approached -X- _ O
by -X- _ O
using -X- _ O
an -X- _ O
information -X- _ O
retrieval -X- _ O
system -X- _ O
to -X- _ O
find -X- _ O
relevant -X- _ O
text -X- _ O
in -X- _ O
combination -X- _ O
with -X- _ O
a -X- _ O
model -X- _ O
which -X- _ O
learns -X- _ O
to -X- _ O
generate -X- _ O
an -X- _ O
answer -X- _ O
given -X- _ O
the -X- _ O
question -X- _ O
and -X- _ O
the -X- _ O
retrieved -X- _ O
text. -X- _ O
Since -X- _ O
this -X- _ O
setting -X- _ O
allows -X- _ O
a -X- _ O
system -X- _ O
to -X- _ O
search -X- _ O
for -X- _ O
and -X- _ O
condition -X- _ O
on -X- _ O
text -X- _ O
which -X- _ O
potentially -X- _ O
contains -X- _ O
the -X- _ O
answer -X- _ O
it -X- _ O
is -X- _ O
denoted -X- _ O
"open-book". -X- _ O
[RRS20] -X- _ O
recently -X- _ O
demonstrated -X- _ O
that -X- _ O
a -X- _ O
large -X- _ O
language -X- _ O
model -X- _ O
can -X- _ O
perform -X- _ O
surprisingly -X- _ O
well -X- _ O
directly -X- _ O
answering -X- _ O
the -X- _ O
questions -X- _ O
without -X- _ O
conditioning -X- _ O
on -X- _ O
auxilliary -X- _ O
information. -X- _ O
They -X- _ O
denote -X- _ O
this -X- _ O
more -X- _ O
restrictive -X- _ O
evaluation -X- _ O
setting -X- _ O
as -X- _ O
"closed-book". -X- _ O
Their -X- _ O
work -X- _ O
suggests -X- _ O
that -X- _ O
even -X- _ O
higher-capacity -X- _ O
models -X- _ O
could -X- _ O
perform -X- _ O
even -X- _ O
better -X- _ O
and -X- _ O
we -X- _ O
test -X- _ O
this -X- _ O
hypothesis -X- _ O
with -X- _ O
GPT-3. -X- _ B-MethodName
We -X- _ O
evaluate -X- _ O
GPT-3 -X- _ B-MethodName
on -X- _ O
the -X- _ O
3 -X- _ O
datasets -X- _ O
in -X- _ O
[RRS20]: -X- _ O
Natural -X- _ B-DatasetName
Questions -X- _ I-DatasetName
[KPR -X- _ O
+ -X- _ O
19], -X- _ O
WebQuestions -X- _ B-DatasetName
[BCFL13], -X- _ O
and -X- _ O
TriviaQA -X- _ B-DatasetName
[JCWZ17], -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
splits. -X- _ O
Note -X- _ O
that -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
all -X- _ O
results -X- _ O
being -X- _ O
in -X- _ O
the -X- _ O
closed-book -X- _ O
setting, -X- _ O
our -X- _ O
use -X- _ O
of -X- _ O
few-shot, -X- _ B-TaskName
one-shot, -X- _ B-TaskName
and -X- _ O
zero-shot -X- _ B-TaskName
evaluations -X- _ O
represent -X- _ O
an -X- _ O
even -X- _ O
stricter -X- _ O
setting -X- _ O
than -X- _ O
previous -X- _ O
closed-book -X- _ O
QA -X- _ O
work: -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
external -X- _ O
content -X- _ O
not -X- _ O
being -X- _ O
allowed, -X- _ O
fine-tuning -X- _ O
on -X- _ O
the -X- _ O
Q&A -X- _ O
dataset -X- _ O
itself -X- _ O
is -X- _ O
also -X- _ O
not -X- _ O
permitted. -X- _ O
The -X- _ O
results -X- _ O
for -X- _ O
GPT-3 -X- _ B-MethodName
are -X- _ O
shown -X- _ O
in -X- _ O
GPT-3's -X- _ B-MethodName
few-shot -X- _ O
result -X- _ O
further -X- _ O
improves -X- _ O
performance -X- _ O
another -X- _ O
3.2% -X- _ O
beyond -X- _ O
this. -X- _ O
On -X- _ O
WebQuestions -X- _ B-DatasetName
(WebQs), -X- _ B-DatasetName
GPT-3 -X- _ B-MethodName
achieves -X- _ O
14.4% -X- _ B-MetricValue
in -X- _ O
the -X- _ O
zero-shot -X- _ O
setting, -X- _ O
25.3% -X- _ B-MetricValue
in -X- _ O
the -X- _ O
one-shot -X- _ O
setting, -X- _ O
and -X- _ O
41.5% -X- _ B-MetricValue
in -X- _ O
the -X- _ O
few-shot -X- _ O
setting. -X- _ O
This -X- _ O
compares -X- _ O
to -X- _ O
37.4% -X- _ B-MetricValue
for -X- _ O
fine-tuned -X- _ O
T5-11B, -X- _ O
and -X- _ O
44.7% -X- _ B-MetricValue
for -X- _ O
fine-tuned -X- _ O
T5-11B+SSM, -X- _ O
which -X- _ O
uses -X- _ O
a -X- _ O
Q&A-specific -X- _ O
pre-training -X- _ O
procedure. -X- _ O
GPT-3 -X- _ B-MethodName
in -X- _ O
the -X- _ O
few-shot -X- _ O
setting -X- _ O
approaches -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
state-of-the-art -X- _ O
fine-tuned -X- _ O
models. -X- _ O
Notably, -X- _ O
compared -X- _ O
to -X- _ O
TriviaQA, -X- _ B-DatasetName
WebQS -X- _ B-MetricValue
shows -X- _ O
a -X- _ O
much -X- _ O
larger -X- _ O
gain -X- _ O
from -X- _ O
zero-shot -X- _ B-TaskName
to -X- _ O
few-shot -X- _ B-TaskName
(and -X- _ O
indeed -X- _ O
its -X- _ O
zero-shot -X- _ B-TaskName
and -X- _ O
one-shot -X- _ B-TaskName
performance -X- _ O
are -X- _ O
poor), -X- _ O
perhaps -X- _ O
suggesting -X- _ O
that -X- _ O
the -X- _ O
WebQs -X- _ O
questions -X- _ O
and/or -X- _ O
the -X- _ O
style -X- _ O
of -X- _ O
their -X- _ O
answers -X- _ O
are -X- _ O
out-of-distribution -X- _ O
for -X- _ O
GPT-3. -X- _ B-MethodName
Nevertheless, -X- _ O
GPT-3 -X- _ B-MethodName
appears -X- _ O
able -X- _ O
to -X- _ O
adapt -X- _ O
to -X- _ O
this -X- _ O
distribution, -X- _ O
recovering -X- _ O
strong -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
few-shot -X- _ O
setting. -X- _ O
On -X- _ O
Natural -X- _ O
Questions -X- _ O
(NQs) -X- _ O
GPT-3 -X- _ O
achieves -X- _ O
14.6% -X- _ B-MetricValue
in -X- _ O
the -X- _ O
zero-shot -X- _ O
setting, -X- _ O
23.0% -X- _ O
in -X- _ O
the -X- _ O
one-shot -X- _ O
setting, -X- _ O
and -X- _ O
29.9% -X- _ B-MetricValue
in -X- _ O
the -X- _ O
few-shot -X- _ O
setting, -X- _ O
compared -X- _ O
to -X- _ O
36.6% -X- _ B-MetricValue
for -X- _ O
fine-tuned -X- _ O
T5 -X- _ O
11B+SSM. -X- _ O
Similar -X- _ O
to -X- _ O
WebQS, -X- _ B-DatasetName
the -X- _ O
large -X- _ O
gain -X- _ O
from -X- _ O
zero-shot -X- _ B-TaskName
to -X- _ O
few-shot -X- _ B-TaskName
may -X- _ O
suggest -X- _ O
a -X- _ O
distribution -X- _ O
shift, -X- _ O
and -X- _ O
may -X- _ O
also -X- _ O
explain -X- _ O
the -X- _ O
less -X- _ O
competitive -X- _ O
performance -X- _ O
compared -X- _ O
to -X- _ O
TriviaQA -X- _ B-DatasetName
and -X- _ O
WebQS. -X- _ B-DatasetName
In -X- _ O
particular, -X- _ O
the -X- _ O
questions -X- _ O
in -X- _ O
NQs -X- _ B-DatasetName
tend -X- _ O
towards -X- _ O
very -X- _ O
fine-grained -X- _ O
knowledge -X- _ O
on -X- _ O
Wikipedia -X- _ O
specifically -X- _ O
which -X- _ O
could -X- _ O
be -X- _ O
testing -X- _ O
the -X- _ O
limits -X- _ O
of -X- _ O
GPT-3's -X- _ B-MethodName
capacity -X- _ O
and -X- _ O
broad -X- _ O
pretraining -X- _ O
distribution. -X- _ O
Overall, -X- _ O
on -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
three -X- _ O
datasets -X- _ O
GPT-3's -X- _ B-DatasetName
one-shot -X- _ O
matches -X- _ O
the -X- _ O
open-domain -X- _ O
fine-tuning -X- _ O
SOTA. -X- _ O
On -X- _ O
the -X- _ O
other -X- _ O
two -X- _ O
datasets -X- _ O
it -X- _ O
approaches -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
the -X- _ O
closed-book -X- _ O
SOTA -X- _ O
despite -X- _ O
not -X- _ O
using -X- _ O
fine-tuning. -X- _ O
On -X- _ O
all -X- _ O
3 -X- _ O
datasets, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
performance -X- _ O
scales -X- _ O
very -X- _ O
smoothly -X- _ O
with -X- _ O
model -X- _ O
size -X- _ O
(Figure -X- _ O
3.3 -X- _ O
and -X- _ O
Appendix -X- _ O
H -X- _ O
Figure -X- _ O
H.7), -X- _ O
possibly -X- _ O
reflecting -X- _ O
the -X- _ O
idea -X- _ O
that -X- _ O
model -X- _ O
capacity -X- _ O
translates -X- _ O
directly -X- _ O
to -X- _ O
more -X- _ O
'knowledge' -X- _ O
absorbed -X- _ O
in -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
model. -X- _ O

We -X- _ O
next -X- _ O
evaluate -X- _ B-MethodName
GPT-3 -X- _ I-MethodName
on -X- _ O
the -X- _ O
StoryCloze -X- _ B-DatasetName
2016 -X- _ I-DatasetName
dataset -X- _ O
[MCH -X- _ O
+ -X- _ O
16], -X- _ O
which -X- _ O
involves -X- _ O
selecting -X- _ O
the -X- _ O
correct -X- _ O
ending -X- _ O
sentence -X- _ O
for -X- _ O
five-sentence -X- _ O
long -X- _ O
stories. -X- _ O
Here -X- _ O
GPT-3 -X- _ B-MethodName
achieves -X- _ O
83.2% -X- _ B-MetricValue
in -X- _ O
the -X- _ O
zero-shot -X- _ B-TaskName
setting -X- _ O
and -X- _ O
87.7% -X- _ B-MetricValue
in -X- _ O
the -X- _ O
few-shot -X- _ B-TaskName
setting -X- _ O
(with -X- _ O
K -X- _ B-HyperparameterName
= -X- _ O
70). -X- _ B-HyperparameterValue
This -X- _ O
is -X- _ O
still -X- _ O
4.1% -X- _ O
lower -X- _ O
than -X- _ O
the -X- _ O
fine-tuned -X- _ O
SOTA -X- _ O
using -X- _ O
a -X- _ O
BERT -X- _ B-MethodName
based -X- _ O
model -X- _ O
[LDL19] -X- _ O
but -X- _ O
improves -X- _ O
over -X- _ O
previous -X- _ O
zero-shot -X- _ O
results -X- _ O
by -X- _ O
roughly -X- _ O
10%. -X- _ O

The -X- _ O
HellaSwag -X- _ B-DatasetName
dataset -X- _ O
[ZHB -X- _ O
+ -X- _ O
19] -X- _ O
involves -X- _ O
picking -X- _ O
the -X- _ O
best -X- _ O
ending -X- _ O
to -X- _ O
a -X- _ O
story -X- _ O
or -X- _ O
set -X- _ O
of -X- _ O
instructions. -X- _ O
The -X- _ O
examples -X- _ O
were -X- _ O
adversarially -X- _ O
mined -X- _ O
to -X- _ O
be -X- _ O
difficult -X- _ O
for -X- _ O
language -X- _ O
models -X- _ O
while -X- _ O
remaining -X- _ O
easy -X- _ O
for -X- _ O
humans -X- _ O
(who -X- _ O
achieve -X- _ O
95.6% -X- _ B-MetricValue
accuracy). -X- _ B-MetricName
GPT-3 -X- _ O
achieves -X- _ O
78.1% -X- _ B-MetricValue
accuracy -X- _ B-MetricName
in -X- _ O
the -X- _ O
one-shot -X- _ O
setting -X- _ O
and -X- _ O
79.3% -X- _ B-MetricValue
accuracy -X- _ B-MetricName
in -X- _ O
the -X- _ O
few-shot -X- _ O
setting, -X- _ O
outperforming -X- _ O
the -X- _ O
75.4% -X- _ B-MetricValue
accuracy -X- _ B-MetricName
of -X- _ O
a -X- _ O
fine-tuned -X- _ O
1.5B -X- _ O
parameter -X- _ O
language -X- _ O
model -X- _ O
[ZHR -X- _ O
+ -X- _ O
19] -X- _ O
but -X- _ O
still -X- _ O
a -X- _ O
fair -X- _ O
amount -X- _ O
lower -X- _ O
than -X- _ O
the -X- _ O
overall -X- _ O
SOTA -X- _ O
of -X- _ O
85.6% -X- _ B-MetricValue
achieved -X- _ O
by -X- _ O
the -X- _ O
fine-tuned -X- _ O
multi-task -X- _ O
model -X- _ O
ALUM. -X- _ O

In -X- _ O
this -X- _ O
section -X- _ O
we -X- _ O
test -X- _ O
GPT-3's -X- _ B-MethodName
performance -X- _ O
on -X- _ O
the -X- _ O
traditional -X- _ O
task -X- _ O
of -X- _ O
language -X- _ O
modeling, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
related -X- _ O
tasks -X- _ O
that -X- _ O
involve -X- _ O
predicting -X- _ O
a -X- _ O
single -X- _ O
word -X- _ O
of -X- _ O
interest, -X- _ O
completing -X- _ O
a -X- _ O
sentence -X- _ O
or -X- _ O
paragraph, -X- _ O
or -X- _ O
choosing -X- _ O
between -X- _ O
possible -X- _ O
completions -X- _ O
of -X- _ O
a -X- _ O
piece -X- _ O
of -X- _ O
text. -X- _ O

In -X- _ O
Figure -X- _ O
3.1 -X- _ O
we -X- _ O
display -X- _ O
training -X- _ O
curves -X- _ O
for -X- _ O
the -X- _ O
8 -X- _ O
models -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
2. -X- _ O
For -X- _ O
this -X- _ O
graph -X- _ O
we -X- _ O
also -X- _ O
include -X- _ O
6 -X- _ O
additional -X- _ O
extra-small -X- _ O
models -X- _ O
with -X- _ O
as -X- _ O
few -X- _ O
as -X- _ O
100,000 -X- _ O
parameters. -X- _ O
As -X- _ O
observed -X- _ O
in -X- _ O
[KMH -X- _ O
+ -X- _ O
20], -X- _ O
language -X- _ O
modeling -X- _ O
performance -X- _ O
follows -X- _ O
a -X- _ O
power-law -X- _ O
when -X- _ O
making -X- _ O
efficient -X- _ O
use -X- _ O
of -X- _ O
training -X- _ O
compute. -X- _ O
After -X- _ O
extending -X- _ O
this -X- _ O
trend -X- _ O
by -X- _ O
two -X- _ O
more -X- _ O
orders -X- _ O
of -X- _ O
magnitude, -X- _ O
we -X- _ O
observe -X- _ O
only -X- _ O
a -X- _ O
slight -X- _ O
(if -X- _ O
any) -X- _ O
departure -X- _ O
from -X- _ O
the -X- _ O
power-law. -X- _ O
One -X- _ O
might -X- _ O
worry -X- _ O
that -X- _ O
these -X- _ O
improvements -X- _ O
in -X- _ O
cross-entropy -X- _ O
loss -X- _ O
come -X- _ O
only -X- _ O
from -X- _ O
modeling -X- _ O
spurious -X- _ O
details -X- _ O
of -X- _ O
our -X- _ O
training -X- _ O
corpus. -X- _ O
However, -X- _ O
we -X- _ O
will -X- _ O
see -X- _ O
in -X- _ O
the -X- _ O
following -X- _ O
sections -X- _ O
that -X- _ O
improvements -X- _ O
in -X- _ O
cross-entropy -X- _ O
loss -X- _ O
lead -X- _ O
to -X- _ O
consistent -X- _ O
performance -X- _ O
gains -X- _ O
across -X- _ O
a -X- _ O
broad -X- _ O
spectrum -X- _ O
of -X- _ O
natural -X- _ O
language -X- _ O
tasks. -X- _ O
Below, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
8 -X- _ O
models -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
2 -X- _ O
(the -X- _ O
175 -X- _ O
billion -X- _ O
parameter -X- _ O
parameter -X- _ O
GPT-3 -X- _ B-MethodName
and -X- _ O
7 -X- _ O
smaller -X- _ O
models) -X- _ O
on -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
datasets. -X- _ O
We -X- _ O
group -X- _ O
the -X- _ O
datasets -X- _ O
into -X- _ O
9 -X- _ O
categories -X- _ O
representing -X- _ O
roughly -X- _ O
similar -X- _ O
tasks. -X- _ O
In -X- _ O
Section -X- _ O
3.1 -X- _ O
we -X- _ O
evaluate -X- _ O
on -X- _ O
traditional -X- _ O
language -X- _ O
modeling -X- _ O
tasks -X- _ O
and -X- _ O
tasks -X- _ O
that -X- _ O
are -X- _ O
similar -X- _ O
to -X- _ O
language -X- _ O
modeling, -X- _ O
such -X- _ O
as -X- _ O
Cloze -X- _ B-TaskName
tasks -X- _ O
and -X- _ O
sentence/paragraph -X- _ O
completion -X- _ O
tasks. -X- _ O
In -X- _ O
Section -X- _ O
3.2 -X- _ O
we -X- _ O
evaluate -X- _ O
on -X- _ O
"closed -X- _ B-TaskName
book" -X- _ I-TaskName
question -X- _ I-TaskName
answering -X- _ I-TaskName
tasks: -X- _ O
tasks -X- _ O
which -X- _ O
require -X- _ O
using -X- _ O
the -X- _ O
information -X- _ O
stored -X- _ O
in -X- _ O
the -X- _ O
model's -X- _ O
parameters -X- _ O
to -X- _ O
answer -X- _ O
general -X- _ O
knowledge -X- _ O
questions. -X- _ O
In -X- _ O
Section -X- _ O
3.3 -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
model's -X- _ O
ability -X- _ O
to -X- _ O
translate -X- _ O
between -X- _ O
languages -X- _ O
(especially -X- _ O
one-shot -X- _ B-TaskName
and -X- _ O
few-shot). -X- _ B-TaskName
In -X- _ O
Section -X- _ O
3.4 -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
model's -X- _ O
performance -X- _ O
on -X- _ O
Winograd -X- _ B-TaskName
Schema-like -X- _ I-TaskName
tasks. -X- _ O
In -X- _ O
Section -X- _ O
3.5 -X- _ O
we -X- _ O
evaluate -X- _ O
on -X- _ O
datasets -X- _ O
that -X- _ O
involve -X- _ O
commonsense -X- _ O
reasoning -X- _ O
or -X- _ O
question -X- _ O
answering. -X- _ O
In -X- _ O
Section -X- _ O
3.6 -X- _ O
we -X- _ O
evaluate -X- _ O
on -X- _ O
reading -X- _ O
comprehension -X- _ O
tasks, -X- _ O
in -X- _ O
Section -X- _ O
3.7 -X- _ O
we -X- _ O
evaluate -X- _ O
on -X- _ O
the -X- _ O
SuperGLUE -X- _ B-DatasetName
benchmark -X- _ O
suite, -X- _ O
and -X- _ O
in -X- _ O
3.8 -X- _ O
we -X- _ O
briefly -X- _ O
explore -X- _ O
NLI. -X- _ B-TaskName
Finally, -X- _ O
in -X- _ O
Section -X- _ O
3.9, -X- _ O
we -X- _ O
invent -X- _ O
some -X- _ O
additional -X- _ O
tasks -X- _ O
designed -X- _ O
especially -X- _ O
to -X- _ O
probe -X- _ O
in-context -X- _ O
learning -X- _ O
abilitiesthese -X- _ O
tasks -X- _ O
focus -X- _ O
on -X- _ O
on-the-fly -X- _ O
reasoning, -X- _ O
adaptation -X- _ O
skills, -X- _ O
or -X- _ O
open-ended -X- _ O
text -X- _ O
synthesis. -X- _ O
We -X- _ O
evaluate -X- _ O
all -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
few-shot, -X- _ B-TaskName
one-shot, -X- _ B-TaskName
and -X- _ O
zero-shot -X- _ B-TaskName
settings. -X- _ O

For -X- _ O
few-shot -X- _ B-TaskName
learning, -X- _ I-TaskName
we -X- _ O
evaluate -X- _ O
each -X- _ O
example -X- _ O
in -X- _ O
the -X- _ O
evaluation -X- _ O
set -X- _ O
by -X- _ O
randomly -X- _ O
drawing -X- _ O
K -X- _ B-HyperparameterName
examples -X- _ O
from -X- _ O
that -X- _ O
task's -X- _ O
training -X- _ O
set -X- _ O
as -X- _ O
conditioning, -X- _ O
delimited -X- _ O
by -X- _ O
1 -X- _ O
or -X- _ O
2 -X- _ O
newlines -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
task. -X- _ O
For -X- _ O
LAMBADA -X- _ B-DatasetName
and -X- _ O
Storycloze -X- _ B-DatasetName
there -X- _ O
is -X- _ O
no -X- _ O
supervised -X- _ O
training -X- _ O
set -X- _ O
available -X- _ O
so -X- _ O
we -X- _ O
draw -X- _ O
conditioning -X- _ O
examples -X- _ O
from -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
and -X- _ O
evaluate -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set. -X- _ O
For -X- _ O
Winograd -X- _ B-DatasetName
(the -X- _ O
original, -X- _ O
not -X- _ O
SuperGLUE -X- _ O
version) -X- _ O
there -X- _ O
is -X- _ O
only -X- _ O
one -X- _ O
dataset, -X- _ O
so -X- _ O
we -X- _ O
draw -X- _ O
conditioning -X- _ O
examples -X- _ O
directly -X- _ O
from -X- _ O
it. -X- _ O
K -X- _ B-HyperparameterName
can -X- _ O
be -X- _ O
any -X- _ O
value -X- _ O
from -X- _ O
0 -X- _ B-HyperparameterValue
to -X- _ O
the -X- _ O
maximum -X- _ O
amount -X- _ O
allowed -X- _ O
by -X- _ O
the -X- _ O
model's -X- _ O
context -X- _ O
window, -X- _ O
which -X- _ O
is -X- _ O
n -X- _ B-HyperparameterName
ctx -X- _ I-HyperparameterName
= -X- _ O
2048 -X- _ B-HyperparameterValue
for -X- _ O
all -X- _ O
models -X- _ O
and -X- _ O
typically -X- _ O
fits -X- _ O
10 -X- _ B-HyperparameterValue
to -X- _ I-HyperparameterValue
100 -X- _ I-HyperparameterValue
examples. -X- _ O
Larger -X- _ O
values -X- _ O
of -X- _ O
K -X- _ B-HyperparameterName
are -X- _ O
usually -X- _ O
but -X- _ O
not -X- _ O
always -X- _ O
better, -X- _ O
so -X- _ O
when -X- _ O
a -X- _ O
separate -X- _ O
development -X- _ O
and -X- _ O
test -X- _ O
set -X- _ O
are -X- _ O
available, -X- _ O
we -X- _ O
experiment -X- _ O
with -X- _ O
a -X- _ O
few -X- _ O
values -X- _ O
of -X- _ O
K -X- _ B-HyperparameterName
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
and -X- _ O
then -X- _ O
run -X- _ O
the -X- _ O
best -X- _ O
value -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set. -X- _ O
For -X- _ O
some -X- _ O
tasks -X- _ O
(see -X- _ O
Appendix -X- _ O
G) -X- _ O
we -X- _ O
also -X- _ O
use -X- _ O
a -X- _ O
natural -X- _ O
language -X- _ O
prompt -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
(or -X- _ O
for -X- _ O
K -X- _ B-HyperparameterName
= -X- _ O
0, -X- _ B-HyperparameterValue
instead -X- _ O
of) -X- _ O
demonstrations. -X- _ O
On -X- _ O
tasks -X- _ O
that -X- _ O
involve -X- _ O
choosing -X- _ O
one -X- _ O
correct -X- _ O
completion -X- _ O
from -X- _ O
several -X- _ O
options -X- _ O
(multiple -X- _ O
choice), -X- _ O
we -X- _ O
provide -X- _ O
K -X- _ B-HyperparameterName
examples -X- _ O
of -X- _ O
context -X- _ O
plus -X- _ O
correct -X- _ O
completion, -X- _ O
followed -X- _ O
by -X- _ O
one -X- _ O
example -X- _ O
of -X- _ O
context -X- _ O
only, -X- _ O
and -X- _ O
compare -X- _ O
the -X- _ O
LM -X- _ O
likelihood -X- _ O
of -X- _ O
each -X- _ O
completion. -X- _ O
For -X- _ O
most -X- _ O
tasks -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
per-token -X- _ O
likelihood -X- _ O
(to -X- _ O
normalize -X- _ O
for -X- _ O
length), -X- _ O
however -X- _ O
on -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
datasets -X- _ O
(ARC, -X- _ B-DatasetName
OpenBookQA, -X- _ B-DatasetName
and -X- _ O
RACE) -X- _ B-DatasetName
we -X- _ O
gain -X- _ O
additional -X- _ O
benefit -X- _ O
as -X- _ O
measured -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set -X- _ O
by -X- _ O
normalizing -X- _ O
by -X- _ O
the -X- _ O
unconditional -X- _ O
probability -X- _ O
of -X- _ O
each -X- _ O
completion, -X- _ O
by -X- _ O
computing -X- _ O
P -X- _ O
(completion|context) -X- _ O
P -X- _ O
(completion|answer -X- _ O
context) -X- _ O
, -X- _ O
where -X- _ O
answer -X- _ O
context -X- _ O
is -X- _ O
the -X- _ O
string -X- _ O
"Answer: -X- _ O
" -X- _ O
or -X- _ O
"A: -X- _ O
" -X- _ O
and -X- _ O
is -X- _ O
used -X- _ O
to -X- _ O
prompt -X- _ O
that -X- _ O
the -X- _ O
completion -X- _ O
should -X- _ O
be -X- _ O
an -X- _ O
answer -X- _ O
but -X- _ O
is -X- _ O
otherwise -X- _ O
generic. -X- _ O
On -X- _ O
tasks -X- _ O
that -X- _ O
involve -X- _ O
binary -X- _ O
classification, -X- _ O
we -X- _ O
give -X- _ O
the -X- _ O
options -X- _ O
more -X- _ O
semantically -X- _ O
meaningful -X- _ O
names -X- _ O
(e.g. -X- _ O
"True" -X- _ O
or -X- _ O
"False" -X- _ O
rather -X- _ O
than -X- _ O
0 -X- _ O
or -X- _ O
1) -X- _ O
and -X- _ O
then -X- _ O
treat -X- _ O
the -X- _ O
task -X- _ O
like -X- _ O
multiple -X- _ O
choice; -X- _ O
we -X- _ O
also -X- _ O
sometimes -X- _ O
frame -X- _ O
the -X- _ O
task -X- _ O
similar -X- _ O
to -X- _ O
what -X- _ O
is -X- _ O
done -X- _ O
by -X- _ O
[RSR -X- _ O
+ -X- _ O
19] -X- _ O
(see -X- _ O
Appendix -X- _ O
G) -X- _ O
for -X- _ O
details. -X- _ O
On -X- _ O
tasks -X- _ O
with -X- _ O
free-form -X- _ O
completion, -X- _ O
we -X- _ O
use -X- _ O
beam -X- _ O
search -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
parameters -X- _ O
as -X- _ O
[RSR -X- _ O
+ -X- _ O
19]: -X- _ O
a -X- _ O
beam -X- _ B-HyperparameterName
width -X- _ I-HyperparameterName
of -X- _ O
4 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
length -X- _ O
penalty -X- _ O
of -X- _ O
α -X- _ B-HyperparameterName
= -X- _ O
0.6. -X- _ B-HyperparameterValue
We -X- _ O
score -X- _ O
the -X- _ O
model -X- _ O
using -X- _ O
F1 -X- _ B-MetricName
similarity -X- _ O
score, -X- _ O
BLEU, -X- _ B-MetricName
or -X- _ O
exact -X- _ O
match, -X- _ O
depending -X- _ O
on -X- _ O
what -X- _ O
is -X- _ O
standard -X- _ O
for -X- _ O
the -X- _ O
dataset -X- _ O
at -X- _ O
hand. -X- _ O
Final -X- _ O
results -X- _ O
are -X- _ O
reported -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
when -X- _ O
publicly -X- _ O
available, -X- _ O
for -X- _ O
each -X- _ O
model -X- _ O
size -X- _ O
and -X- _ O
learning -X- _ O
setting -X- _ O
(zero-, -X- _ B-TaskName
one-, -X- _ B-TaskName
and -X- _ O
few-shot). -X- _ B-TaskName
When -X- _ O
the -X- _ O
test -X- _ O
set -X- _ O
is -X- _ O
private, -X- _ O
our -X- _ O
model -X- _ O
is -X- _ O
often -X- _ O
too -X- _ O
large -X- _ O
to -X- _ O
fit -X- _ O
on -X- _ O
the -X- _ O
test -X- _ O
server, -X- _ O
so -X- _ O
we -X- _ O
report -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set. -X- _ O
We -X- _ O
do -X- _ O
submit -X- _ O
to -X- _ O
the -X- _ O
test -X- _ O
server -X- _ O
on -X- _ O
a -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
datasets -X- _ O
(SuperGLUE, -X- _ B-DatasetName
TriviaQA, -X- _ B-DatasetName
PiQa) -X- _ B-DatasetName
where -X- _ O
we -X- _ O
were -X- _ O
able -X- _ O
to -X- _ O
make -X- _ O
submission -X- _ O
work, -X- _ O
and -X- _ O
we -X- _ O
submit -X- _ O
only -X- _ O
the -X- _ O
200B -X- _ O
few-shot -X- _ B-TaskName
results, -X- _ O
and -X- _ O
report -X- _ O
development -X- _ O
set -X- _ O
results -X- _ O
for -X- _ O
everything -X- _ O
else. -X- _ O

As -X- _ O
found -X- _ O
in -X- _ O
[KMH -X- _ O
+ -X- _ O
20,MKAT18], -X- _ O
larger -X- _ O
models -X- _ O
can -X- _ O
typically -X- _ O
use -X- _ O
a -X- _ O
larger -X- _ O
batch -X- _ B-HyperparameterName
size, -X- _ I-HyperparameterName
but -X- _ O
require -X- _ O
a -X- _ O
smaller -X- _ O
learning -X- _ B-HyperparameterName
rate. -X- _ I-HyperparameterName
We -X- _ O
measure -X- _ O
the -X- _ O
gradient -X- _ O
noise -X- _ O
scale -X- _ O
during -X- _ O
training -X- _ O
and -X- _ O
use -X- _ O
it -X- _ O
to -X- _ O
guide -X- _ O
our -X- _ O
choice -X- _ O
of -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
[MKAT18]. -X- _ O
Table -X- _ O
2.1 -X- _ O
shows -X- _ O
the -X- _ O
parameter -X- _ O
settings -X- _ O
we -X- _ O
used. -X- _ O
To -X- _ O
train -X- _ O
the -X- _ O
larger -X- _ O
models -X- _ O
without -X- _ O
running -X- _ O
out -X- _ O
of -X- _ O
memory, -X- _ O
we -X- _ O
use -X- _ O
a -X- _ O
mixture -X- _ O
of -X- _ O
model -X- _ O
parallelism -X- _ O
within -X- _ O
each -X- _ O
matrix -X- _ O
multiply -X- _ O
and -X- _ O
model -X- _ O
parallelism -X- _ O
across -X- _ O
the -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
network. -X- _ O
All -X- _ O
models -X- _ O
were -X- _ O
trained -X- _ O
on -X- _ O
V100 -X- _ O
GPU's -X- _ O
on -X- _ O
part -X- _ O
of -X- _ O
a -X- _ O
high-bandwidth -X- _ O
cluster -X- _ O
provided -X- _ O
by -X- _ O
Microsoft. -X- _ O
Details -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
process -X- _ O
and -X- _ O
hyperparameter -X- _ O
settings -X- _ O
are -X- _ O
described -X- _ O
in -X- _ O
Appendix -X- _ O
B. -X- _ O

Datasets -X- _ O
for -X- _ O
language -X- _ O
models -X- _ O
have -X- _ O
rapidly -X- _ O
expanded, -X- _ O
culminating -X- _ O
in -X- _ O
the -X- _ O
Common -X- _ B-DatasetName
Crawl -X- _ I-DatasetName
dataset -X- _ I-DatasetName
2 -X- _ I-DatasetName
[RSR -X- _ O
+ -X- _ O
19] -X- _ O
constituting -X- _ O
nearly -X- _ O
a -X- _ O
trillion -X- _ O
words. -X- _ O
This -X- _ O
size -X- _ O
of -X- _ O
dataset -X- _ O
is -X- _ O
sufficient -X- _ O
to -X- _ O
train -X- _ O
our -X- _ O
largest -X- _ O
models -X- _ O
without -X- _ O
ever -X- _ O
updating -X- _ O
on -X- _ O
the -X- _ O
same -X- _ O
sequence -X- _ O
twice. -X- _ O
However, -X- _ O
we -X- _ O
have -X- _ O
found -X- _ O
that -X- _ O
unfiltered -X- _ O
or -X- _ O
lightly -X- _ O
filtered -X- _ O
versions -X- _ O
of -X- _ O
Common -X- _ B-DatasetName
Crawl -X- _ I-DatasetName
tend -X- _ O
to -X- _ O
have -X- _ O
lower -X- _ O
quality -X- _ O
than -X- _ O
more -X- _ O
curated -X- _ O
datasets. -X- _ O
Therefore, -X- _ O
we -X- _ O
took -X- _ O
3 -X- _ O
steps -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
average -X- _ O
quality -X- _ O
of -X- _ O
our -X- _ O
datasets: -X- _ O
(1) -X- _ O
we -X- _ O
downloaded -X- _ O
and -X- _ O
filtered -X- _ O
a -X- _ B-DatasetName
version -X- _ I-DatasetName
of -X- _ I-DatasetName
CommonCrawl -X- _ I-DatasetName
based -X- _ O
on -X- _ O
similarity -X- _ O
to -X- _ O
a -X- _ O
range -X- _ O
of -X- _ O
high-quality -X- _ O
reference -X- _ O
corpora, -X- _ O
(2) -X- _ O
we -X- _ O
performed -X- _ O
fuzzy -X- _ O
deduplication -X- _ O
at -X- _ O
the -X- _ O
document -X- _ O
level, -X- _ O
within -X- _ O
and -X- _ O
across -X- _ O
datasets, -X- _ O
to -X- _ O
prevent -X- _ O
redundancy -X- _ O
and -X- _ O
preserve -X- _ O
the -X- _ O
integrity -X- _ O
of -X- _ O
our -X- _ O
held-out -X- _ O
validation -X- _ O
set -X- _ O
as -X- _ O
an -X- _ O
accurate -X- _ O
measure -X- _ O
of -X- _ O
overfitting, -X- _ O
and -X- _ O
(3) -X- _ O
we -X- _ O
also -X- _ O
added -X- _ O
known -X- _ O
high-quality -X- _ O
reference -X- _ O
corpora -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
mix -X- _ O
to -X- _ O
augment -X- _ O
CommonCrawl -X- _ O
and -X- _ O
increase -X- _ O
its -X- _ O
diversity. -X- _ O
Details -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
two -X- _ O
points -X- _ O
(processing -X- _ O
of -X- _ O
Common -X- _ B-DatasetName
Crawl) -X- _ I-DatasetName
are -X- _ O
described -X- _ O
in -X- _ O
Appendix -X- _ O
A. -X- _ O
For -X- _ O
the -X- _ O
third, -X- _ O
we -X- _ O
added -X- _ O
several -X- _ O
curated -X- _ O
high-quality -X- _ O
datasets, -X- _ O
including -X- _ O
an -X- _ O
expanded -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
WebText -X- _ O
dataset -X- _ O
[RWC -X- _ O
+ -X- _ O
19], -X- _ O
collected -X- _ O
by -X- _ O
scraping -X- _ O
links -X- _ O
over -X- _ O
a -X- _ O
longer -X- _ O
period -X- _ O
of -X- _ O
time, -X- _ O
and -X- _ O
first -X- _ O
described -X- _ O
in -X- _ O
[KMH -X- _ O
+ -X- _ O
20], -X- _ O
two -X- _ O
internet-based -X- _ O
books -X- _ O
corpora -X- _ O
(Books1 -X- _ O
and -X- _ O
Books2) -X- _ O
and -X- _ O
English-language -X- _ O
Wikipedia. -X- _ O
Table -X- _ O
2.2 -X- _ O
shows -X- _ O
the -X- _ O
final -X- _ O
mixture -X- _ O
of -X- _ O
datasets -X- _ O
that -X- _ O
we -X- _ O
used -X- _ O
in -X- _ O
training. -X- _ O
The -X- _ O
CommonCrawl -X- _ B-DatasetName
data -X- _ O
was -X- _ O
downloaded -X- _ O
from -X- _ O
41 -X- _ O
shards -X- _ O
of -X- _ O
monthly -X- _ O
CommonCrawl -X- _ B-DatasetName
covering -X- _ O
2016 -X- _ O
to -X- _ O
2019, -X- _ O
constituting -X- _ O
45TB -X- _ O
of -X- _ O
compressed -X- _ O
plaintext -X- _ O
before -X- _ O
filtering -X- _ O
and -X- _ O
570GB -X- _ O
after -X- _ O
filtering, -X- _ O
roughly -X- _ O
equivalent -X- _ O
to -X- _ O
400 -X- _ O
billion -X- _ O
byte-pair-encoded -X- _ O
tokens. -X- _ O
Note -X- _ O
that -X- _ O
during -X- _ O
training, -X- _ O
datasets -X- _ O
are -X- _ O
not -X- _ O
sampled -X- _ O
in -X- _ O
proportion -X- _ O
to -X- _ O
their -X- _ O
size, -X- _ O
but -X- _ O
rather -X- _ O
datasets -X- _ O
we -X- _ O
view -X- _ O
as -X- _ O
higher-quality -X- _ O
are -X- _ O
sampled -X- _ O
more -X- _ O
frequently, -X- _ O
such -X- _ O
that -X- _ O
CommonCrawl -X- _ B-DatasetName
and -X- _ O
Books2 -X- _ B-DatasetName
datasets -X- _ O
are -X- _ O
sampled -X- _ O
less -X- _ O
than -X- _ O
once -X- _ O
during -X- _ O
training, -X- _ O
but -X- _ O
the -X- _ O
other -X- _ O
datasets -X- _ O
are -X- _ O
sampled -X- _ O
2-3 -X- _ O
times. -X- _ O
This -X- _ O
essentially -X- _ O
accepts -X- _ O
a -X- _ O
small -X- _ O
amount -X- _ O
of -X- _ O
overfitting -X- _ O
in -X- _ O
exchange -X- _ O
for -X- _ O
higher -X- _ O
quality -X- _ O
training -X- _ O
data. -X- _ O
that -X- _ O
are -X- _ O
drawn -X- _ O
from -X- _ O
a -X- _ O
given -X- _ O
dataset, -X- _ O
which -X- _ O
we -X- _ O
intentionally -X- _ O
do -X- _ O
not -X- _ O
make -X- _ O
proportional -X- _ O
to -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
dataset. -X- _ O
As -X- _ O
a -X- _ O
result, -X- _ O
when -X- _ O
we -X- _ O
train -X- _ O
for -X- _ O
300 -X- _ O
billion -X- _ O
tokens, -X- _ O
some -X- _ O
datasets -X- _ O
are -X- _ O
seen -X- _ O
up -X- _ O
to -X- _ O
3.4 -X- _ O
times -X- _ O
during -X- _ O
training -X- _ O
while -X- _ O
other -X- _ O
datasets -X- _ O
are -X- _ O
seen -X- _ O
less -X- _ O
than -X- _ O
once. -X- _ O
A -X- _ O
major -X- _ O
methodological -X- _ O
concern -X- _ O
with -X- _ O
language -X- _ O
models -X- _ O
pretrained -X- _ O
on -X- _ O
a -X- _ O
broad -X- _ O
swath -X- _ O
of -X- _ O
internet -X- _ O
data, -X- _ O
particularly -X- _ O
large -X- _ O
models -X- _ O
with -X- _ O
the -X- _ O
capacity -X- _ O
to -X- _ O
memorize -X- _ O
vast -X- _ O
amounts -X- _ O
of -X- _ O
content, -X- _ O
is -X- _ O
potential -X- _ O
contamination -X- _ O
of -X- _ O
downstream -X- _ O
tasks -X- _ O
by -X- _ O
having -X- _ O
their -X- _ O
test -X- _ O
or -X- _ O
development -X- _ O
sets -X- _ O
inadvertently -X- _ O
seen -X- _ O
during -X- _ O
pre-training. -X- _ O
To -X- _ O
reduce -X- _ O
such -X- _ O
contamination, -X- _ O
we -X- _ O
searched -X- _ O
for -X- _ O
and -X- _ O
attempted -X- _ O
to -X- _ O
remove -X- _ O
any -X- _ O
overlaps -X- _ O
with -X- _ O
the -X- _ O
development -X- _ O
and -X- _ O
test -X- _ O
sets -X- _ O
of -X- _ O
all -X- _ O
benchmarks -X- _ O
studied -X- _ O
in -X- _ O
this -X- _ O
paper. -X- _ O
Unfortunately, -X- _ O
a -X- _ O
bug -X- _ O
in -X- _ O
the -X- _ O
filtering -X- _ O
caused -X- _ O
us -X- _ O
to -X- _ O
ignore -X- _ O
some -X- _ O
overlaps, -X- _ O
and -X- _ O
due -X- _ O
to -X- _ O
the -X- _ O
cost -X- _ O
of -X- _ O
training -X- _ O
it -X- _ O
was -X- _ O
not -X- _ O
feasible -X- _ O
to -X- _ O
retrain -X- _ O
the -X- _ O
model. -X- _ O
In -X- _ O
Section -X- _ O
4 -X- _ O
we -X- _ O
characterize -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
the -X- _ O
remaining -X- _ O
overlaps, -X- _ O
and -X- _ O
in -X- _ O
future -X- _ O
work -X- _ O
we -X- _ O
will -X- _ O
more -X- _ O
aggressively -X- _ O
remove -X- _ O
data -X- _ O
contamination. -X- _ O

We -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
and -X- _ O
architecture -X- _ O
as -X- _ O
GPT-2 -X- _ O
[RWC -X- _ O
+ -X- _ O
19], -X- _ O
including -X- _ O
the -X- _ O
modified -X- _ O
initialization, -X- _ O
pre-normalization, -X- _ O
and -X- _ O
reversible -X- _ O
tokenization -X- _ O
described -X- _ O
therein, -X- _ O
with -X- _ O
the -X- _ O
exception -X- _ O
that -X- _ O
we -X- _ O
use -X- _ O
alternating -X- _ O
dense -X- _ O
and -X- _ O
locally -X- _ O
banded -X- _ O
sparse -X- _ O
attention -X- _ O
patterns -X- _ O
in -X- _ O
the -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
transformer, -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
Sparse -X- _ O
Transformer -X- _ O
[CGRS19]. -X- _ O
To -X- _ O
study -X- _ O
the -X- _ O
dependence -X- _ O
of -X- _ O
ML -X- _ O
performance -X- _ O
on -X- _ O
model -X- _ O
size, -X- _ O
we -X- _ O
train -X- _ O
8 -X- _ O
different -X- _ O
sizes -X- _ O
of -X- _ O
model, -X- _ O
ranging -X- _ O
over -X- _ O
three -X- _ O
orders -X- _ O
of -X- _ O
magnitude -X- _ O
from -X- _ O
125 -X- _ O
million -X- _ O
parameters -X- _ O
to -X- _ O
175 -X- _ O
billion -X- _ O
parameters, -X- _ O
with -X- _ O
the -X- _ O
last -X- _ O
being -X- _ O
the -X- _ O
model -X- _ O
we -X- _ O
call -X- _ O
GPT-3. -X- _ B-MethodName
Previous -X- _ O
work -X- _ O
[KMH -X- _ O
+ -X- _ O
20] -X- _ O
suggests -X- _ O
that -X- _ O
with -X- _ O
enough -X- _ O
training -X- _ O
data, -X- _ O
scaling -X- _ O
of -X- _ O
validation -X- _ O
loss -X- _ O
should -X- _ O
be -X- _ O
approximately -X- _ O
a -X- _ O
smooth -X- _ O
power -X- _ O
law -X- _ O
as -X- _ O
a -X- _ O
function -X- _ O
of -X- _ O
size; -X- _ O
training -X- _ O
models -X- _ O
of -X- _ O
many -X- _ O
different -X- _ O
sizes -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
test -X- _ O
this -X- _ O
hypothesis -X- _ O
both -X- _ O
for -X- _ O
validation -X- _ O
loss -X- _ O
and -X- _ O
for -X- _ O
downstream -X- _ O
language -X- _ O
tasks. -X- _ O
Table -X- _ O
2.1 -X- _ O
shows -X- _ O
the -X- _ O
sizes -X- _ O
and -X- _ O
architectures -X- _ O
of -X- _ O
our -X- _ O
8 -X- _ O
models. -X- _ O
Here -X- _ O
n -X- _ O
params -X- _ O
is -X- _ O
the -X- _ O
total -X- _ O
number -X- _ O
of -X- _ O
trainable -X- _ O
parameters, -X- _ O
n -X- _ B-HyperparameterName
layers -X- _ I-HyperparameterName
is -X- _ O
the -X- _ O
total -X- _ B-HyperparameterName
number -X- _ I-HyperparameterName
of -X- _ I-HyperparameterName
layers, -X- _ I-HyperparameterName
d -X- _ B-HyperparameterName
model -X- _ I-HyperparameterName
is -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
units -X- _ I-HyperparameterName
in -X- _ I-HyperparameterName
each -X- _ I-HyperparameterName
bottleneck -X- _ I-HyperparameterName
layer -X- _ I-HyperparameterName
(we -X- _ O
always -X- _ O
have -X- _ O
the -X- _ O
feedforward -X- _ O
layer -X- _ O
four -X- _ O
times -X- _ O
the -X- _ O
size -X- _ O
of -X- _ O
the -X- _ O
bottleneck -X- _ O
layer, -X- _ O
d -X- _ B-HyperparameterName
ff -X- _ I-HyperparameterName
= -X- _ O
4 -X- _ B-HyperparameterValue
* -X- _ I-HyperparameterValue
d -X- _ I-HyperparameterValue
model -X- _ I-HyperparameterValue
), -X- _ O
and -X- _ O
d -X- _ B-HyperparameterName
head -X- _ I-HyperparameterName
is -X- _ O
the -X- _ O
dimension -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
each -X- _ I-HyperparameterName
attention -X- _ I-HyperparameterName
head. -X- _ I-HyperparameterName
All -X- _ O
models -X- _ O
use -X- _ O
a -X- _ O
context -X- _ B-HyperparameterName
window -X- _ I-HyperparameterName
of -X- _ O
n -X- _ B-HyperparameterName
ctx -X- _ I-HyperparameterName
= -X- _ O
2048 -X- _ B-HyperparameterValue
tokens. -X- _ I-HyperparameterValue
We -X- _ O
partition -X- _ O
the -X- _ O
model -X- _ O
across -X- _ O
GPUs -X- _ O
along -X- _ O
both -X- _ O
the -X- _ O
depth -X- _ O
and -X- _ O
width -X- _ O
dimension -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
minimize -X- _ O
data-transfer -X- _ O
between -X- _ O
nodes. -X- _ O
The -X- _ O
precise -X- _ O
architectural -X- _ O
parameters -X- _ O
for -X- _ O
each -X- _ O
model -X- _ O
are -X- _ O
chosen -X- _ O
based -X- _ O
on -X- _ O
computational -X- _ O
efficiency -X- _ O
and -X- _ O
load-balancing -X- _ O
in -X- _ O
the -X- _ O
layout -X- _ O
of -X- _ O
models -X- _ O
across -X- _ O
GPU's. -X- _ O
Previous -X- _ O
work -X- _ O
[KMH -X- _ O
+ -X- _ O
20] -X- _ O
suggests -X- _ O
that -X- _ O
validation -X- _ O
loss -X- _ O
is -X- _ O
not -X- _ O
strongly -X- _ O
sensitive -X- _ O
to -X- _ O
these -X- _ O
parameters -X- _ O
within -X- _ O
a -X- _ O
reasonably -X- _ O
broad -X- _ O
range. -X- _ O

Our -X- _ O
basic -X- _ O
pre-training -X- _ O
approach, -X- _ O
including -X- _ O
model, -X- _ O
data, -X- _ O
and -X- _ O
training, -X- _ O
is -X- _ O
similar -X- _ O
to -X- _ O
the -X- _ O
process -X- _ O
described -X- _ O
in -X- _ O
[RWC -X- _ O
+ -X- _ O
19], -X- _ O
with -X- _ O
relatively -X- _ O
straightforward -X- _ O
scaling -X- _ O
up -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
size, -X- _ O
dataset -X- _ O
size -X- _ O
and -X- _ O
diversity, -X- _ O
and -X- _ O
length -X- _ O
of -X- _ O
training. -X- _ O
Our -X- _ O
use -X- _ O
of -X- _ O
in-context -X- _ O
learning -X- _ O
is -X- _ O
also -X- _ O
similar -X- _ O
to -X- _ O
[RWC -X- _ O
+ -X- _ O
19], -X- _ O
but -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
systematically -X- _ O
explore -X- _ O
different -X- _ O
settings -X- _ O
for -X- _ O
learning -X- _ O
within -X- _ O
the -X- _ O
context. -X- _ O
Therefore, -X- _ O
we -X- _ O
start -X- _ O
this -X- _ O
section -X- _ O
by -X- _ O
explicitly -X- _ O
defining -X- _ O
and -X- _ O
contrasting -X- _ O
the -X- _ O
different -X- _ O
settings -X- _ O
that -X- _ O
we -X- _ O
will -X- _ O
be -X- _ O
evaluating -X- _ O
GPT-3 -X- _ B-MethodName
on -X- _ O
or -X- _ O
could -X- _ O
in -X- _ O
principle -X- _ O
evaluate -X- _ O
GPT-3 -X- _ B-MethodName
on. -X- _ O
These -X- _ O
settings -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
lying -X- _ O
on -X- _ O
a -X- _ O
spectrum -X- _ O
of -X- _ O
how -X- _ O
much -X- _ O
task-specific -X- _ O
data -X- _ O
they -X- _ O
tend -X- _ O
to -X- _ O
rely -X- _ O
on. -X- _ O
Specifically, -X- _ O
we -X- _ O
can -X- _ O
identify -X- _ O
at -X- _ O
least -X- _ O
four -X- _ O
points -X- _ O
on -X- _ O
this -X- _ O
spectrum -X- _ O
(see -X- _ O
Figure -X- _ O
2.1 -X- _ O
for -X- _ O
an -X- _ O
illustration): -X- _ O
• -X- _ O
Fine-Tuning -X- _ O
(FT) -X- _ O
has -X- _ O
been -X- _ O
the -X- _ O
most -X- _ O
common -X- _ O
approach -X- _ O
in -X- _ O
recent -X- _ O
years, -X- _ O
and -X- _ O
involves -X- _ O
updating -X- _ O
the -X- _ O
weights -X- _ O
of -X- _ O
a -X- _ O
pre-trained -X- _ O
model -X- _ O
by -X- _ O
training -X- _ O
on -X- _ O
a -X- _ O
supervised -X- _ O
dataset -X- _ O
specific -X- _ O
to -X- _ O
the -X- _ O
desired -X- _ O
task. -X- _ O
Typically -X- _ O
thousands -X- _ O
to -X- _ O
hundreds -X- _ O
of -X- _ O
thousands -X- _ O
of -X- _ O
labeled -X- _ O
examples -X- _ O
are -X- _ O
used. -X- _ O
The -X- _ O
main -X- _ O
advantage -X- _ O
of -X- _ O
fine-tuning -X- _ O
is -X- _ O
strong -X- _ O
performance -X- _ O
on -X- _ O
many -X- _ O
benchmarks. -X- _ O
The -X- _ O
main -X- _ O
disadvantages -X- _ O
are -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
a -X- _ O
new -X- _ O
large -X- _ O
dataset -X- _ O
for -X- _ O
every -X- _ O
task, -X- _ O
the -X- _ O
potential -X- _ O
for -X- _ O
poor -X- _ O
generalization -X- _ O
out-of-distribution -X- _ O
[MPL19], -X- _ O
and -X- _ O
the -X- _ O
potential -X- _ O
to -X- _ O
exploit -X- _ O
spurious -X- _ O
features -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
[GSL -X- _ O
+ -X- _ O
18, -X- _ O
NK19], -X- _ O
potentially -X- _ O
resulting -X- _ O
in -X- _ O
an -X- _ O
unfair -X- _ O
comparison -X- _ O
with -X- _ O
human -X- _ O
performance. -X- _ O
In -X- _ O
this -X- _ O
work -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
fine-tune -X- _ O
GPT-3 -X- _ B-MethodName
because -X- _ O
our -X- _ O
focus -X- _ O
is -X- _ O
on -X- _ O
task-agnostic -X- _ O
performance, -X- _ O
but -X- _ O
GPT-3 -X- _ B-MethodName
can -X- _ O
be -X- _ O
fine-tuned -X- _ O
in -X- _ O
principle -X- _ O
and -X- _ O
this -X- _ O
is -X- _ O
a -X- _ O
promising -X- _ O
direction -X- _ O
for -X- _ O
future -X- _ O
work. -X- _ O
• -X- _ O
Few-Shot -X- _ B-TaskName
(FS) -X- _ B-TaskName
is -X- _ O
the -X- _ O
term -X- _ O
we -X- _ O
will -X- _ O
use -X- _ O
in -X- _ O
this -X- _ O
work -X- _ O
to -X- _ O
refer -X- _ O
to -X- _ O
the -X- _ O
setting -X- _ O
where -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
given -X- _ O
a -X- _ O
few -X- _ O
demonstrations -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
as -X- _ O
conditioning -X- _ O
[RWC -X- _ O
+ -X- _ O
19], -X- _ O
but -X- _ O
no -X- _ O
weight -X- _ O
updates -X- _ O
are -X- _ O
allowed. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
2.1, -X- _ O
for -X- _ O
a -X- _ O
typical -X- _ O
dataset -X- _ O
an -X- _ O
example -X- _ O
has -X- _ O
a -X- _ O
context -X- _ O
and -X- _ O
a -X- _ O
desired -X- _ O
completion -X- _ O
(for -X- _ O
example -X- _ O
an -X- _ O
English -X- _ O
sentence -X- _ O
and -X- _ O
the -X- _ O
French -X- _ O
translation), -X- _ O
and -X- _ O
few-shot -X- _ B-TaskName
works -X- _ O
by -X- _ O
giving -X- _ O
K -X- _ B-HyperparameterName
examples -X- _ O
of -X- _ O
context -X- _ O
and -X- _ O
completion, -X- _ O
and -X- _ O
then -X- _ O
one -X- _ O
final -X- _ O
example -X- _ O
of -X- _ O
context, -X- _ O
with -X- _ O
the -X- _ O
model -X- _ O
expected -X- _ O
to -X- _ O
provide -X- _ O
the -X- _ O
completion. -X- _ O
We -X- _ O
typically -X- _ O
set -X- _ O
K -X- _ B-HyperparameterName
in -X- _ O
the -X- _ O
range -X- _ O
of -X- _ O
10 -X- _ B-HyperparameterValue
to -X- _ I-HyperparameterValue
100 -X- _ I-HyperparameterValue
as -X- _ O
this -X- _ O
is -X- _ O
how -X- _ O
many -X- _ O
examples -X- _ O
can -X- _ O
fit -X- _ O
in -X- _ O
the -X- _ O
model's -X- _ O
context -X- _ O
window -X- _ O
(n -X- _ B-HyperparameterName
ctx -X- _ O
= -X- _ O
2048). -X- _ B-HyperparameterValue
The -X- _ O
main -X- _ O
advantages -X- _ O
of -X- _ O
few-shot -X- _ O
are -X- _ O
a -X- _ O
major -X- _ O
reduction -X- _ O
in -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
task-specific -X- _ O
data -X- _ O
and -X- _ O
reduced -X- _ O
potential -X- _ O
to -X- _ O
learn -X- _ O
an -X- _ O
overly -X- _ O
narrow -X- _ O
distribution -X- _ O
from -X- _ O
a -X- _ O
large -X- _ O
but -X- _ O
narrow -X- _ O
fine-tuning -X- _ O
dataset. -X- _ O
The -X- _ O
main -X- _ O
disadvantage -X- _ O
is -X- _ O
that -X- _ O
results -X- _ O
from -X- _ O
this -X- _ O
method -X- _ O
have -X- _ O
so -X- _ O
far -X- _ O
been -X- _ O
much -X- _ O
worse -X- _ O
than -X- _ O
state-of-the-art -X- _ O
fine-tuned -X- _ O
models. -X- _ O
Also, -X- _ O
a -X- _ O
small -X- _ O
amount -X- _ O
of -X- _ O
task -X- _ O
specific -X- _ O
data -X- _ O
is -X- _ O
still -X- _ O
required. -X- _ O
As -X- _ O
indicated -X- _ O
by -X- _ O
the -X- _ O
name, -X- _ O
few-shot -X- _ B-TaskName
learning -X- _ I-TaskName
as -X- _ O
described -X- _ O
here -X- _ O
for -X- _ O
language -X- _ O
models -X- _ O
is -X- _ O
related -X- _ O
to -X- _ O
few-shot -X- _ B-TaskName
learning -X- _ I-TaskName
as -X- _ O
used -X- _ O
in -X- _ O
other -X- _ O
contexts -X- _ O
in -X- _ O
ML -X- _ O
[HYC01, -X- _ O
VBL -X- _ O
+ -X- _ O
16] -X- _ O
-both -X- _ O
involve -X- _ O
learning -X- _ O
based -X- _ O
on -X- _ O
a -X- _ O
broad -X- _ O
distribution -X- _ O
of -X- _ O
tasks -X- _ O
(in -X- _ O
this -X- _ O
case -X- _ O
implicit -X- _ O
in -X- _ O
the -X- _ O
pre-training -X- _ O
data) -X- _ O
and -X- _ O
then -X- _ O
rapidly -X- _ O
adapting -X- _ O
to -X- _ O
a -X- _ O
new -X- _ O
task. -X- _ O
• -X- _ O
One-Shot -X- _ B-TaskName
(1S) -X- _ B-TaskName
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
few-shot -X- _ B-TaskName
except -X- _ O
that -X- _ O
only -X- _ O
one -X- _ O
demonstration -X- _ O
is -X- _ O
allowed, -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
a -X- _ O
natural -X- _ O
language -X- _ O
description -X- _ O
of -X- _ O
the -X- _ O
task, -X- _ O
as -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1. -X- _ O
The -X- _ O
reason -X- _ O
to -X- _ O
distinguish -X- _ O
one-shot -X- _ B-TaskName
from -X- _ O
few-shot -X- _ B-TaskName
and -X- _ O
zero-shot -X- _ B-TaskName
(below) -X- _ O
is -X- _ O
that -X- _ O
it -X- _ O
most -X- _ O
closely -X- _ O
matches -X- _ O
the -X- _ O
way -X- _ O
in -X- _ O
which -X- _ O
some -X- _ O
tasks -X- _ O
are -X- _ O
communicated -X- _ O
to -X- _ O
humans. -X- _ O
For -X- _ O
example, -X- _ O
when -X- _ O
asking -X- _ O
humans -X- _ O
to -X- _ O
generate -X- _ O
a -X- _ O
dataset -X- _ O
on -X- _ O
a -X- _ O
human -X- _ O
worker -X- _ O
service -X- _ O
(for -X- _ O
example -X- _ O
Mechanical -X- _ O
Turk), -X- _ O
it -X- _ O
is -X- _ O
common -X- _ O
to -X- _ O
give -X- _ O
one -X- _ O
demonstration -X- _ O
of -X- _ O
the -X- _ O
task. -X- _ O
By -X- _ O
contrast -X- _ O
it -X- _ O
is -X- _ O
sometimes -X- _ O
difficult -X- _ O
to -X- _ O
communicate -X- _ O
the -X- _ O
content -X- _ O
or -X- _ O
format -X- _ O
of -X- _ O
a -X- _ O
task -X- _ O
if -X- _ O
no -X- _ O
examples -X- _ O
are -X- _ O
given. -X- _ O
Figure -X- _ O
2.1: -X- _ O
Zero-shot, -X- _ B-TaskName
one-shot -X- _ B-TaskName
and -X- _ O
few-shot, -X- _ B-TaskName
contrasted -X- _ O
with -X- _ O
traditional -X- _ O
fine-tuning. -X- _ O
The -X- _ O
panels -X- _ O
above -X- _ O
show -X- _ O
four -X- _ O
methods -X- _ O
for -X- _ O
performing -X- _ O
a -X- _ O
task -X- _ O
with -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
-fine-tuning -X- _ O
is -X- _ O
the -X- _ O
traditional -X- _ O
method, -X- _ O
whereas -X- _ O
zero-, -X- _ O
one-, -X- _ O
and -X- _ O
few-shot, -X- _ O
which -X- _ O
we -X- _ O
study -X- _ O
in -X- _ O
this -X- _ O
work, -X- _ O
require -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
perform -X- _ O
the -X- _ O
task -X- _ O
with -X- _ O
only -X- _ O
forward -X- _ O
passes -X- _ O
at -X- _ O
test -X- _ O
time. -X- _ O
We -X- _ O
typically -X- _ O
present -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
a -X- _ O
few -X- _ O
dozen -X- _ O
examples -X- _ O
in -X- _ O
the -X- _ O
few -X- _ O
shot -X- _ O
setting. -X- _ O
Exact -X- _ O
phrasings -X- _ O
for -X- _ O
all -X- _ O
task -X- _ O
descriptions, -X- _ O
examples -X- _ O
and -X- _ O
prompts -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
G. -X- _ O
• -X- _ O
Zero-Shot -X- _ B-TaskName
(0S) -X- _ B-TaskName
is -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
one-shot -X- _ B-DatasetName
except -X- _ O
that -X- _ O
no -X- _ O
demonstrations -X- _ O
are -X- _ O
allowed, -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
only -X- _ O
given -X- _ O
a -X- _ O
natural -X- _ O
language -X- _ O
instruction -X- _ O
describing -X- _ O
the -X- _ O
task. -X- _ O
This -X- _ O
method -X- _ O
provides -X- _ O
maximum -X- _ O
convenience, -X- _ O
potential -X- _ O
for -X- _ O
robustness, -X- _ O
and -X- _ O
avoidance -X- _ O
of -X- _ O
spurious -X- _ O
correlations -X- _ O
(unless -X- _ O
they -X- _ O
occur -X- _ O
very -X- _ O
broadly -X- _ O
across -X- _ O
the -X- _ O
large -X- _ O
corpus -X- _ O
of -X- _ O
pre-training -X- _ O
data), -X- _ O
but -X- _ O
is -X- _ O
also -X- _ O
the -X- _ O
most -X- _ O
challenging -X- _ O
setting. -X- _ O
In -X- _ O
some -X- _ O
cases -X- _ O
it -X- _ O
may -X- _ O
even -X- _ O
be -X- _ O
difficult -X- _ O
for -X- _ O
humans -X- _ O
to -X- _ O
understand -X- _ O
the -X- _ O
format -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
without -X- _ O
prior -X- _ O
examples, -X- _ O
so -X- _ O
this -X- _ O
setting -X- _ O
is -X- _ O
in -X- _ O
some -X- _ O
cases -X- _ O
"unfairly -X- _ O
hard". -X- _ O
For -X- _ O
example, -X- _ O
if -X- _ O
someone -X- _ O
is -X- _ O
asked -X- _ O
to -X- _ O
"make -X- _ O
a -X- _ O
Figure -X- _ O
2.1 -X- _ O
shows -X- _ O
the -X- _ O
four -X- _ O
methods -X- _ O
using -X- _ O
the -X- _ O
example -X- _ O
of -X- _ O
translating -X- _ O
English -X- _ O
to -X- _ O
French. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
we -X- _ O
focus -X- _ O
on -X- _ O
zero-shot, -X- _ O
one-shot -X- _ O
and -X- _ O
few-shot, -X- _ O
with -X- _ O
the -X- _ O
aim -X- _ O
of -X- _ O
comparing -X- _ O
them -X- _ O
not -X- _ O
as -X- _ O
competing -X- _ O
alternatives, -X- _ O
but -X- _ O
as -X- _ O
different -X- _ O
problem -X- _ O
settings -X- _ O
which -X- _ O
offer -X- _ O
a -X- _ O
varying -X- _ O
trade-off -X- _ O
between -X- _ O
performance -X- _ O
on -X- _ O
specific -X- _ O
benchmarks -X- _ O
and -X- _ O
sample -X- _ O
efficiency. -X- _ O
We -X- _ O
especially -X- _ O
highlight -X- _ O
the -X- _ O
few-shot -X- _ O
results -X- _ O
as -X- _ O
many -X- _ O
of -X- _ O
them -X- _ O
are -X- _ O
only -X- _ O
slightly -X- _ O
behind -X- _ O
state-of-the-art -X- _ O
fine-tuned -X- _ O
models. -X- _ O
Ultimately, -X- _ O
however, -X- _ O
one-shot, -X- _ O
or -X- _ O
even -X- _ O
sometimes -X- _ O
zero-shot, -X- _ O
seem -X- _ O
like -X- _ O
the -X- _ O
fairest -X- _ O
comparisons -X- _ O
to -X- _ O
human -X- _ O
performance, -X- _ O
and -X- _ O
are -X- _ O
important -X- _ O
targets -X- _ O
for -X- _ O
future -X- _ O
work. -X- _ O
Table -X- _ O
2.1: -X- _ O
Sizes, -X- _ O
architectures, -X- _ O
and -X- _ O
learning -X- _ O
hyper-parameters -X- _ O
(batch -X- _ O
size -X- _ O
in -X- _ O
tokens -X- _ O
and -X- _ O
learning -X- _ O
rate) -X- _ O
of -X- _ O
the -X- _ O
models -X- _ O
which -X- _ O
we -X- _ O
trained. -X- _ O
All -X- _ O
models -X- _ O
were -X- _ O
trained -X- _ O
for -X- _ O
a -X- _ O
total -X- _ O
of -X- _ O
300 -X- _ O
billion -X- _ O
tokens. -X- _ O

Recent -X- _ O
years -X- _ O
have -X- _ O
featured -X- _ O
a -X- _ O
trend -X- _ O
towards -X- _ O
pre-trained -X- _ O
language -X- _ O
representations -X- _ O
in -X- _ O
NLP -X- _ O
systems, -X- _ O
applied -X- _ O
in -X- _ O
increasingly -X- _ O
flexible -X- _ O
and -X- _ O
task-agnostic -X- _ O
ways -X- _ O
for -X- _ O
downstream -X- _ O
transfer. -X- _ O
First, -X- _ O
single-layer -X- _ O
representations -X- _ O
were -X- _ O
learned -X- _ O
using -X- _ O
word -X- _ O
vectors -X- _ O
[MCCD13,PSM14] -X- _ O
and -X- _ O
fed -X- _ O
to -X- _ O
task-specific -X- _ O
architectures, -X- _ O
then -X- _ O
RNNs -X- _ O
with -X- _ O
multiple -X- _ O
layers -X- _ O
of -X- _ O
representations -X- _ O
and -X- _ O
contextual -X- _ O
state -X- _ O
were -X- _ O
used -X- _ O
to -X- _ O
form -X- _ O
stronger -X- _ O
representations -X- _ O
[DL15,MBXS17,PNZtY18] -X- _ O
(though -X- _ O
still -X- _ O
applied -X- _ O
to -X- _ O
task-specific -X- _ O
architectures), -X- _ O
and -X- _ O
more -X- _ O
recently -X- _ O
pre-trained -X- _ O
recurrent -X- _ O
or -X- _ O
transformer -X- _ O
language -X- _ O
models -X- _ O
[VSP -X- _ O
+ -X- _ O
17] -X- _ O
have -X- _ O
been -X- _ O
directly -X- _ O
fine-tuned, -X- _ O
entirely -X- _ O
removing -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
task-specific -X- _ O
architectures -X- _ O
[RNSS18,DCLT18,HR18]. -X- _ O
This -X- _ O
last -X- _ O
paradigm -X- _ O
has -X- _ O
led -X- _ O
to -X- _ O
substantial -X- _ O
progress -X- _ O
on -X- _ O
many -X- _ O
challenging -X- _ O
NLP -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
reading -X- _ O
comprehension, -X- _ O
question -X- _ O
answering, -X- _ O
textual -X- _ O
entailment, -X- _ O
and -X- _ O
many -X- _ O
others, -X- _ O
and -X- _ O
has -X- _ O
continued -X- _ O
to -X- _ O
advance -X- _ O
based -X- _ O
on -X- _ O
new -X- _ O
architectures -X- _ O
and -X- _ O
algorithms -X- _ O
[RSR -X- _ O
+ -X- _ O
19, -X- _ O
LOG -X- _ O
+ -X- _ O
19, -X- _ O
YDY -X- _ O
+ -X- _ O
19, -X- _ O
LCG -X- _ O
+ -X- _ O
19]. -X- _ O
However, -X- _ O
a -X- _ O
major -X- _ O
limitation -X- _ O
to -X- _ O
this -X- _ O
approach -X- _ O
is -X- _ O
that -X- _ O
while -X- _ O
the -X- _ O
architecture -X- _ O
is -X- _ O
task-agnostic, -X- _ O
there -X- _ O
is -X- _ O
still -X- _ O
a -X- _ O
need -X- _ O
for -X- _ O
task-specific -X- _ O
datasets -X- _ O
and -X- _ O
task-specific -X- _ O
fine-tuning: -X- _ O
to -X- _ O
achieve -X- _ O
strong -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
desired -X- _ O
task -X- _ O
typically -X- _ O
requires -X- _ O
fine-tuning -X- _ O
on -X- _ O
a -X- _ O
dataset -X- _ O
of -X- _ O
thousands -X- _ O
to -X- _ O
hundreds -X- _ O
of -X- _ O
thousands -X- _ O
of -X- _ O
examples -X- _ O
specific -X- _ O
to -X- _ O
that -X- _ O
task. -X- _ O
Removing -X- _ O
this -X- _ O
limitation -X- _ O
would -X- _ O
be -X- _ O
desirable, -X- _ O
for -X- _ O
several -X- _ O
reasons. -X- _ O
First, -X- _ O
from -X- _ O
a -X- _ O
practical -X- _ O
perspective, -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
a -X- _ O
large -X- _ O
dataset -X- _ O
of -X- _ O
labeled -X- _ O
examples -X- _ O
for -X- _ O
every -X- _ O
new -X- _ O
task -X- _ O
limits -X- _ O
the -X- _ O
applicability -X- _ O
of -X- _ O
language -X- _ O
models. -X- _ O
There -X- _ O
exists -X- _ O
a -X- _ O
very -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
possible -X- _ O
useful -X- _ O
language -X- _ O
tasks, -X- _ O
encompassing -X- _ O
anything -X- _ O
from -X- _ O
correcting -X- _ O
grammar, -X- _ O
to -X- _ O
generating -X- _ O
examples -X- _ O
of -X- _ O
an -X- _ O
abstract -X- _ O
concept, -X- _ O
to -X- _ O
critiquing -X- _ O
a -X- _ O
short -X- _ O
story. -X- _ O
For -X- _ O
many -X- _ O
of -X- _ O
these -X- _ O
tasks -X- _ O
it -X- _ O
is -X- _ O
difficult -X- _ O
to -X- _ O
collect -X- _ O
a -X- _ O
large -X- _ O
supervised -X- _ O
training -X- _ O
dataset, -X- _ O
especially -X- _ O
when -X- _ O
the -X- _ O
process -X- _ O
must -X- _ O
be -X- _ O
repeated -X- _ O
for -X- _ O
every -X- _ O
new -X- _ O
task. -X- _ O
Second, -X- _ O
the -X- _ O
potential -X- _ O
to -X- _ O
exploit -X- _ O
spurious -X- _ O
correlations -X- _ O
in -X- _ O
training -X- _ O
data -X- _ O
fundamentally -X- _ O
grows -X- _ O
with -X- _ O
the -X- _ O
expressiveness -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
and -X- _ O
the -X- _ O
narrowness -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
distribution. -X- _ O
This -X- _ O
can -X- _ O
create -X- _ O
problems -X- _ O
for -X- _ O
the -X- _ O
pre-training -X- _ O
plus -X- _ O
fine-tuning -X- _ O
paradigm, -X- _ O
where -X- _ O
models -X- _ O
are -X- _ O
designed -X- _ O
to -X- _ O
be -X- _ O
large -X- _ O
to -X- _ O
absorb -X- _ O
information -X- _ O
during -X- _ O
pre-training, -X- _ O
but -X- _ O
are -X- _ O
then -X- _ O
fine-tuned -X- _ O
on -X- _ O
very -X- _ O
narrow -X- _ O
task -X- _ O
distributions. -X- _ O
For -X- _ O
instance -X- _ O
[HLW -X- _ O
+ -X- _ O
20] -X- _ O
observe -X- _ O
that -X- _ O
larger -X- _ O
models -X- _ O
do -X- _ O
not -X- _ O
necessarily -X- _ O
generalize -X- _ O
better -X- _ O
out-of-distribution. -X- _ O
There -X- _ O
is -X- _ O
evidence -X- _ O
that -X- _ O
suggests -X- _ O
that -X- _ O
the -X- _ O
generalization -X- _ O
achieved -X- _ O
under -X- _ O
this -X- _ O
paradigm -X- _ O
can -X- _ O
be -X- _ O
poor -X- _ O
because -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
overly -X- _ O
specific -X- _ O
to -X- _ O
the -X- _ O
training -X- _ O
distribution -X- _ O
and -X- _ O
does -X- _ O
not -X- _ O
generalize -X- _ O
well -X- _ O
outside -X- _ O
it -X- _ O
[YdC -X- _ O
+ -X- _ O
19, -X- _ O
MPL19]. -X- _ O
Thus, -X- _ O
the -X- _ O
performance -X- _ O
of -X- _ O
fine-tuned -X- _ O
models -X- _ O
on -X- _ O
specific -X- _ O
benchmarks, -X- _ O
even -X- _ O
when -X- _ O
it -X- _ O
is -X- _ O
nominally -X- _ O
at -X- _ O
human-level, -X- _ O
may -X- _ O
exaggerate -X- _ O
actual -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
underlying -X- _ O
task -X- _ O
[GSL -X- _ O
+ -X- _ O
18, -X- _ O
NK19]. -X- _ O
Third, -X- _ O
humans -X- _ O
do -X- _ O
not -X- _ O
require -X- _ O
large -X- _ O
supervised -X- _ O
datasets -X- _ O
to -X- _ O
learn -X- _ O
most -X- _ O
language -X- _ O
tasks -X- _ O
-a -X- _ O
brief -X- _ O
directive -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
(e.g. -X- _ O
"please -X- _ O
tell -X- _ O
me -X- _ O
if -X- _ O
this -X- _ O
sentence -X- _ O
describes -X- _ O
something -X- _ O
happy -X- _ O
or -X- _ O
something -X- _ O
sad") -X- _ O
or -X- _ O
at -X- _ O
most -X- _ O
a -X- _ O
tiny -X- _ O
number -X- _ O
of -X- _ O
demonstrations -X- _ O
(e.g. -X- _ O
"here -X- _ O
are -X- _ O
two -X- _ O
examples -X- _ O
of -X- _ O
people -X- _ O
acting -X- _ O
brave; -X- _ O
please -X- _ O
give -X- _ O
a -X- _ O
third -X- _ O
example -X- _ O
of -X- _ O
bravery") -X- _ O
is -X- _ O
often -X- _ O
Figure -X- _ O
1.1: -X- _ O
Language -X- _ O
model -X- _ O
meta-learning. -X- _ O
During -X- _ O
unsupervised -X- _ O
pre-training, -X- _ O
a -X- _ O
language -X- _ O
model -X- _ O
develops -X- _ O
a -X- _ O
broad -X- _ O
set -X- _ O
of -X- _ O
skills -X- _ O
and -X- _ O
pattern -X- _ O
recognition -X- _ O
abilities. -X- _ O
It -X- _ O
then -X- _ O
uses -X- _ O
these -X- _ O
abilities -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
to -X- _ O
rapidly -X- _ O
adapt -X- _ O
to -X- _ O
or -X- _ O
recognize -X- _ O
the -X- _ O
desired -X- _ O
task. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
term -X- _ O
"in-context -X- _ O
learning" -X- _ O
to -X- _ O
describe -X- _ O
the -X- _ O
inner -X- _ O
loop -X- _ O
of -X- _ O
this -X- _ O
process, -X- _ O
which -X- _ O
occurs -X- _ O
within -X- _ O
the -X- _ O
forward-pass -X- _ O
upon -X- _ O
each -X- _ O
sequence. -X- _ O
The -X- _ O
sequences -X- _ O
in -X- _ O
this -X- _ O
diagram -X- _ O
are -X- _ O
not -X- _ O
intended -X- _ O
to -X- _ O
be -X- _ O
representative -X- _ O
of -X- _ O
the -X- _ O
data -X- _ O
a -X- _ O
model -X- _ O
would -X- _ O
see -X- _ O
during -X- _ O
pre-training, -X- _ O
but -X- _ O
are -X- _ O
intended -X- _ O
to -X- _ O
show -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
sometimes -X- _ O
repeated -X- _ O
sub-tasks -X- _ O
embedded -X- _ O
within -X- _ O
a -X- _ O
single -X- _ O
sequence. -X- _ O
Figure -X- _ O
1.2: -X- _ O
Larger -X- _ O
models -X- _ O
make -X- _ O
increasingly -X- _ O
efficient -X- _ O
use -X- _ O
of -X- _ O
in-context -X- _ O
information. -X- _ O
We -X- _ O
show -X- _ O
in-context -X- _ O
learning -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
simple -X- _ O
task -X- _ O
requiring -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
remove -X- _ O
random -X- _ O
symbols -X- _ O
from -X- _ O
a -X- _ O
word, -X- _ O
both -X- _ O
with -X- _ O
and -X- _ O
without -X- _ O
a -X- _ O
natural -X- _ O
language -X- _ O
task -X- _ O
description -X- _ O
(see -X- _ O
Sec. -X- _ O
3.9.2). -X- _ O
The -X- _ O
steeper -X- _ O
"in-context -X- _ O
learning -X- _ O
curves" -X- _ O
for -X- _ O
large -X- _ O
models -X- _ O
demonstrate -X- _ O
improved -X- _ O
ability -X- _ O
to -X- _ O
learn -X- _ O
a -X- _ O
task -X- _ O
from -X- _ O
contextual -X- _ O
information. -X- _ O
We -X- _ O
see -X- _ O
qualitatively -X- _ O
similar -X- _ O
behavior -X- _ O
across -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
tasks. -X- _ O
sufficient -X- _ O
to -X- _ O
enable -X- _ O
a -X- _ O
human -X- _ O
to -X- _ O
perform -X- _ O
a -X- _ O
new -X- _ O
task -X- _ O
to -X- _ O
at -X- _ O
least -X- _ O
a -X- _ O
reasonable -X- _ O
degree -X- _ O
of -X- _ O
competence. -X- _ O
Aside -X- _ O
from -X- _ O
pointing -X- _ O
to -X- _ O
a -X- _ O
conceptual -X- _ O
limitation -X- _ O
in -X- _ O
our -X- _ O
current -X- _ O
NLP -X- _ O
techniques, -X- _ O
this -X- _ O
adaptability -X- _ O
has -X- _ O
practical -X- _ O
advantages -X- _ O
-it -X- _ O
allows -X- _ O
humans -X- _ O
to -X- _ O
seamlessly -X- _ O
mix -X- _ O
together -X- _ O
or -X- _ O
switch -X- _ O
between -X- _ O
many -X- _ O
tasks -X- _ O
and -X- _ O
skills, -X- _ O
for -X- _ O
example -X- _ O
performing -X- _ O
addition -X- _ O
during -X- _ O
a -X- _ O
lengthy -X- _ O
dialogue. -X- _ O
To -X- _ O
be -X- _ O
broadly -X- _ O
useful, -X- _ O
we -X- _ O
would -X- _ O
someday -X- _ O
like -X- _ O
our -X- _ O
NLP -X- _ O
systems -X- _ O
to -X- _ O
have -X- _ O
this -X- _ O
same -X- _ O
fluidity -X- _ O
and -X- _ O
generality. -X- _ O
One -X- _ O
potential -X- _ O
route -X- _ O
towards -X- _ O
addressing -X- _ O
these -X- _ O
issues -X- _ O
is -X- _ O
meta-learning -X- _ O
1 -X- _ O
-which -X- _ O
in -X- _ O
the -X- _ O
context -X- _ O
of -X- _ O
language -X- _ O
models -X- _ O
means -X- _ O
the -X- _ O
model -X- _ O
develops -X- _ O
a -X- _ O
broad -X- _ O
set -X- _ O
of -X- _ O
skills -X- _ O
and -X- _ O
pattern -X- _ O
recognition -X- _ O
abilities -X- _ O
at -X- _ O
training -X- _ O
time, -X- _ O
and -X- _ O
then -X- _ O
uses -X- _ O
those -X- _ O
abilities -X- _ O
at -X- _ O
inference -X- _ O
time -X- _ O
to -X- _ O
rapidly -X- _ O
adapt -X- _ O
to -X- _ O
or -X- _ O
recognize -X- _ O
the -X- _ O
desired -X- _ O
task -X- _ O
(illustrated -X- _ O
in -X- _ O
Figure -X- _ O
1.1). -X- _ O
Recent -X- _ O
work -X- _ O
[RWC -X- _ O
+ -X- _ O
19] -X- _ O
attempts -X- _ O
to -X- _ O
do -X- _ O
this -X- _ O
via -X- _ O
what -X- _ O
we -X- _ O
call -X- _ O
"in-context -X- _ O
learning", -X- _ O
using -X- _ O
the -X- _ O
text -X- _ O
input -X- _ O
of -X- _ O
a -X- _ O
pretrained -X- _ O
language -X- _ O
model -X- _ O
as -X- _ O
a -X- _ O
form -X- _ O
of -X- _ O
task -X- _ O
specification: -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
conditioned -X- _ O
on -X- _ O
a -X- _ O
natural -X- _ O
language -X- _ O
instruction -X- _ O
and/or -X- _ O
a -X- _ O
few -X- _ O
demonstrations -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
and -X- _ O
is -X- _ O
then -X- _ O
expected -X- _ O
to -X- _ O
complete -X- _ O
further -X- _ O
instances -X- _ O
of -X- _ O
the -X- _ O
task -X- _ O
simply -X- _ O
by -X- _ O
predicting -X- _ O
what -X- _ O
comes -X- _ O
next. -X- _ O
While -X- _ O
it -X- _ O
has -X- _ O
shown -X- _ O
some -X- _ O
initial -X- _ O
promise, -X- _ O
this -X- _ O
approach -X- _ O
still -X- _ O
achieves -X- _ O
results -X- _ O
far -X- _ O
inferior -X- _ O
to -X- _ O
fine-tuning -X- _ O
-for -X- _ O
example -X- _ O
[RWC -X- _ O
+ -X- _ O
19] -X- _ O
achieves -X- _ O
only -X- _ O
4% -X- _ O
on -X- _ O
Natural -X- _ O
Questions, -X- _ O
and -X- _ O
even -X- _ O
its -X- _ O
55 -X- _ O
F1 -X- _ O
CoQa -X- _ O
result -X- _ O
is -X- _ O
now -X- _ O
more -X- _ O
than -X- _ O
35 -X- _ O
points -X- _ O
behind -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art. -X- _ O
Meta-learning -X- _ O
clearly -X- _ O
requires -X- _ O
substantial -X- _ O
improvement -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
be -X- _ O
viable -X- _ O
as -X- _ O
a -X- _ O
practical -X- _ O
method -X- _ O
of -X- _ O
solving -X- _ O
language -X- _ O
tasks. -X- _ O
Another -X- _ O
recent -X- _ O
trend -X- _ O
in -X- _ O
language -X- _ O
modeling -X- _ O
may -X- _ O
offer -X- _ O
a -X- _ O
way -X- _ O
forward. -X- _ O
In -X- _ O
recent -X- _ O
years -X- _ O
the -X- _ O
capacity -X- _ O
of -X- _ O
transformer -X- _ O
language -X- _ O
models -X- _ O
has -X- _ O
increased -X- _ O
substantially, -X- _ O
from -X- _ O
100 -X- _ O
million -X- _ O
parameters -X- _ O
[RNSS18], -X- _ O
to -X- _ O
300 -X- _ O
million -X- _ O
parameters -X- _ O
[DCLT18], -X- _ O
to -X- _ O
1.5 -X- _ O
billion -X- _ O
parameters -X- _ O
[RWC -X- _ O
+ -X- _ O
19], -X- _ O
to -X- _ O
8 -X- _ O
billion -X- _ O
parameters -X- _ O
[SPP -X- _ O
+ -X- _ O
19], -X- _ O
11 -X- _ O
billion -X- _ O
parameters -X- _ O
[RSR -X- _ O
+ -X- _ O
19], -X- _ O
and -X- _ O
finally -X- _ O
17 -X- _ O
billion -X- _ O
parameters -X- _ O
[Tur20]. -X- _ O
Each -X- _ O
increase -X- _ O
has -X- _ O
brought -X- _ O
improvements -X- _ O
in -X- _ O
text -X- _ O
synthesis -X- _ O
and/or -X- _ O
downstream -X- _ O
NLP -X- _ O
tasks, -X- _ O
and -X- _ O
there -X- _ O
is -X- _ O
evidence -X- _ O
suggesting -X- _ O
that -X- _ O
log -X- _ O
loss, -X- _ O
which -X- _ O
correlates -X- _ O
well -X- _ O
with -X- _ O
many -X- _ O
downstream -X- _ O
tasks, -X- _ O
follows -X- _ O
a -X- _ O
smooth -X- _ O
trend -X- _ O
of -X- _ O
improvement -X- _ O
with -X- _ O
scale -X- _ O
[KMH -X- _ O
+ -X- _ O
20]. -X- _ O
Since -X- _ O
in-context -X- _ O
learning -X- _ O
involves -X- _ O
absorbing -X- _ O
many -X- _ O
skills -X- _ O
and -X- _ O
tasks -X- _ O
within -X- _ O
the -X- _ O
parameters -X- _ O
of -X- _ O
the -X- _ O
model, -X- _ O
it -X- _ O
is -X- _ O
plausible -X- _ O
that -X- _ O
in-context -X- _ O
learning -X- _ O
abilities -X- _ O
might -X- _ O
show -X- _ O
similarly -X- _ O
strong -X- _ O
gains -X- _ O
with -X- _ O
scale. -X- _ O
Figure -X- _ O
1.3: -X- _ O
Aggregate -X- _ O
performance -X- _ O
for -X- _ O
all -X- _ O
42 -X- _ O
accuracy-denominated -X- _ O
benchmarks -X- _ O
While -X- _ O
zero-shot -X- _ O
performance -X- _ O
improves -X- _ O
steadily -X- _ O
with -X- _ O
model -X- _ O
size, -X- _ O
few-shot -X- _ O
performance -X- _ O
increases -X- _ O
more -X- _ O
rapidly, -X- _ O
demonstrating -X- _ O
that -X- _ O
larger -X- _ O
models -X- _ O
are -X- _ O
more -X- _ O
proficient -X- _ O
at -X- _ O
in-context -X- _ O
learning. -X- _ O
See -X- _ O
Figure -X- _ O
3.8 -X- _ O
for -X- _ O
a -X- _ O
more -X- _ O
detailed -X- _ O
analysis -X- _ O
on -X- _ O
SuperGLUE, -X- _ O
a -X- _ O
standard -X- _ O
NLP -X- _ O
benchmark -X- _ O
suite. -X- _ O
In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
test -X- _ O
this -X- _ O
hypothesis -X- _ O
by -X- _ O
training -X- _ O
a -X- _ O
175 -X- _ O
billion -X- _ O
parameter -X- _ O
autoregressive -X- _ O
language -X- _ O
model, -X- _ O
which -X- _ O
we -X- _ O
call -X- _ O
GPT-3, -X- _ B-MethodName
and -X- _ O
measuring -X- _ O
its -X- _ O
in-context -X- _ O
learning -X- _ O
abilities. -X- _ O
Specifically, -X- _ O
we -X- _ O
evaluate -X- _ O
GPT-3 -X- _ B-MethodName
on -X- _ O
over -X- _ O
two -X- _ O
dozen -X- _ O
NLP -X- _ O
datasets, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
several -X- _ O
novel -X- _ O
tasks -X- _ O
designed -X- _ O
to -X- _ O
test -X- _ O
rapid -X- _ O
adaptation -X- _ O
to -X- _ O
tasks -X- _ O
unlikely -X- _ O
to -X- _ O
be -X- _ O
directly -X- _ O
contained -X- _ O
in -X- _ O
the -X- _ O
training -X- _ O
set. -X- _ O
For -X- _ O
each -X- _ O
task, -X- _ O
we -X- _ O
evaluate -X- _ O
GPT-3 -X- _ B-MethodName
under -X- _ O
3 -X- _ O
conditions: -X- _ O
(a) -X- _ O
"few-shot -X- _ B-TaskName
learning", -X- _ I-TaskName
or -X- _ O
in-context -X- _ B-TaskName
learning -X- _ I-TaskName
where -X- _ O
we -X- _ O
allow -X- _ O
as -X- _ O
many -X- _ O
demonstrations -X- _ O
as -X- _ O
will -X- _ O
fit -X- _ O
into -X- _ O
the -X- _ O
model's -X- _ O
context -X- _ O
window -X- _ O
(typically -X- _ O
10 -X- _ O
to -X- _ O
100), -X- _ O
(b) -X- _ O
"one-shot -X- _ B-TaskName
learning", -X- _ I-TaskName
where -X- _ O
we -X- _ O
allow -X- _ O
only -X- _ O
one -X- _ O
demonstration, -X- _ O
and -X- _ O
(c) -X- _ O
"zero-shot" -X- _ B-TaskName
learning, -X- _ O
where -X- _ O
no -X- _ O
demonstrations -X- _ O
are -X- _ O
allowed -X- _ O
and -X- _ O
only -X- _ O
an -X- _ O
instruction -X- _ O
in -X- _ O
natural -X- _ O
language -X- _ O
is -X- _ O
given -X- _ O
to -X- _ O
the -X- _ O
model. -X- _ O
GPT-3 -X- _ B-MethodName
could -X- _ O
also -X- _ O
in -X- _ O
principle -X- _ O
be -X- _ O
evaluated -X- _ O
in -X- _ O
the -X- _ O
traditional -X- _ O
fine-tuning -X- _ O
setting, -X- _ O
but -X- _ O
we -X- _ O
leave -X- _ O
this -X- _ O
to -X- _ O
future -X- _ O
work. -X- _ O
Figure -X- _ O
1.2 -X- _ O
illustrates -X- _ O
the -X- _ O
conditions -X- _ O
we -X- _ O
study, -X- _ O
and -X- _ O
shows -X- _ O
few-shot -X- _ B-TaskName
learning -X- _ O
of -X- _ O
a -X- _ O
simple -X- _ O
task -X- _ O
requiring -X- _ O
the -X- _ O
model -X- _ O
to -X- _ O
remove -X- _ O
extraneous -X- _ O
symbols -X- _ O
from -X- _ O
a -X- _ O
word. -X- _ O
Model -X- _ O
performance -X- _ O
improves -X- _ O
with -X- _ O
the -X- _ O
addition -X- _ O
of -X- _ O
a -X- _ O
natural -X- _ O
language -X- _ O
task -X- _ O
description, -X- _ O
and -X- _ O
with -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
in -X- _ O
the -X- _ O
model's -X- _ O
context, -X- _ O
K. -X- _ O
Few-shot -X- _ B-TaskName
learning -X- _ I-TaskName
also -X- _ O
improves -X- _ O
dramatically -X- _ O
with -X- _ O
model -X- _ O
size. -X- _ O
Though -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
this -X- _ O
case -X- _ O
are -X- _ O
particularly -X- _ O
striking, -X- _ O
the -X- _ O
general -X- _ O
trends -X- _ O
with -X- _ O
both -X- _ O
model -X- _ O
size -X- _ O
and -X- _ O
number -X- _ O
of -X- _ O
examples -X- _ O
in-context -X- _ O
hold -X- _ O
for -X- _ O
most -X- _ O
tasks -X- _ O
we -X- _ O
study. -X- _ O
We -X- _ O
emphasize -X- _ O
that -X- _ O
these -X- _ O
"learning" -X- _ O
curves -X- _ O
involve -X- _ O
no -X- _ O
gradient -X- _ O
updates -X- _ O
or -X- _ O
fine-tuning, -X- _ O
just -X- _ O
increasing -X- _ O
numbers -X- _ O
of -X- _ O
demonstrations -X- _ O
given -X- _ O
as -X- _ O
conditioning. -X- _ O
Broadly, -X- _ O
on -X- _ O
NLP -X- _ O
tasks -X- _ O
GPT-3 -X- _ B-MethodName
achieves -X- _ O
promising -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
zero-shot -X- _ O
and -X- _ O
one-shot -X- _ O
settings, -X- _ O
and -X- _ O
in -X- _ O
the -X- _ O
the -X- _ O
few-shot -X- _ O
setting -X- _ O
is -X- _ O
sometimes -X- _ O
competitive -X- _ O
with -X- _ O
or -X- _ O
even -X- _ O
occasionally -X- _ O
surpasses -X- _ O
state-of-the-art -X- _ O
(despite -X- _ O
state-of-the-art -X- _ O
being -X- _ O
held -X- _ O
by -X- _ O
fine-tuned -X- _ O
models). -X- _ O
For -X- _ O
example, -X- _ O
GPT-3 -X- _ B-MethodName
achieves -X- _ O
81.5 -X- _ B-MetricValue
F1 -X- _ B-MetricName
on -X- _ O
CoQA -X- _ B-DatasetName
in -X- _ O
the -X- _ O
zero-shot -X- _ O
setting, -X- _ O
84.0 -X- _ B-MetricValue
F1 -X- _ B-MetricName
on -X- _ O
CoQA -X- _ B-DatasetName
in -X- _ O
the -X- _ O
one-shot -X- _ O
setting, -X- _ O
85.0 -X- _ B-MetricValue
F1 -X- _ B-MetricName
in -X- _ O
the -X- _ O
few-shot -X- _ B-TaskName
setting. -X- _ O
Similarly, -X- _ O
GPT-3 -X- _ O
achieves -X- _ O
64.3% -X- _ B-MetricValue
accuracy -X- _ B-MetricName
on -X- _ O
TriviaQA -X- _ B-DatasetName
in -X- _ O
the -X- _ O
zero-shot -X- _ B-TaskName
setting, -X- _ O
68.0% -X- _ B-MetricValue
in -X- _ O
the -X- _ O
one-shot -X- _ B-TaskName
setting, -X- _ O
and -X- _ O
71.2% -X- _ B-MetricValue
in -X- _ O
the -X- _ O
few-shot -X- _ B-TaskName
setting, -X- _ O
the -X- _ O
last -X- _ O
of -X- _ O
which -X- _ O
is -X- _ O
state-of-the-art -X- _ O
relative -X- _ O
to -X- _ O
fine-tuned -X- _ O
models -X- _ O
operating -X- _ O
in -X- _ O
the -X- _ O
same -X- _ O
closed-book -X- _ O
setting. -X- _ O
GPT-3 -X- _ B-MethodName
also -X- _ O
displays -X- _ O
one-shot -X- _ B-TaskName
and -X- _ O
few-shot -X- _ O
proficiency -X- _ O
at -X- _ O
tasks -X- _ O
designed -X- _ O
to -X- _ O
test -X- _ O
rapid -X- _ O
adaption -X- _ O
or -X- _ O
on-the-fly -X- _ O
reasoning, -X- _ O
which -X- _ O
include -X- _ O
unscrambling -X- _ O
words, -X- _ O
performing -X- _ O
arithmetic, -X- _ O
and -X- _ O
using -X- _ O
novel -X- _ O
words -X- _ O
in -X- _ O
a -X- _ O
sentence -X- _ O
after -X- _ O
seeing -X- _ O
them -X- _ O
defined -X- _ O
only -X- _ O
once. -X- _ O
We -X- _ O
also -X- _ O
show -X- _ O
that -X- _ O
in -X- _ O
the -X- _ O
few-shot -X- _ O
setting, -X- _ O
GPT-3 -X- _ B-MethodName
can -X- _ O
generate -X- _ O
synthetic -X- _ O
news -X- _ O
articles -X- _ O
which -X- _ O
human -X- _ O
evaluators -X- _ O
have -X- _ O
difficulty -X- _ O
distinguishing -X- _ O
from -X- _ O
human-generated -X- _ O
articles. -X- _ O
At -X- _ O
the -X- _ O
same -X- _ O
time, -X- _ O
we -X- _ O
also -X- _ O
find -X- _ O
some -X- _ O
tasks -X- _ O
on -X- _ O
which -X- _ O
few-shot -X- _ O
performance -X- _ O
struggles, -X- _ O
even -X- _ O
at -X- _ O
the -X- _ O
scale -X- _ O
of -X- _ O
GPT-3. -X- _ B-MethodName
This -X- _ O
includes -X- _ B-TaskName
natural -X- _ I-TaskName
language -X- _ I-TaskName
inference -X- _ I-TaskName
tasks -X- _ I-TaskName
like -X- _ O
the -X- _ O
ANLI -X- _ B-DatasetName
dataset, -X- _ O
and -X- _ O
some -X- _ O
reading -X- _ O
comprehension -X- _ O
datasets -X- _ O
like -X- _ O
RACE -X- _ B-DatasetName
or -X- _ O
QuAC. -X- _ B-DatasetName
By -X- _ O
presenting -X- _ O
a -X- _ O
broad -X- _ O
characterization -X- _ O
of -X- _ O
GPT-3's -X- _ B-MethodName
strengths -X- _ O
and -X- _ O
weaknesses, -X- _ O
including -X- _ O
these -X- _ O
limitations, -X- _ O
we -X- _ O
hope -X- _ O
to -X- _ O
stimulate -X- _ O
study -X- _ O
of -X- _ O
few-shot -X- _ O
learning -X- _ O
in -X- _ O
language -X- _ O
models -X- _ O
and -X- _ O
draw -X- _ O
attention -X- _ O
to -X- _ O
where -X- _ O
progress -X- _ O
is -X- _ O
most -X- _ O
needed. -X- _ O
A -X- _ O
heuristic -X- _ O
sense -X- _ O
of -X- _ O
the -X- _ O
overall -X- _ O
results -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
Figure -X- _ O
1.3, -X- _ O
which -X- _ O
aggregates -X- _ O
the -X- _ O
various -X- _ O
tasks -X- _ O
(though -X- _ O
it -X- _ O
should -X- _ O
not -X- _ O
be -X- _ O
seen -X- _ O
as -X- _ O
a -X- _ O
rigorous -X- _ O
or -X- _ O
meaningful -X- _ O
benchmark -X- _ O
in -X- _ O
itself). -X- _ O
We -X- _ O
also -X- _ O
undertake -X- _ O
a -X- _ O
systematic -X- _ O
study -X- _ O
of -X- _ O
"data -X- _ O
contamination" -X- _ O
-a -X- _ O
growing -X- _ O
problem -X- _ O
when -X- _ O
training -X- _ O
high -X- _ O
capacity -X- _ O
models -X- _ O
on -X- _ O
datasets -X- _ O
such -X- _ O
as -X- _ O
Common -X- _ O
Crawl, -X- _ O
which -X- _ O
can -X- _ O
potentially -X- _ O
include -X- _ O
content -X- _ O
from -X- _ O
test -X- _ O
datasets -X- _ O
simply -X- _ O
because -X- _ O
such -X- _ O
content -X- _ O
often -X- _ O
exists -X- _ O
on -X- _ O
the -X- _ O
web. -X- _ O
In -X- _ O
this -X- _ O
paper -X- _ O
we -X- _ O
develop -X- _ O
systematic -X- _ O
tools -X- _ O
to -X- _ O
measure -X- _ O
data -X- _ O
contamination -X- _ O
and -X- _ O
quantify -X- _ O
its -X- _ O
distorting -X- _ O
effects. -X- _ O
Although -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
data -X- _ O
contamination -X- _ O
has -X- _ O
a -X- _ O
minimal -X- _ O
effect -X- _ O
on -X- _ O
GPT-3's -X- _ B-MethodName
performance -X- _ O
on -X- _ O
most -X- _ O
datasets, -X- _ O
we -X- _ O
do -X- _ O
identify -X- _ O
a -X- _ O
few -X- _ O
datasets -X- _ O
where -X- _ O
it -X- _ O
could -X- _ O
be -X- _ O
inflating -X- _ O
results, -X- _ O
and -X- _ O
we -X- _ O
either -X- _ O
do -X- _ O
not -X- _ O
report -X- _ O
results -X- _ O
on -X- _ O
these -X- _ O
datasets -X- _ O
or -X- _ O
we -X- _ O
note -X- _ O
them -X- _ O
with -X- _ O
an -X- _ O
asterisk, -X- _ O
depending -X- _ O
on -X- _ O
the -X- _ O
severity. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
all -X- _ O
the -X- _ O
above, -X- _ O
we -X- _ O
also -X- _ O
train -X- _ O
a -X- _ O
series -X- _ O
of -X- _ O
smaller -X- _ O
models -X- _ O
(ranging -X- _ O
from -X- _ O
125 -X- _ O
million -X- _ O
parameters -X- _ O
to -X- _ O
13 -X- _ O
billion -X- _ O
parameters) -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
compare -X- _ O
their -X- _ O
performance -X- _ O
to -X- _ O
GPT-3 -X- _ B-MethodName
in -X- _ O
the -X- _ O
zero, -X- _ O
one -X- _ O
and -X- _ O
few-shot -X- _ O
settings. -X- _ O
Broadly, -X- _ O
for -X- _ O
most -X- _ O
tasks -X- _ O
we -X- _ O
find -X- _ O
relatively -X- _ O
smooth -X- _ O
scaling -X- _ O
with -X- _ O
model -X- _ O
capacity -X- _ O
in -X- _ O
all -X- _ O
three -X- _ O
settings; -X- _ O
one -X- _ O
notable -X- _ O
pattern -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
gap -X- _ O
between -X- _ O
zero-, -X- _ O
one-, -X- _ O
and -X- _ O
few-shot -X- _ O
performance -X- _ O
often -X- _ O
grows -X- _ O
with -X- _ O
model -X- _ O
capacity, -X- _ O
perhaps -X- _ O
suggesting -X- _ O
that -X- _ O
larger -X- _ O
models -X- _ O
are -X- _ O
more -X- _ O
proficient -X- _ O
meta-learners. -X- _ O
Finally, -X- _ O
given -X- _ O
the -X- _ O
broad -X- _ O
spectrum -X- _ O
of -X- _ O
capabilities -X- _ O
displayed -X- _ O
by -X- _ O
GPT-3, -X- _ B-MethodName
we -X- _ O
discuss -X- _ O
concerns -X- _ O
about -X- _ O
bias, -X- _ O
fairness, -X- _ O
and -X- _ O
broader -X- _ O
societal -X- _ O
impacts, -X- _ O
and -X- _ O
attempt -X- _ O
a -X- _ O
preliminary -X- _ O
analysis -X- _ O
of -X- _ O
GPT-3's -X- _ B-MethodName
characteristics -X- _ O
in -X- _ O
this -X- _ O
regard. -X- _ O
The -X- _ O
remainder -X- _ O
of -X- _ O
this -X- _ O
paper -X- _ O
is -X- _ O
organized -X- _ O
as -X- _ O
follows. -X- _ O
In -X- _ O
Section -X- _ O
2, -X- _ O
we -X- _ O
describe -X- _ O
our -X- _ O
approach -X- _ O
and -X- _ O
methods -X- _ O
for -X- _ O
training -X- _ O
GPT-3 -X- _ B-MethodName
and -X- _ O
evaluating -X- _ O
it. -X- _ O
Section -X- _ O
3 -X- _ O
presents -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
full -X- _ O
range -X- _ O
of -X- _ O
tasks -X- _ O
in -X- _ O
the -X- _ O
zero-, -X- _ O
one-and -X- _ O
few-shot -X- _ O
settings. -X- _ O
Section -X- _ O
4 -X- _ O
addresses -X- _ O
questions -X- _ O
of -X- _ O
data -X- _ O
contamination -X- _ O
(train-test -X- _ O
overlap). -X- _ O
Section -X- _ O
5 -X- _ O
discusses -X- _ O
limitations -X- _ O
of -X- _ O
GPT-3. -X- _ B-MethodName
Section -X- _ O
6 -X- _ O
discusses -X- _ O
broader -X- _ O
impacts. -X- _ O
Section -X- _ O
7 -X- _ O
reviews -X- _ O
related -X- _ O
work -X- _ O
and -X- _ O
Section -X- _ O
8 -X- _ O
concludes. -X- _ O

Recent -X- _ O
work -X- _ O
has -X- _ O
demonstrated -X- _ O
substantial -X- _ O
gains -X- _ O
on -X- _ O
many -X- _ O
NLP -X- _ O
tasks -X- _ O
and -X- _ O
benchmarks -X- _ O
by -X- _ O
pre-training -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
corpus -X- _ O
of -X- _ O
text -X- _ O
followed -X- _ O
by -X- _ O
fine-tuning -X- _ O
on -X- _ O
a -X- _ O
specific -X- _ O
task. -X- _ O
While -X- _ O
typically -X- _ O
task-agnostic -X- _ O
in -X- _ O
architecture, -X- _ O
this -X- _ O
method -X- _ O
still -X- _ O
requires -X- _ O
task-specific -X- _ O
fine-tuning -X- _ O
datasets -X- _ O
of -X- _ O
thousands -X- _ O
or -X- _ O
tens -X- _ O
of -X- _ O
thousands -X- _ O
of -X- _ O
examples. -X- _ O
By -X- _ O
contrast, -X- _ O
humans -X- _ O
can -X- _ O
generally -X- _ O
perform -X- _ O
a -X- _ O
new -X- _ O
language -X- _ O
task -X- _ O
from -X- _ O
only -X- _ O
a -X- _ O
few -X- _ O
examples -X- _ O
or -X- _ O
from -X- _ O
simple -X- _ O
instructions -X- _ O
-something -X- _ O
which -X- _ O
current -X- _ O
NLP -X- _ O
systems -X- _ O
still -X- _ O
largely -X- _ O
struggle -X- _ O
to -X- _ O
do. -X- _ O
Here -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
scaling -X- _ O
up -X- _ O
language -X- _ O
models -X- _ O
greatly -X- _ O
improves -X- _ O
task-agnostic, -X- _ O
few-shot -X- _ O
performance, -X- _ O
sometimes -X- _ O
even -X- _ O
reaching -X- _ O
competitiveness -X- _ O
with -X- _ O
prior -X- _ O
state-of-the-art -X- _ O
finetuning -X- _ O
approaches. -X- _ O
Specifically, -X- _ O
we -X- _ O
train -X- _ O
GPT-3, -X- _ B-MethodName
an -X- _ O
autoregressive -X- _ O
language -X- _ O
model -X- _ O
with -X- _ O
175 -X- _ O
billion -X- _ O
parameters, -X- _ O
10x -X- _ O
more -X- _ O
than -X- _ O
any -X- _ O
previous -X- _ O
non-sparse -X- _ O
language -X- _ O
model, -X- _ O
and -X- _ O
test -X- _ O
its -X- _ O
performance -X- _ O
in -X- _ O
the -X- _ O
few-shot -X- _ O
setting. -X- _ O
For -X- _ O
all -X- _ O
tasks, -X- _ O
GPT-3 -X- _ B-MethodName
is -X- _ O
applied -X- _ O
without -X- _ O
any -X- _ O
gradient -X- _ O
updates -X- _ O
or -X- _ O
fine-tuning, -X- _ O
with -X- _ O
tasks -X- _ O
and -X- _ O
few-shot -X- _ O
demonstrations -X- _ O
specified -X- _ O
purely -X- _ O
via -X- _ O
text -X- _ O
interaction -X- _ O
with -X- _ O
the -X- _ O
model. -X- _ O
GPT-3 -X- _ B-MethodName
achieves -X- _ O
strong -X- _ O
performance -X- _ O
on -X- _ O
many -X- _ O
NLP -X- _ O
datasets, -X- _ O
including -X- _ O
translation, -X- _ B-TaskName
question-answering, -X- _ B-TaskName
and -X- _ O
cloze -X- _ B-TaskName
tasks, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
several -X- _ O
tasks -X- _ O
that -X- _ O
require -X- _ O
on-the-fly -X- _ O
reasoning -X- _ O
or -X- _ O
domain -X- _ O
adaptation, -X- _ O
such -X- _ O
as -X- _ O
unscrambling -X- _ B-TaskName
words, -X- _ I-TaskName
using -X- _ B-TaskName
a -X- _ I-TaskName
novel -X- _ I-TaskName
word -X- _ I-TaskName
in -X- _ I-TaskName
a -X- _ I-TaskName
sentence, -X- _ I-TaskName
or -X- _ O
performing -X- _ B-TaskName
3-digit -X- _ I-TaskName
arithmetic. -X- _ I-TaskName
At -X- _ O
the -X- _ O
same -X- _ O
time, -X- _ O
we -X- _ O
also -X- _ O
identify -X- _ O
some -X- _ O
datasets -X- _ O
where -X- _ O
GPT-3's -X- _ B-MethodName
few-shot -X- _ O
learning -X- _ O
still -X- _ O
struggles, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
some -X- _ O
datasets -X- _ O
where -X- _ O
GPT-3 -X- _ B-MethodName
faces -X- _ O
methodological -X- _ O
issues -X- _ O
related -X- _ O
to -X- _ O
training -X- _ O
on -X- _ O
large -X- _ O
web -X- _ O
corpora. -X- _ O
Finally, -X- _ O
we -X- _ O
find -X- _ O
that -X- _ O
GPT-3 -X- _ B-MethodName
can -X- _ O
generate -X- _ O
samples -X- _ O
of -X- _ O
news -X- _ O
articles -X- _ O
which -X- _ O
human -X- _ O
evaluators -X- _ O
have -X- _ O
difficulty -X- _ O
distinguishing -X- _ O
from -X- _ O
articles -X- _ O
written -X- _ O
by -X- _ O
humans. -X- _ O
We -X- _ O
discuss -X- _ O
broader -X- _ O
societal -X- _ O
impacts -X- _ O
of -X- _ O
this -X- _ O
finding -X- _ O
and -X- _ O
of -X- _ O
GPT-3 -X- _ B-MethodName
in -X- _ O
general. -X- _ O


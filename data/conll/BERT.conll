-DOCSTART- -X- O
All -X- _ O
of -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
results -X- _ O
presented -X- _ O
so -X- _ O
far -X- _ O
have -X- _ O
used -X- _ O
the -X- _ O
fine-tuning -X- _ O
approach, -X- _ O
where -X- _ O
a -X- _ O
simple -X- _ O
classification -X- _ O
layer -X- _ O
is -X- _ O
added -X- _ O
to -X- _ O
the -X- _ O
pre-trained -X- _ O
model, -X- _ O
and -X- _ O
all -X- _ O
parameters -X- _ O
are -X- _ O
jointly -X- _ O
fine-tuned -X- _ O
on -X- _ O
a -X- _ O
downstream -X- _ O
task. -X- _ O
However, -X- _ O
the -X- _ O
feature-based -X- _ O
approach, -X- _ O
where -X- _ O
fixed -X- _ O
features -X- _ O
are -X- _ O
extracted -X- _ O
from -X- _ O
the -X- _ O
pretrained -X- _ O
model, -X- _ O
has -X- _ O
certain -X- _ O
advantages. -X- _ O
First, -X- _ O
not -X- _ O
all -X- _ O
tasks -X- _ O
can -X- _ O
be -X- _ O
easily -X- _ O
represented -X- _ O
by -X- _ O
a -X- _ O
Transformer -X- _ O
encoder -X- _ O
architecture, -X- _ O
and -X- _ O
therefore -X- _ O
require -X- _ O
a -X- _ O
task-specific -X- _ O
model -X- _ O
architecture -X- _ O
to -X- _ O
be -X- _ O
added. -X- _ O
Second, -X- _ O
there -X- _ O
are -X- _ O
major -X- _ O
computational -X- _ O
benefits -X- _ O
to -X- _ O
pre-compute -X- _ O
an -X- _ O
expensive -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
training -X- _ O
data -X- _ O
once -X- _ O
and -X- _ O
then -X- _ O
run -X- _ O
many -X- _ O
experiments -X- _ O
with -X- _ O
cheaper -X- _ O
models -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
this -X- _ O
representation. -X- _ O
In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
two -X- _ O
approaches -X- _ O
by -X- _ O
applying -X- _ O
BERT -X- _ B-MethodName
to -X- _ O
the -X- _ O
CoNLL-2003 -X- _ B-DatasetName
Named -X- _ B-TaskName
Entity -X- _ I-TaskName
Recognition -X- _ I-TaskName
(NER) -X- _ B-TaskName
task -X- _ O
(Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder, -X- _ O
2003). -X- _ O
In -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
BERT, -X- _ B-MethodName
we -X- _ O
use -X- _ O
a -X- _ O
case-preserving -X- _ O
WordPiece -X- _ O
model, -X- _ O
and -X- _ O
we -X- _ O
include -X- _ O
the -X- _ O
maximal -X- _ O
document -X- _ O
context -X- _ O
provided -X- _ O
by -X- _ O
the -X- _ O
data. -X- _ O
Following -X- _ O
standard -X- _ O
practice, -X- _ O
we -X- _ O
formulate -X- _ O
this -X- _ O
as -X- _ O
a -X- _ O
tagging -X- _ O
task -X- _ O
but -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
a -X- _ O
CRF -X- _ O
layer -X- _ O
in -X- _ O
the -X- _ O
output. -X- _ O
We -X- _ O
use -X- _ O
the -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
sub-token -X- _ O
as -X- _ O
the -X- _ O
input -X- _ O
to -X- _ O
the -X- _ O
token-level -X- _ O
classifier -X- _ O
over -X- _ O
the -X- _ O
NER -X- _ B-TaskName
label -X- _ O
set. -X- _ O
To -X- _ O
ablate -X- _ O
the -X- _ O
fine-tuning -X- _ O
approach, -X- _ O
we -X- _ O
apply -X- _ O
the -X- _ O
feature-based -X- _ O
approach -X- _ O
by -X- _ O
extracting -X- _ O
the -X- _ O
activations -X- _ O
from -X- _ O
one -X- _ O
or -X- _ O
more -X- _ O
layers -X- _ O
without -X- _ O
fine-tuning -X- _ O
any -X- _ O
parameters -X- _ O
of -X- _ O
BERT. -X- _ B-MethodName
These -X- _ O
contextual -X- _ O
embeddings -X- _ O
are -X- _ O
used -X- _ O
as -X- _ O
input -X- _ O
to -X- _ O
a -X- _ O
randomly -X- _ O
initialized -X- _ O
two-layer -X- _ B-HyperparameterValue
768-dimensional -X- _ B-HyperparameterValue
BiLSTM -X- _ O
before -X- _ O
the -X- _ O
classification -X- _ O
layer. -X- _ O
Results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
7. -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
performs -X- _ O
competitively -X- _ O
with -X- _ O
state-of-the-art -X- _ O
methods. -X- _ O
The -X- _ O
best -X- _ O
performing -X- _ O
method -X- _ O
concatenates -X- _ O
the -X- _ O
token -X- _ O
representations -X- _ O
from -X- _ O
the -X- _ O
top -X- _ O
four -X- _ O
hidden -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
pre-trained -X- _ O
Transformer, -X- _ O
which -X- _ O
is -X- _ O
only -X- _ O
0.3 -X- _ B-MetricValue
F1 -X- _ B-MetricName
behind -X- _ O
fine-tuning -X- _ O
the -X- _ O
entire -X- _ O
model. -X- _ O
This -X- _ O
demonstrates -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
effective -X- _ O
for -X- _ O
both -X- _ O
finetuning -X- _ O
and -X- _ O
feature-based -X- _ O
approaches. -X- _ O

To -X- _ O
generate -X- _ O
each -X- _ O
training -X- _ O
input -X- _ O
sequence, -X- _ O
we -X- _ O
sample -X- _ O
two -X- _ O
spans -X- _ O
of -X- _ O
text -X- _ O
from -X- _ O
the -X- _ O
corpus, -X- _ O
which -X- _ O
we -X- _ O
refer -X- _ O
to -X- _ O
as -X- _ O
"sentences" -X- _ O
even -X- _ O
though -X- _ O
they -X- _ O
are -X- _ O
typically -X- _ O
much -X- _ O
longer -X- _ O
than -X- _ O
single -X- _ O
sentences -X- _ O
(but -X- _ O
can -X- _ O
be -X- _ O
shorter -X- _ O
also). -X- _ O
The -X- _ O
first -X- _ O
sentence -X- _ O
receives -X- _ O
the -X- _ O
A -X- _ O
embedding -X- _ O
and -X- _ O
the -X- _ O
second -X- _ O
receives -X- _ O
the -X- _ O
B -X- _ O
embedding. -X- _ O
50% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
B -X- _ O
is -X- _ O
the -X- _ O
actual -X- _ O
next -X- _ O
sentence -X- _ O
that -X- _ O
follows -X- _ O
A -X- _ O
and -X- _ O
50% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
random -X- _ O
sentence, -X- _ O
which -X- _ O
is -X- _ O
done -X- _ O
for -X- _ O
the -X- _ O
"next -X- _ O
sentence -X- _ O
prediction" -X- _ O
task. -X- _ O
They -X- _ O
are -X- _ O
sampled -X- _ O
such -X- _ O
that -X- _ O
the -X- _ O
combined -X- _ O
length -X- _ O
is -X- _ O
 -X- _ O
512 -X- _ O
tokens. -X- _ O
The -X- _ O
LM -X- _ O
masking -X- _ O
is -X- _ O
applied -X- _ O
after -X- _ O
WordPiece -X- _ O
tokenization -X- _ O
with -X- _ O
a -X- _ O
uniform -X- _ O
masking -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
15%, -X- _ B-HyperparameterValue
and -X- _ O
no -X- _ O
special -X- _ O
consideration -X- _ O
given -X- _ O
to -X- _ O
partial -X- _ O
word -X- _ O
pieces. -X- _ O
We -X- _ O
train -X- _ O
with -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
256 -X- _ B-HyperparameterValue
sequences -X- _ O
(256 -X- _ O
sequences -X- _ O
* -X- _ O
512 -X- _ O
tokens -X- _ O
= -X- _ O
128,000 -X- _ O
tokens/batch) -X- _ O
for -X- _ O
1,000,000 -X- _ O
steps, -X- _ O
which -X- _ O
is -X- _ O
approximately -X- _ O
40 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
over -X- _ O
the -X- _ O
3.3 -X- _ O
billion -X- _ O
word -X- _ O
corpus. -X- _ O
We -X- _ O
use -X- _ O
Adam -X- _ B-HyperparameterValue
with -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
1e-4, -X- _ B-HyperparameterValue
1 -X- _ O
= -X- _ O
0.9, -X- _ B-HyperparameterValue
2 -X- _ O
= -X- _ O
0.999, -X- _ B-HyperparameterValue
L2 -X- _ B-HyperparameterName
weight -X- _ I-HyperparameterName
decay -X- _ I-HyperparameterName
of -X- _ O
0.01, -X- _ B-HyperparameterValue
learning -X- _ O
rate -X- _ O
warmup -X- _ O
over -X- _ O
the -X- _ O
first -X- _ O
10,000 -X- _ O
steps, -X- _ O
and -X- _ O
linear -X- _ O
decay -X- _ O
of -X- _ O
the -X- _ O
learning -X- _ O
rate. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
dropout -X- _ B-HyperparameterName
probability -X- _ I-HyperparameterName
of -X- _ O
0.1 -X- _ B-HyperparameterValue
on -X- _ O
all -X- _ O
layers. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
gelu -X- _ B-HyperparameterValue
activation -X- _ B-HyperparameterName
(Hendrycks -X- _ O
and -X- _ O
Gimpel, -X- _ O
2016) -X- _ O
rather -X- _ O
than -X- _ O
the -X- _ O
standard -X- _ O
relu, -X- _ O
following -X- _ O
OpenAI -X- _ O
GPT. -X- _ O
The -X- _ O
training -X- _ O
loss -X- _ O
is -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
mean -X- _ O
masked -X- _ O
LM -X- _ O
likelihood -X- _ O
and -X- _ O
the -X- _ O
mean -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
likelihood. -X- _ O
Training -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
was -X- _ O
performed -X- _ O
on -X- _ O
4 -X- _ O
Cloud -X- _ O
TPUs -X- _ O
in -X- _ O
Pod -X- _ O
configuration -X- _ O
(16 -X- _ O
TPU -X- _ O
chips -X- _ O
total). -X- _ O
13 -X- _ O
Training -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
was -X- _ O
performed -X- _ O
on -X- _ O
16 -X- _ O
Cloud -X- _ O
TPUs -X- _ O
(64 -X- _ O
TPU -X- _ O
chips -X- _ O
total). -X- _ O
Each -X- _ O
pretraining -X- _ O
took -X- _ O
4 -X- _ O
days -X- _ O
to -X- _ O
complete. -X- _ O
Longer -X- _ O
sequences -X- _ O
are -X- _ O
disproportionately -X- _ O
expensive -X- _ O
because -X- _ O
attention -X- _ O
is -X- _ O
quadratic -X- _ O
to -X- _ O
the -X- _ O
sequence -X- _ O
length. -X- _ O
To -X- _ O
speed -X- _ O
up -X- _ O
pretraing -X- _ O
in -X- _ O
our -X- _ O
experiments, -X- _ O
we -X- _ O
pre-train -X- _ O
the -X- _ O
model -X- _ O
with -X- _ O
sequence -X- _ B-HyperparameterName
length -X- _ I-HyperparameterName
of -X- _ O
128 -X- _ B-HyperparameterValue
for -X- _ O
90% -X- _ O
of -X- _ O
the -X- _ O
steps. -X- _ O
Then, -X- _ O
we -X- _ O
train -X- _ O
the -X- _ O
rest -X- _ O
10% -X- _ O
of -X- _ O
the -X- _ O
steps -X- _ O
of -X- _ O
sequence -X- _ B-HyperparameterName
of -X- _ O
512 -X- _ B-HyperparameterValue
to -X- _ O
learn -X- _ O
the -X- _ O
positional -X- _ O
embeddings. -X- _ O

Language -X- _ O
Understanding" -X- _ O
We -X- _ O
organize -X- _ O
the -X- _ O
appendix -X- _ O
into -X- _ O
three -X- _ O
sections: -X- _ O
• -X- _ O
Additional -X- _ O
implementation -X- _ O
details -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
are -X- _ O
presented -X- _ O
in -X- _ O
Appendix -X- _ O
A; -X- _ O
• -X- _ O
Additional -X- _ O
details -X- _ O
for -X- _ O
our -X- _ O
experiments -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Appendix -X- _ O
B; -X- _ O
and -X- _ O
• -X- _ O
Additional -X- _ O
ablation -X- _ O
studies -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Appendix -X- _ O
C. -X- _ O
We -X- _ O
present -X- _ O
additional -X- _ O
ablation -X- _ O
studies -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
including: -X- _ O

Figure -X- _ O
5 -X- _ O
presents -X- _ O
MNLI -X- _ B-DatasetName
Dev -X- _ O
accuracy -X- _ O
after -X- _ O
finetuning -X- _ O
from -X- _ O
a -X- _ O
checkpoint -X- _ O
that -X- _ O
has -X- _ O
been -X- _ O
pre-trained -X- _ O
for -X- _ O
k -X- _ O
steps. -X- _ O
This -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
answer -X- _ O
the -X- _ O
following -X- _ O
questions: -X- _ O
1 -X- _ O
Note -X- _ O
that -X- _ O
the -X- _ O
purpose -X- _ O
of -X- _ O
the -X- _ O
masking -X- _ O
strategies -X- _ O
is -X- _ O
to -X- _ O
reduce -X- _ O
the -X- _ O
mismatch -X- _ O
between -X- _ O
pre-training -X- _ O
and -X- _ O
fine-tuning, -X- _ O
as -X- _ O
the -X- _ O
[MASK] -X- _ O
symbol -X- _ O
never -X- _ O
appears -X- _ O
during -X- _ O
the -X- _ O
fine-tuning -X- _ O
stage. -X- _ O
We -X- _ O
report -X- _ O
the -X- _ O
Dev -X- _ O
results -X- _ O
for -X- _ O
both -X- _ O
MNLI -X- _ O
and -X- _ O
NER. -X- _ B-TaskName
For -X- _ O
NER, -X- _ B-TaskName
we -X- _ O
report -X- _ O
both -X- _ O
fine-tuning -X- _ O
and -X- _ O
feature-based -X- _ O
approaches, -X- _ O
as -X- _ O
we -X- _ O
expect -X- _ O
the -X- _ O
mismatch -X- _ O
will -X- _ O
be -X- _ O
amplified -X- _ O
for -X- _ O
the -X- _ O
feature-based -X- _ O
approach -X- _ O
as -X- _ O
the -X- _ O
model -X- _ O
will -X- _ O
not -X- _ O
have -X- _ O
the -X- _ O
chance -X- _ O
to -X- _ O
adjust -X- _ O
the -X- _ O
representations. -X- _ O
The -X- _ O
results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
8. -X- _ O
In -X- _ O
the -X- _ O
table, -X- _ O
MASK -X- _ O
means -X- _ O
that -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
target -X- _ O
token -X- _ O
with -X- _ O
the -X- _ O
[MASK] -X- _ O
symbol -X- _ O
for -X- _ O
MLM; -X- _ B-TaskName
SAME -X- _ O
means -X- _ O
that -X- _ O
we -X- _ O
keep -X- _ O
the -X- _ O
target -X- _ O
token -X- _ O
as -X- _ O
is; -X- _ O
RND -X- _ O
means -X- _ O
that -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
target -X- _ O
token -X- _ O
with -X- _ O
another -X- _ O
random -X- _ O
token. -X- _ O
The -X- _ O
numbers -X- _ O
in -X- _ O
the -X- _ O
left -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
table -X- _ O
represent -X- _ O
the -X- _ O
probabilities -X- _ O
of -X- _ O
the -X- _ O
specific -X- _ O
strategies -X- _ O
used -X- _ O
during -X- _ O
MLM -X- _ B-TaskName
pre-training -X- _ O
(BERT -X- _ B-MethodName
uses -X- _ O
80%, -X- _ O
10%, -X- _ O
10%). -X- _ O
The -X- _ O
right -X- _ O
part -X- _ O
of -X- _ O
the -X- _ O
paper -X- _ O
represents -X- _ O
the -X- _ O
Dev -X- _ O
set -X- _ O
results. -X- _ O
For -X- _ O
the -X- _ O
feature-based -X- _ O
approach, -X- _ O
we -X- _ O
concatenate -X- _ O
the -X- _ O
last -X- _ O
4 -X- _ O
layers -X- _ O
of -X- _ O
BERT -X- _ O
as -X- _ O
the -X- _ O
features, -X- _ O
which -X- _ O
was -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
the -X- _ O
best -X- _ O
approach -X- _ O
in -X- _ O
Section -X- _ O
5.3. -X- _ O
From -X- _ O
the -X- _ O
table -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
that -X- _ O
fine-tuning -X- _ O
is -X- _ O
surprisingly -X- _ O
robust -X- _ O
to -X- _ O
different -X- _ O
masking -X- _ O
strategies. -X- _ O
However, -X- _ O
as -X- _ O
expected, -X- _ O
using -X- _ O
only -X- _ O
the -X- _ O
MASK -X- _ O
strategy -X- _ O
was -X- _ O
problematic -X- _ O
when -X- _ O
applying -X- _ O
the -X- _ O
featurebased -X- _ O
approach -X- _ O
to -X- _ O
NER. -X- _ B-TaskName
Interestingly, -X- _ O
using -X- _ O
only -X- _ O
the -X- _ O
RND -X- _ O
strategy -X- _ O
performs -X- _ O
much -X- _ O
worse -X- _ O
than -X- _ O
our -X- _ O
strategy -X- _ O
as -X- _ O
well. -X- _ O

The -X- _ O
Semantic -X- _ B-DatasetName
Textual -X- _ I-DatasetName
Similarity -X- _ I-DatasetName
Benchmark -X- _ I-DatasetName
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
sentence -X- _ O
pairs -X- _ O
drawn -X- _ O
from -X- _ O
news -X- _ O
headlines -X- _ O
and -X- _ O
other -X- _ O
sources -X- _ O
(Cer -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O
They -X- _ O
were -X- _ O
annotated -X- _ O
with -X- _ O
a -X- _ O
score -X- _ O
from -X- _ O
1 -X- _ O
to -X- _ O
5 -X- _ O
denoting -X- _ O
how -X- _ O
similar -X- _ O
the -X- _ O
two -X- _ O
sentences -X- _ O
are -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
semantic -X- _ O
meaning. -X- _ O
MRPC -X- _ B-DatasetName
Microsoft -X- _ B-DatasetName
Research -X- _ I-DatasetName
Paraphrase -X- _ I-DatasetName
Corpus -X- _ I-DatasetName
consists -X- _ O
of -X- _ O
sentence -X- _ O
pairs -X- _ O
automatically -X- _ O
extracted -X- _ O
from -X- _ O
online -X- _ O
news -X- _ O
sources, -X- _ O
with -X- _ O
human -X- _ O
annotations -X- _ O
for -X- _ O
whether -X- _ O
the -X- _ O
sentences -X- _ O
in -X- _ O
the -X- _ O
pair -X- _ O
are -X- _ O
semantically -X- _ O
equivalent -X- _ O
(Dolan -X- _ O
and -X- _ O
Brockett, -X- _ O
2005). -X- _ O
RTE -X- _ B-DatasetName
Recognizing -X- _ B-DatasetName
Textual -X- _ I-DatasetName
Entailment -X- _ I-DatasetName
is -X- _ O
a -X- _ O
binary -X- _ O
entailment -X- _ O
task -X- _ O
similar -X- _ O
to -X- _ O
MNLI, -X- _ O
but -X- _ O
with -X- _ O
much -X- _ O
less -X- _ O
training -X- _ O
data -X- _ O
(Bentivogli -X- _ O
et -X- _ O
al., -X- _ O
2009). -X- _ O
14 -X- _ O
WNLI -X- _ B-DatasetName
Winograd -X- _ B-DatasetName
NLI -X- _ I-DatasetName
is -X- _ O
a -X- _ O
small -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
dataset -X- _ O
(Levesque -X- _ O
et -X- _ O
al., -X- _ O
2011). -X- _ O
The -X- _ O
GLUE -X- _ B-DatasetName
webpage -X- _ O
notes -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
issues -X- _ O
with -X- _ O
the -X- _ O
construction -X- _ O
of -X- _ O
this -X- _ O
dataset, -X- _ O
15 -X- _ O
and -X- _ O
every -X- _ O
trained -X- _ O
system -X- _ O
that's -X- _ O
been -X- _ O
submitted -X- _ O
to -X- _ O
GLUE -X- _ B-DatasetName
has -X- _ O
performed -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
65.1 -X- _ O
baseline -X- _ O
accuracy -X- _ O
of -X- _ O
predicting -X- _ O
the -X- _ O
majority -X- _ O
class. -X- _ O
We -X- _ O
therefore -X- _ O
exclude -X- _ O
this -X- _ O
set -X- _ O
to -X- _ O
be -X- _ O
fair -X- _ O
to -X- _ O
OpenAI -X- _ O
GPT. -X- _ B-MethodName
For -X- _ O
our -X- _ O
GLUE -X- _ B-DatasetName
submission, -X- _ O
we -X- _ O
always -X- _ O
predicted -X- _ O
the -X- _ O
ma-jority -X- _ O
class. -X- _ O

The -X- _ O
Stanford -X- _ B-DatasetName
Sentiment -X- _ I-DatasetName
Treebank -X- _ I-DatasetName
is -X- _ O
a -X- _ O
binary -X- _ O
single-sentence -X- _ O
classification -X- _ O
task -X- _ O
consisting -X- _ O
of -X- _ O
sentences -X- _ O
extracted -X- _ O
from -X- _ O
movie -X- _ O
reviews -X- _ O
with -X- _ O
human -X- _ O
annotations -X- _ O
of -X- _ O
their -X- _ O
sentiment -X- _ O
(Socher -X- _ O
et -X- _ O
al., -X- _ O
2013). -X- _ O
CoLA -X- _ B-DatasetName
The -X- _ B-DatasetName
Corpus -X- _ I-DatasetName
of -X- _ I-DatasetName
Linguistic -X- _ I-DatasetName
Acceptability -X- _ I-DatasetName
is -X- _ O
a -X- _ O
binary -X- _ O
single-sentence -X- _ O
classification -X- _ O
task, -X- _ O
where -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
an -X- _ O
English -X- _ O
sentence -X- _ O
is -X- _ O
linguistically -X- _ O
"acceptable" -X- _ O
or -X- _ O
not -X- _ O
(Warstadt -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O

Tasks -X- _ O
The -X- _ O
illustration -X- _ O
of -X- _ O
fine-tuning -X- _ O
BERT -X- _ B-MethodName
on -X- _ O
different -X- _ O
tasks -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
Figure -X- _ O
4. -X- _ O
Our -X- _ O
task-specific -X- _ O
models -X- _ O
are -X- _ O
formed -X- _ O
by -X- _ O
incorporating -X- _ O
BERT -X- _ B-MethodName
with -X- _ O
one -X- _ O
additional -X- _ O
output -X- _ O
layer, -X- _ O
so -X- _ O
a -X- _ O
minimal -X- _ O
number -X- _ O
of -X- _ O
parameters -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
learned -X- _ O
from -X- _ O
scratch. -X- _ O
Among -X- _ O
the -X- _ O
tasks, -X- _ O
MNLI -X- _ B-DatasetName
Multi-Genre -X- _ B-DatasetName
Natural -X- _ I-DatasetName
Language -X- _ I-DatasetName
Inference -X- _ I-DatasetName
is -X- _ O
a -X- _ O
large-scale, -X- _ O
crowdsourced -X- _ O
entailment -X- _ O
classification -X- _ O
task -X- _ O
(Williams -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O
Given -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
sentences, -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
whether -X- _ O
the -X- _ O
second -X- _ O
sentence -X- _ O
is -X- _ O
an -X- _ O
entailment, -X- _ O
contradiction, -X- _ O
or -X- _ O
neutral -X- _ O
with -X- _ O
respect -X- _ O
to -X- _ O
the -X- _ O
first -X- _ O
one. -X- _ O
QQP -X- _ B-DatasetName
Quora -X- _ B-DatasetName
Question -X- _ I-DatasetName
Pairs -X- _ I-DatasetName
is -X- _ O
a -X- _ O
binary -X- _ O
classification -X- _ O
task -X- _ O
where -X- _ O
the -X- _ O
goal -X- _ O
is -X- _ O
to -X- _ O
determine -X- _ O
if -X- _ O
two -X- _ O
questions -X- _ O
asked -X- _ O
on -X- _ O
Quora -X- _ O
are -X- _ O
semantically -X- _ O
equivalent -X- _ O
. -X- _ O
QNLI -X- _ B-DatasetName
Question -X- _ B-DatasetName
Natural -X- _ I-DatasetName
Language -X- _ I-DatasetName
Inference -X- _ I-DatasetName
is -X- _ O
a -X- _ O
version -X- _ O
of -X- _ O
the -X- _ O
Stanford -X- _ B-DatasetName
Question -X- _ I-DatasetName
Answering -X- _ I-DatasetName
Dataset -X- _ I-DatasetName
(Rajpurkar -X- _ O
et -X- _ O
al., -X- _ O
2016) -X- _ O
which -X- _ O
has -X- _ O
been -X- _ O
converted -X- _ O
to -X- _ O
a -X- _ O
binary -X- _ O
classification -X- _ O
task -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2018a) -X- _ O
... -X- _ O
... -X- _ O
... -X- _ O

OpenAI -X- _ O
GPT -X- _ B-MethodName
Here -X- _ O
we -X- _ O
studies -X- _ O
the -X- _ O
differences -X- _ O
in -X- _ O
recent -X- _ O
popular -X- _ O
representation -X- _ O
learning -X- _ O
models -X- _ O
including -X- _ O
ELMo, -X- _ B-MethodName
OpenAI -X- _ O
GPT -X- _ B-MethodName
and -X- _ O
BERT. -X- _ B-MethodName
The -X- _ O
comparisons -X- _ O
between -X- _ O
the -X- _ O
model -X- _ O
architectures -X- _ O
are -X- _ O
shown -X- _ O
visually -X- _ O
in -X- _ O
Figure -X- _ O
3. -X- _ O
Note -X- _ O
that -X- _ O
in -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
architecture -X- _ O
differences, -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
OpenAI -X- _ O
GPT -X- _ B-MethodName
are -X- _ O
finetuning -X- _ O
approaches, -X- _ O
while -X- _ O
ELMo -X- _ B-MethodName
is -X- _ O
a -X- _ O
feature-based -X- _ O
approach. -X- _ O
The -X- _ O
most -X- _ O
comparable -X- _ O
existing -X- _ O
pre-training -X- _ O
method -X- _ O
to -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
OpenAI -X- _ O
GPT, -X- _ B-MethodName
which -X- _ O
trains -X- _ O
a -X- _ O
left-to-right -X- _ O
Transformer -X- _ O
LM -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
text -X- _ O
corpus. -X- _ O
In -X- _ O
fact, -X- _ O
many -X- _ O
of -X- _ O
the -X- _ O
design -X- _ O
decisions -X- _ O
in -X- _ O
BERT -X- _ B-MethodName
were -X- _ O
intentionally -X- _ O
made -X- _ O
to -X- _ O
make -X- _ O
it -X- _ O
as -X- _ O
close -X- _ O
to -X- _ O
GPT -X- _ B-MethodName
as -X- _ O
possible -X- _ O
so -X- _ O
that -X- _ O
the -X- _ O
two -X- _ O
methods -X- _ O
could -X- _ O
be -X- _ O
minimally -X- _ O
compared. -X- _ O
The -X- _ O
core -X- _ O
argument -X- _ O
of -X- _ O
this -X- _ O
work -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
bi-directionality -X- _ O
and -X- _ O
the -X- _ O
two -X- _ O
pretraining -X- _ O
tasks -X- _ O
presented -X- _ O
in -X- _ O
Section -X- _ O
3.1 -X- _ O
account -X- _ O
for -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
the -X- _ O
empirical -X- _ O
improvements, -X- _ O
but -X- _ O
we -X- _ O
do -X- _ O
note -X- _ O
that -X- _ O
there -X- _ O
are -X- _ O
several -X- _ O
other -X- _ O
differences -X- _ O
between -X- _ O
how -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
GPT -X- _ B-MethodName
were -X- _ O
trained: -X- _ O
• -X- _ O
GPT -X- _ B-MethodName
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
BooksCorpus -X- _ B-DatasetName
(800M -X- _ O
words); -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
BooksCorpus -X- _ B-DatasetName
(800M -X- _ O
words) -X- _ O
and -X- _ O
Wikipedia -X- _ B-DatasetName
(2,500M -X- _ O
words). -X- _ O
• -X- _ O
GPT -X- _ B-MethodName
uses -X- _ O
a -X- _ O
sentence -X- _ O
separator -X- _ O
( -X- _ O
• -X- _ O
GPT -X- _ B-MethodName
was -X- _ O
trained -X- _ O
for -X- _ O
1M -X- _ O
steps -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ O
size -X- _ O
of -X- _ O
32,000 -X- _ O
words; -X- _ O
BERT -X- _ B-MethodName
was -X- _ O
trained -X- _ O
for -X- _ O
1M -X- _ O
steps -X- _ O
with -X- _ O
a -X- _ O
batch -X- _ O
size -X- _ O
of -X- _ O
128,000 -X- _ O
words. -X- _ O
• -X- _ O
GPT -X- _ B-MethodName
used -X- _ O
the -X- _ O
same -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
5e-5 -X- _ B-HyperparameterValue
for -X- _ O
all -X- _ O
fine-tuning -X- _ O
experiments; -X- _ O
BERT -X- _ B-MethodName
chooses -X- _ O
a -X- _ O
task-specific -X- _ O
fine-tuning -X- _ O
learning -X- _ O
rate -X- _ O
which -X- _ O
performs -X- _ O
the -X- _ O
best -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set. -X- _ O
To -X- _ O
isolate -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
these -X- _ O
differences, -X- _ O
we -X- _ O
perform -X- _ O
ablation -X- _ O
experiments -X- _ O
in -X- _ O
Section -X- _ O
5.1 -X- _ O
which -X- _ O
demonstrate -X- _ O
that -X- _ O
the -X- _ O
majority -X- _ O
of -X- _ O
the -X- _ O
improvements -X- _ O
are -X- _ O
in -X- _ O
fact -X- _ O
coming -X- _ O
from -X- _ O
the -X- _ O
two -X- _ O
pre-training -X- _ O
tasks -X- _ O
and -X- _ O
the -X- _ O
bidirectionality -X- _ O
they -X- _ O
enable. -X- _ O

For -X- _ O
fine-tuning, -X- _ O
most -X- _ O
model -X- _ O
hyperparameters -X- _ O
are -X- _ O
the -X- _ O
same -X- _ O
as -X- _ O
in -X- _ O
pre-training, -X- _ O
with -X- _ O
the -X- _ O
exception -X- _ O
of -X- _ O
the -X- _ O
batch -X- _ B-HyperparameterName
size, -X- _ I-HyperparameterName
learning -X- _ B-HyperparameterName
rate, -X- _ I-HyperparameterName
and -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
training -X- _ I-HyperparameterName
epochs. -X- _ I-HyperparameterName
The -X- _ O
dropout -X- _ B-HyperparameterName
probability -X- _ I-HyperparameterName
was -X- _ O
always -X- _ O
kept -X- _ O
at -X- _ O
0.1. -X- _ B-HyperparameterValue
The -X- _ O
optimal -X- _ O
hyperparameter -X- _ O
values -X- _ O
are -X- _ O
task-specific, -X- _ O
but -X- _ O
we -X- _ O
found -X- _ O
the -X- _ O
following -X- _ O
range -X- _ O
of -X- _ O
possible -X- _ O
values -X- _ O
to -X- _ O
work -X- _ O
well -X- _ O
across -X- _ O
all -X- _ O
tasks: -X- _ O
• -X- _ O
Batch -X- _ B-HyperparameterName
size: -X- _ I-HyperparameterName
16, -X- _ B-HyperparameterValue
32 -X- _ B-HyperparameterValue
We -X- _ O
also -X- _ O
observed -X- _ O
that -X- _ O
large -X- _ O
data -X- _ O
sets -X- _ O
(e.g., -X- _ O
100k+ -X- _ O
labeled -X- _ O
training -X- _ O
examples) -X- _ O
were -X- _ O
far -X- _ O
less -X- _ O
sensitive -X- _ O
to -X- _ O
hyperparameter -X- _ O
choice -X- _ O
than -X- _ O
small -X- _ O
data -X- _ O
sets. -X- _ O
Fine-tuning -X- _ O
is -X- _ O
typically -X- _ O
very -X- _ O
fast, -X- _ O
so -X- _ O
it -X- _ O
is -X- _ O
reasonable -X- _ O
to -X- _ O
simply -X- _ O
run -X- _ O
an -X- _ O
exhaustive -X- _ O
search -X- _ O
over -X- _ O
the -X- _ O
above -X- _ O
parameters -X- _ O
and -X- _ O
choose -X- _ O
the -X- _ O
model -X- _ O
that -X- _ O
performs -X- _ O
best -X- _ O
on -X- _ O
the -X- _ O
development -X- _ O
set. -X- _ O

Recent -X- _ O
empirical -X- _ O
improvements -X- _ O
due -X- _ O
to -X- _ O
transfer -X- _ O
learning -X- _ O
with -X- _ O
language -X- _ O
models -X- _ O
have -X- _ O
demonstrated -X- _ O
that -X- _ O
rich, -X- _ O
unsupervised -X- _ O
pre-training -X- _ O
is -X- _ O
an -X- _ O
integral -X- _ O
part -X- _ O
of -X- _ O
many -X- _ O
language -X- _ O
understanding -X- _ O
systems. -X- _ O
In -X- _ O
particular, -X- _ O
these -X- _ O
results -X- _ O
enable -X- _ O
even -X- _ O
low-resource -X- _ O
tasks -X- _ O
to -X- _ O
benefit -X- _ O
from -X- _ O
deep -X- _ O
unidirectional -X- _ O
architectures. -X- _ O
Our -X- _ O
major -X- _ O
contribution -X- _ O
is -X- _ O
further -X- _ O
generalizing -X- _ O
these -X- _ O
findings -X- _ O
to -X- _ O
deep -X- _ O
bidirectional -X- _ O
architectures, -X- _ O
allowing -X- _ O
the -X- _ O
same -X- _ O
pre-trained -X- _ O
model -X- _ O
to -X- _ O
successfully -X- _ O
tackle -X- _ O
a -X- _ O
broad -X- _ O
set -X- _ O
of -X- _ O
NLP -X- _ O
tasks. -X- _ O
Masked -X- _ B-TaskName
LM -X- _ I-TaskName
and -X- _ O
the -X- _ O
Masking -X- _ O
Procedure -X- _ O
Assuming -X- _ O
the -X- _ O
unlabeled -X- _ O
sentence -X- _ O
is -X- _ O
my -X- _ O
dog -X- _ O
is -X- _ O
hairy, -X- _ O
and -X- _ O
during -X- _ O
the -X- _ O
random -X- _ O
masking -X- _ O
procedure -X- _ O
we -X- _ O
chose -X- _ O
the -X- _ O
4-th -X- _ O
token -X- _ O
(which -X- _ O
corresponding -X- _ O
to -X- _ O
hairy), -X- _ O
our -X- _ O
masking -X- _ O
procedure -X- _ O
can -X- _ O
be -X- _ O
further -X- _ O
illustrated -X- _ O
by -X- _ O
• -X- _ O
10% -X- _ O
of -X- _ O
the -X- _ O
time: -X- _ O
Replace -X- _ O
the -X- _ O
word -X- _ O
with -X- _ O
a -X- _ O
random -X- _ O
word, -X- _ O
e.g., -X- _ O
my -X- _ O
dog -X- _ O
is -X- _ O
hairy -X- _ O
! -X- _ O
my -X- _ O
dog -X- _ O
is -X- _ O
apple -X- _ O
• -X- _ O
10% -X- _ O
of -X- _ O
the -X- _ O
time: -X- _ O
Keep -X- _ O
the -X- _ O
word -X- _ O
unchanged, -X- _ O
e.g., -X- _ O
my -X- _ O
dog -X- _ O
is -X- _ O
hairy -X- _ O
! -X- _ O
my -X- _ O
dog -X- _ O
is -X- _ O
hairy. -X- _ O
The -X- _ O
purpose -X- _ O
of -X- _ O
this -X- _ O
is -X- _ O
to -X- _ O
bias -X- _ O
the -X- _ O
representation -X- _ O
towards -X- _ O
the -X- _ O
actual -X- _ O
observed -X- _ O
word. -X- _ O
The -X- _ O
advantage -X- _ O
of -X- _ O
this -X- _ O
procedure -X- _ O
is -X- _ O
that -X- _ O
the -X- _ O
Transformer -X- _ O
encoder -X- _ O
does -X- _ O
not -X- _ O
know -X- _ O
which -X- _ O
words -X- _ O
it -X- _ O
will -X- _ O
be -X- _ O
asked -X- _ O
to -X- _ O
predict -X- _ O
or -X- _ O
which -X- _ O
have -X- _ O
been -X- _ O
replaced -X- _ O
by -X- _ O
random -X- _ O
words, -X- _ O
so -X- _ O
it -X- _ O
is -X- _ O
forced -X- _ O
to -X- _ O
keep -X- _ O
a -X- _ O
distributional -X- _ O
contextual -X- _ O
representation -X- _ O
of -X- _ O
every -X- _ O
input -X- _ O
token. -X- _ O
Additionally, -X- _ O
because -X- _ O
random -X- _ O
replacement -X- _ O
only -X- _ O
occurs -X- _ O
for -X- _ O
1.5% -X- _ O
of -X- _ O
all -X- _ O
tokens -X- _ O
(i.e., -X- _ O
10% -X- _ O
of -X- _ O
15%), -X- _ O
this -X- _ O
does -X- _ O
not -X- _ O
seem -X- _ O
to -X- _ O
harm -X- _ O
the -X- _ O
model's -X- _ O
language -X- _ O
understanding -X- _ O
capability. -X- _ O
In -X- _ O
Section -X- _ O
C.2, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
impact -X- _ O
this -X- _ O
procedure. -X- _ O
Compared -X- _ O
to -X- _ O
standard -X- _ O
langauge -X- _ O
model -X- _ O
training, -X- _ O
the -X- _ O
masked -X- _ B-TaskName
LM -X- _ I-TaskName
only -X- _ O
make -X- _ O
predictions -X- _ O
on -X- _ O
15% -X- _ O
of -X- _ O
tokens -X- _ O
in -X- _ O
each -X- _ O
batch, -X- _ O
which -X- _ O
suggests -X- _ O
that -X- _ O
more -X- _ O
pre-training -X- _ O
steps -X- _ O
may -X- _ O
be -X- _ O
required -X- _ O
for -X- _ O
the -X- _ O
model -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
explore -X- _ O
the -X- _ O
effect -X- _ O
of -X- _ O
model -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
on -X- _ O
fine-tuning -X- _ O
task -X- _ O
accuracy. -X- _ O
We -X- _ O
trained -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
models -X- _ O
with -X- _ O
a -X- _ O
differing -X- _ O
number -X- _ O
of -X- _ O
layers, -X- _ O
hidden -X- _ O
units, -X- _ O
and -X- _ O
attention -X- _ O
heads, -X- _ O
while -X- _ O
otherwise -X- _ O
using -X- _ O
the -X- _ O
same -X- _ O
hyperparameters -X- _ O
and -X- _ O
training -X- _ O
procedure -X- _ O
as -X- _ O
described -X- _ O
previously. -X- _ O
Results -X- _ O
on -X- _ O
selected -X- _ O
GLUE -X- _ B-DatasetName
tasks -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6. -X- _ O
In -X- _ O
this -X- _ O
table, -X- _ O
we -X- _ O
report -X- _ O
the -X- _ O
average -X- _ O
Dev -X- _ O
Set -X- _ O
accuracy -X- _ O
from -X- _ O
5 -X- _ O
random -X- _ O
restarts -X- _ O
of -X- _ O
fine-tuning. -X- _ O
We -X- _ O
can -X- _ O
see -X- _ O
that -X- _ O
larger -X- _ O
models -X- _ O
lead -X- _ O
to -X- _ O
a -X- _ O
strict -X- _ O
accuracy -X- _ O
improvement -X- _ O
across -X- _ O
all -X- _ O
four -X- _ O
datasets, -X- _ O
even -X- _ O
for -X- _ O
MRPC -X- _ B-DatasetName
which -X- _ O
only -X- _ O
has -X- _ O
3,600 -X- _ O
labeled -X- _ O
training -X- _ O
examples, -X- _ O
and -X- _ O
is -X- _ O
substantially -X- _ O
different -X- _ O
from -X- _ O
the -X- _ O
pre-training -X- _ O
tasks. -X- _ O
It -X- _ O
is -X- _ O
also -X- _ O
perhaps -X- _ O
surprising -X- _ O
that -X- _ O
we -X- _ O
are -X- _ O
able -X- _ O
to -X- _ O
achieve -X- _ O
such -X- _ O
significant -X- _ O
improvements -X- _ O
on -X- _ O
top -X- _ O
of -X- _ O
models -X- _ O
which -X- _ O
are -X- _ O
already -X- _ O
quite -X- _ O
large -X- _ O
relative -X- _ O
to -X- _ O
the -X- _ O
existing -X- _ O
literature. -X- _ O
For -X- _ O
example, -X- _ O
the -X- _ O
largest -X- _ O
Transformer -X- _ O
explored -X- _ O
in -X- _ O
Vaswani -X- _ O
et -X- _ O
al. -X- _ O
(2017) -X- _ O
is -X- _ O
(L=6, -X- _ B-HyperparameterName
H=1024, -X- _ B-HyperparameterName
A=16) -X- _ B-HyperparameterName
with -X- _ O
100M -X- _ O
parameters -X- _ O
for -X- _ O
the -X- _ O
encoder, -X- _ O
and -X- _ O
the -X- _ O
largest -X- _ O
Transformer -X- _ O
we -X- _ O
have -X- _ O
found -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
is -X- _ O
(L=64, -X- _ B-HyperparameterName
H=512, -X- _ B-HyperparameterName
A=2) -X- _ B-HyperparameterName
with -X- _ O
235M -X- _ O
parameters -X- _ O
(Al-Rfou -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O
By -X- _ O
contrast, -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
contains -X- _ O
110M -X- _ O
parameters -X- _ O
and -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
contains -X- _ O
340M -X- _ O
parameters. -X- _ O
It -X- _ O
has -X- _ O
long -X- _ O
been -X- _ O
known -X- _ O
that -X- _ O
increasing -X- _ O
the -X- _ O
model -X- _ O
size -X- _ O
will -X- _ O
lead -X- _ O
to -X- _ O
continual -X- _ O
improvements -X- _ O
on -X- _ O
large-scale -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
machine -X- _ B-TaskName
translation -X- _ I-TaskName
and -X- _ O
language -X- _ B-TaskName
modeling, -X- _ I-TaskName
which -X- _ O
is -X- _ O
demonstrated -X- _ O
by -X- _ O
the -X- _ O
LM -X- _ O
perplexity -X- _ O
of -X- _ O
held-out -X- _ O
training -X- _ O
data -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
6. -X- _ O
However, -X- _ O
we -X- _ O
believe -X- _ O
that -X- _ O
this -X- _ O
is -X- _ O
the -X- _ O
first -X- _ O
work -X- _ O
to -X- _ O
demonstrate -X- _ O
convincingly -X- _ O
that -X- _ O
scaling -X- _ O
to -X- _ O
extreme -X- _ O
model -X- _ O
sizes -X- _ O
also -X- _ O
leads -X- _ O
to -X- _ O
large -X- _ O
improvements -X- _ O
on -X- _ O
very -X- _ O
small -X- _ O
scale -X- _ O
tasks, -X- _ O
provided -X- _ O
that -X- _ O
the -X- _ O
model -X- _ O
has -X- _ O
been -X- _ O
sufficiently -X- _ O
pre-trained. -X- _ O
Peters -X- _ O
et -X- _ O
al. -X- _ O
(2018b) -X- _ O
presented -X- _ O
mixed -X- _ O
results -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
task -X- _ O
impact -X- _ O
of -X- _ O
increasing -X- _ O
the -X- _ O
pre-trained -X- _ O
bi-LM -X- _ O
size -X- _ O
from -X- _ O
two -X- _ O
to -X- _ O
four -X- _ O
layers -X- _ O
and -X- _ O
Melamud -X- _ O
et -X- _ O
al. -X- _ O
(2016) -X- _ O
mentioned -X- _ O
in -X- _ O
passing -X- _ O
that -X- _ O
increasing -X- _ O
hidden -X- _ B-HyperparameterName
dimension -X- _ I-HyperparameterName
size -X- _ I-HyperparameterName
from -X- _ O
200 -X- _ B-HyperparameterValue
to -X- _ O
600 -X- _ B-HyperparameterValue
helped, -X- _ O
but -X- _ O
increasing -X- _ O
further -X- _ O
to -X- _ O
1,000 -X- _ B-HyperparameterValue
did -X- _ O
not -X- _ O
bring -X- _ O
further -X- _ O
improvements. -X- _ O
Both -X- _ O
of -X- _ O
these -X- _ O
prior -X- _ O
works -X- _ O
used -X- _ O
a -X- _ O
featurebased -X- _ O
approach -X- _ O
-we -X- _ O
hypothesize -X- _ O
that -X- _ O
when -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
fine-tuned -X- _ O
directly -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
tasks -X- _ O
and -X- _ O
uses -X- _ O
only -X- _ O
a -X- _ O
very -X- _ O
small -X- _ O
number -X- _ O
of -X- _ O
randomly -X- _ O
initialized -X- _ O
additional -X- _ O
parameters, -X- _ O
the -X- _ O
taskspecific -X- _ O
models -X- _ O
can -X- _ O
benefit -X- _ O
from -X- _ O
the -X- _ O
larger, -X- _ O
more -X- _ O
expressive -X- _ O
pre-trained -X- _ O
representations -X- _ O
even -X- _ O
when -X- _ O
downstream -X- _ O
task -X- _ O
data -X- _ O
is -X- _ O
very -X- _ O
small. -X- _ O

A -X- _ O
left-context-only -X- _ O
model -X- _ O
which -X- _ O
is -X- _ O
trained -X- _ O
using -X- _ O
a -X- _ O
standard -X- _ O
Left-to-Right -X- _ O
(LTR) -X- _ B-MethodName
LM, -X- _ O
rather -X- _ O
than -X- _ O
an -X- _ O
MLM. -X- _ O
The -X- _ O
left-only -X- _ O
constraint -X- _ O
was -X- _ O
also -X- _ O
applied -X- _ O
at -X- _ O
fine-tuning, -X- _ O
because -X- _ O
removing -X- _ O
it -X- _ O
introduced -X- _ O
a -X- _ O
pre-train/fine-tune -X- _ O
mismatch -X- _ O
that -X- _ O
degraded -X- _ O
downstream -X- _ O
performance. -X- _ O
Additionally, -X- _ O
this -X- _ O
model -X- _ O
was -X- _ O
pre-trained -X- _ O
without -X- _ O
the -X- _ O
NSP -X- _ B-TaskName
task. -X- _ O
This -X- _ O
is -X- _ O
directly -X- _ O
comparable -X- _ O
to -X- _ O
OpenAI -X- _ O
GPT, -X- _ B-MethodName
but -X- _ O
using -X- _ O
our -X- _ O
larger -X- _ O
training -X- _ O
dataset, -X- _ O
our -X- _ O
input -X- _ O
representation, -X- _ O
and -X- _ O
our -X- _ O
fine-tuning -X- _ O
scheme. -X- _ O
We -X- _ O
first -X- _ O
examine -X- _ O
the -X- _ O
impact -X- _ O
brought -X- _ O
by -X- _ O
the -X- _ O
NSP -X- _ B-TaskName
task. -X- _ O
In -X- _ O
Table -X- _ O
5, -X- _ O
we -X- _ O
show -X- _ O
that -X- _ O
removing -X- _ O
NSP -X- _ B-TaskName
hurts -X- _ O
performance -X- _ O
significantly -X- _ O
on -X- _ O
QNLI, -X- _ O
MNLI, -X- _ O
and -X- _ O
SQuAD -X- _ O
1.1. -X- _ O
Next, -X- _ O
we -X- _ O
evaluate -X- _ O
the -X- _ O
impact -X- _ O
of -X- _ O
training -X- _ O
bidirectional -X- _ O
representations -X- _ O
by -X- _ O
comparing -X- _ O
"No -X- _ B-TaskName
NSP" -X- _ I-TaskName
to -X- _ O
"LTR -X- _ O
& -X- _ O
No -X- _ O
NSP". -X- _ O
The -X- _ O
LTR -X- _ B-MethodName
model -X- _ O
performs -X- _ O
worse -X- _ O
than -X- _ O
the -X- _ O
MLM -X- _ O
model -X- _ O
on -X- _ O
all -X- _ O
tasks, -X- _ O
with -X- _ O
large -X- _ O
drops -X- _ O
on -X- _ O
MRPC -X- _ B-MetricName
and -X- _ O
SQuAD. -X- _ B-DatasetName
For -X- _ O
SQuAD -X- _ B-DatasetName
it -X- _ O
is -X- _ O
intuitively -X- _ O
clear -X- _ O
that -X- _ O
a -X- _ O
LTR -X- _ B-MethodName
model -X- _ O
will -X- _ O
perform -X- _ O
poorly -X- _ O
at -X- _ O
token -X- _ O
predictions, -X- _ O
since -X- _ O
the -X- _ O
token-level -X- _ O
hidden -X- _ O
states -X- _ O
have -X- _ O
no -X- _ O
rightside -X- _ O
context. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
make -X- _ O
a -X- _ O
good -X- _ O
faith -X- _ O
attempt -X- _ O
at -X- _ O
strengthening -X- _ O
the -X- _ O
LTR -X- _ B-MethodName
system, -X- _ O
we -X- _ O
added -X- _ O
a -X- _ O
randomly -X- _ O
initialized -X- _ O
BiLSTM -X- _ O
on -X- _ O
top. -X- _ O
This -X- _ O
does -X- _ O
significantly -X- _ O
improve -X- _ O
results -X- _ O
on -X- _ O
SQuAD, -X- _ B-DatasetName
but -X- _ O
the -X- _ O
results -X- _ O
are -X- _ O
still -X- _ O
far -X- _ O
worse -X- _ O
than -X- _ O
those -X- _ O
of -X- _ O
the -X- _ O
pretrained -X- _ O
bidirectional -X- _ O
models. -X- _ O
The -X- _ O
BiLSTM -X- _ O
hurts -X- _ O
performance -X- _ O
on -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
tasks. -X- _ O
We -X- _ O
recognize -X- _ O
that -X- _ O
it -X- _ O
would -X- _ O
also -X- _ O
be -X- _ O
possible -X- _ O
to -X- _ O
train -X- _ O
separate -X- _ O
LTR -X- _ B-MethodName
and -X- _ O
RTL -X- _ O
models -X- _ O
and -X- _ O
represent -X- _ O
each -X- _ O
token -X- _ O
as -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
two -X- _ O
models, -X- _ O
as -X- _ O
ELMo -X- _ O
does. -X- _ O
However: -X- _ O
(a) -X- _ O
this -X- _ O
is -X- _ O
twice -X- _ O
as -X- _ O
expensive -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
bidirectional -X- _ O
model; -X- _ O
(b) -X- _ O
this -X- _ O
is -X- _ O
non-intuitive -X- _ O
for -X- _ O
tasks -X- _ O
like -X- _ O
QA, -X- _ B-TaskName
since -X- _ O
the -X- _ O
RTL -X- _ O
model -X- _ O
would -X- _ O
not -X- _ O
be -X- _ O
able -X- _ O
to -X- _ O
condition -X- _ O
the -X- _ O
answer -X- _ O
on -X- _ O
the -X- _ O
question; -X- _ O
(c) -X- _ O
this -X- _ O
it -X- _ O
is -X- _ O
strictly -X- _ O
less -X- _ O
powerful -X- _ O
than -X- _ O
a -X- _ O
deep -X- _ O
bidirectional -X- _ O
model, -X- _ O
since -X- _ O
it -X- _ O
can -X- _ O
use -X- _ O
both -X- _ O
left -X- _ O
and -X- _ O
right -X- _ O
context -X- _ O
at -X- _ O
every -X- _ O
layer. -X- _ O

We -X- _ O
demonstrate -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
the -X- _ O
deep -X- _ O
bidirectionality -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
by -X- _ O
evaluating -X- _ O
two -X- _ O
pretraining -X- _ O
objectives -X- _ O
using -X- _ O
exactly -X- _ O
the -X- _ O
same -X- _ O
pretraining -X- _ O
data, -X- _ O
fine-tuning -X- _ O
scheme, -X- _ O
and -X- _ O
hyperparameters -X- _ O
as -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
: -X- _ O
No -X- _ B-TaskName
NSP: -X- _ I-TaskName
A -X- _ O
bidirectional -X- _ O
model -X- _ O
which -X- _ O
is -X- _ O
trained -X- _ O
using -X- _ O
the -X- _ O
"masked -X- _ B-TaskName
LM" -X- _ I-TaskName
(MLM) -X- _ B-TaskName
but -X- _ O
without -X- _ O
the -X- _ O
"next -X- _ B-TaskName
sentence -X- _ I-TaskName
prediction" -X- _ I-TaskName
(NSP) -X- _ B-TaskName
task. -X- _ O

The -X- _ O
Stanford -X- _ B-DatasetName
Question -X- _ I-DatasetName
Answering -X- _ I-DatasetName
Dataset -X- _ I-DatasetName
(SQuAD -X- _ B-DatasetName
v1.1) -X- _ I-DatasetName
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
100k -X- _ O
crowdsourced -X- _ O
question/answer -X- _ O
pairs -X- _ O
(Rajpurkar -X- _ O
et -X- _ O
al., -X- _ O
2016). -X- _ O
Given -X- _ O
a -X- _ O
question -X- _ O
and -X- _ O
a -X- _ O
passage -X- _ O
from -X- _ O
Wikipedia -X- _ O
containing -X- _ O
the -X- _ O
answer, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ B-TaskName
the -X- _ I-TaskName
answer -X- _ I-TaskName
text -X- _ I-TaskName
span -X- _ I-TaskName
in -X- _ I-TaskName
the -X- _ I-TaskName
passage. -X- _ I-TaskName
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1, -X- _ O
in -X- _ O
the -X- _ O
question -X- _ B-TaskName
answering -X- _ I-TaskName
task, -X- _ O
we -X- _ O
represent -X- _ O
the -X- _ O
input -X- _ O
question -X- _ O
and -X- _ O
passage -X- _ O
as -X- _ O
a -X- _ O
single -X- _ O
packed -X- _ O
sequence, -X- _ O
with -X- _ O
the -X- _ O
question -X- _ O
using -X- _ O
the -X- _ O
A -X- _ O
embedding -X- _ O
and -X- _ O
the -X- _ O
passage -X- _ O
using -X- _ O
the -X- _ O
B -X- _ O
embedding. -X- _ O
We -X- _ O
only -X- _ O
introduce -X- _ O
a -X- _ O
start -X- _ O
vector -X- _ O
S -X- _ O
2 -X- _ O
R -X- _ O
H -X- _ O
and -X- _ O
an -X- _ O
end -X- _ O
vector -X- _ O
E -X- _ O
2 -X- _ O
R -X- _ O
H -X- _ O
during -X- _ O
fine-tuning. -X- _ O
The -X- _ O
probability -X- _ O
of -X- _ O
word -X- _ O
i -X- _ O
being -X- _ O
the -X- _ O
start -X- _ O
of -X- _ O
the -X- _ O
answer -X- _ O
span -X- _ O
is -X- _ O
computed -X- _ O
as -X- _ O
a -X- _ O
dot -X- _ O
product -X- _ O
between -X- _ O
T -X- _ O
i -X- _ O
and -X- _ O
S -X- _ O
followed -X- _ O
by -X- _ O
a -X- _ O
softmax -X- _ O
over -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
words -X- _ O
in -X- _ O
the -X- _ O
paragraph: -X- _ O
P -X- _ O
i -X- _ O
= -X- _ O
e -X- _ O
S•T -X- _ O
i -X- _ O
P -X- _ O
j -X- _ O
e -X- _ O
S•T -X- _ O
j -X- _ O
. -X- _ O
The -X- _ O
analogous -X- _ O
formula -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
the -X- _ O
end -X- _ O
of -X- _ O
the -X- _ O
answer -X- _ O
span. -X- _ O
The -X- _ O
score -X- _ O
of -X- _ O
a -X- _ O
candidate -X- _ O
span -X- _ O
from -X- _ O
position -X- _ O
i -X- _ O
to -X- _ O
position -X- _ O
j -X- _ O
is -X- _ O
defined -X- _ O
as -X- _ O
S•T -X- _ O
i -X- _ O
+ -X- _ O
E•T -X- _ O
j -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
maximum -X- _ O
scoring -X- _ O
span -X- _ O
where -X- _ O
j -X- _ O
i -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
a -X- _ O
prediction. -X- _ O
The -X- _ O
training -X- _ O
objective -X- _ O
is -X- _ O
the -X- _ O
sum -X- _ O
of -X- _ O
the -X- _ O
log-likelihoods -X- _ O
of -X- _ O
the -X- _ O
correct -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
positions. -X- _ O
We -X- _ O
fine-tune -X- _ O
for -X- _ O
3 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
5e-5 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
32. -X- _ B-HyperparameterValue
Table -X- _ O
2 -X- _ O
shows -X- _ O
top -X- _ O
leaderboard -X- _ O
entries -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
results -X- _ O
from -X- _ O
top -X- _ O
published -X- _ O
systems -X- _ O
(Seo -X- _ O
et -X- _ O
al., -X- _ O
2017;Clark -X- _ O
and -X- _ O
Gardner, -X- _ O
2018;Peters -X- _ O
et -X- _ O
al., -X- _ O
2018a;Hu -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O
The -X- _ O
top -X- _ O
results -X- _ O
from -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
leaderboard -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
up-to-date -X- _ O
public -X- _ O
system -X- _ O
descriptions -X- _ O
available, -X- _ O
11 -X- _ O
and -X- _ O
are -X- _ O
allowed -X- _ O
to -X- _ O
use -X- _ O
any -X- _ O
public -X- _ O
data -X- _ O
when -X- _ O
training -X- _ O
their -X- _ O
systems. -X- _ O
We -X- _ O
therefore -X- _ O
use -X- _ O
modest -X- _ O
data -X- _ O
augmentation -X- _ O
in -X- _ O
our -X- _ O
system -X- _ O
by -X- _ O
first -X- _ O
fine-tuning -X- _ O
on -X- _ O
TriviaQA -X- _ B-DatasetName
(Joshi -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
befor -X- _ O
fine-tuning -X- _ O
on -X- _ O
SQuAD. -X- _ B-DatasetName
Our -X- _ O
best -X- _ O
performing -X- _ O
system -X- _ O
outperforms -X- _ O
the -X- _ O
top -X- _ O
leaderboard -X- _ O
system -X- _ O
by -X- _ O
+1.5 -X- _ O
F1 -X- _ B-MetricName
in -X- _ O
ensembling -X- _ O
and -X- _ O
+1.3 -X- _ O
F1 -X- _ B-MetricName
as -X- _ O
a -X- _ O
single -X- _ O
system. -X- _ O
In -X- _ O
fact, -X- _ O
our -X- _ O
single -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
outperforms -X- _ O
the -X- _ O
top -X- _ O
ensemble -X- _ O
system -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
F1 -X- _ B-MetricName
score. -X- _ O
Without -X- _ O
TriviaQA -X- _ O
fine- -X- _ O
tuning -X- _ O
data, -X- _ O
we -X- _ O
only -X- _ O
lose -X- _ O
0.1-0.4 -X- _ O
F1, -X- _ B-MetricName
still -X- _ O
outperforming -X- _ O
all -X- _ O
existing -X- _ O
systems -X- _ O
by -X- _ O
a -X- _ O
wide -X- _ O
margin. -X- _ O
12 -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
perform -X- _ O
ablation -X- _ O
experiments -X- _ O
over -X- _ O
a -X- _ O
number -X- _ O
of -X- _ O
facets -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
in -X- _ O
order -X- _ O
to -X- _ O
better -X- _ O
understand -X- _ O
their -X- _ O
relative -X- _ O
importance. -X- _ O
Additional -X- _ O
ablation -X- _ O
studies -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
C. -X- _ O

The -X- _ O
Situations -X- _ B-DatasetName
With -X- _ I-DatasetName
Adversarial -X- _ I-DatasetName
Generations -X- _ I-DatasetName
(SWAG) -X- _ B-DatasetName
dataset -X- _ O
contains -X- _ O
113k -X- _ O
sentence-pair -X- _ O
completion -X- _ O
examples -X- _ O
that -X- _ O
evaluate -X- _ O
grounded -X- _ O
commonsense -X- _ O
inference -X- _ O
(Zellers -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O
Given -X- _ O
a -X- _ O
sentence, -X- _ O
the -X- _ O
task -X- _ O
is -X- _ O
to -X- _ O
choose -X- _ B-TaskName
the -X- _ I-TaskName
most -X- _ I-TaskName
plausible -X- _ I-TaskName
continuation -X- _ I-TaskName
among -X- _ I-TaskName
four -X- _ I-TaskName
choices. -X- _ I-TaskName
When -X- _ O
fine-tuning -X- _ O
on -X- _ O
the -X- _ O
SWAG -X- _ B-DatasetName
dataset, -X- _ O
we -X- _ O
construct -X- _ O
four -X- _ O
input -X- _ O
sequences, -X- _ O
each -X- _ O
containing -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
given -X- _ O
sentence -X- _ O
(sentence -X- _ O
A) -X- _ O
and -X- _ O
a -X- _ O
possible -X- _ O
continuation -X- _ O
(sentence -X- _ O
B). -X- _ O
The -X- _ O
only -X- _ O
task-specific -X- _ O
parameters -X- _ O
introduced -X- _ O
is -X- _ O
a -X- _ O
vector -X- _ O
whose -X- _ O
dot -X- _ O
product -X- _ O
with -X- _ O
the -X- _ O
[CLS] -X- _ O
token -X- _ O
representation -X- _ O
C -X- _ O
denotes -X- _ O
a -X- _ O
score -X- _ O
for -X- _ O
each -X- _ O
choice -X- _ O
which -X- _ O
is -X- _ O
normalized -X- _ O
with -X- _ O
a -X- _ O
softmax -X- _ O
layer. -X- _ O
We -X- _ O
fine-tune -X- _ O
the -X- _ O
model -X- _ O
for -X- _ O
3 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
2e-5 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
16. -X- _ B-HyperparameterValue
Results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
4. -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
outperforms -X- _ O
the -X- _ O
authors' -X- _ O
baseline -X- _ O
ESIM+ELMo -X- _ B-MethodName
system -X- _ O
by -X- _ O
+27.1% -X- _ O
and -X- _ O
OpenAI -X- _ O
GPT -X- _ B-MethodName
by -X- _ O
8.3%. -X- _ O

The -X- _ O
SQuAD -X- _ B-DatasetName
2.0 -X- _ I-DatasetName
task -X- _ O
extends -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
1.1 -X- _ I-DatasetName
problem -X- _ O
definition -X- _ O
by -X- _ O
allowing -X- _ O
for -X- _ O
the -X- _ O
possibility -X- _ O
that -X- _ O
no -X- _ O
short -X- _ O
answer -X- _ O
exists -X- _ O
in -X- _ O
the -X- _ O
provided -X- _ O
paragraph, -X- _ O
making -X- _ O
the -X- _ O
problem -X- _ O
more -X- _ O
realistic. -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
simple -X- _ O
approach -X- _ O
to -X- _ O
extend -X- _ O
the -X- _ O
SQuAD -X- _ B-DatasetName
v1.1 -X- _ I-DatasetName
BERT -X- _ B-MethodName
model -X- _ O
for -X- _ O
this -X- _ O
task. -X- _ O
We -X- _ O
treat -X- _ O
questions -X- _ O
that -X- _ O
do -X- _ O
not -X- _ O
have -X- _ O
an -X- _ O
answer -X- _ O
as -X- _ O
having -X- _ O
an -X- _ O
answer -X- _ O
span -X- _ O
with -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
at -X- _ O
the -X- _ O
[CLS] -X- _ O
token. -X- _ O
The -X- _ O
probability -X- _ O
space -X- _ O
for -X- _ O
the -X- _ O
start -X- _ O
and -X- _ O
end -X- _ O
answer -X- _ O
span -X- _ O
positions -X- _ O
is -X- _ O
extended -X- _ O
to -X- _ O
include -X- _ O
the -X- _ O
position -X- _ O
of -X- _ O
the -X- _ O
[CLS] -X- _ O
token. -X- _ O
For -X- _ O
prediction, -X- _ O
we -X- _ O
compare -X- _ O
the -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
no-answer -X- _ O
span: -X- _ O
s -X- _ O
null -X- _ O
= -X- _ O
S•C -X- _ O
+ -X- _ O
E•C -X- _ O
to -X- _ O
the -X- _ O
score -X- _ O
of -X- _ O
the -X- _ O
best -X- _ O
non-null -X- _ O
span -X- _ O
12 -X- _ O
The -X- _ O
TriviaQA -X- _ B-DatasetName
data -X- _ O
we -X- _ O
used -X- _ O
consists -X- _ O
of -X- _ O
paragraphs -X- _ O
from -X- _ O
TriviaQA-Wiki -X- _ O
formed -X- _ O
of -X- _ O
the -X- _ O
first -X- _ O
400 -X- _ O
tokens -X- _ O
in -X- _ O
documents, -X- _ O
that -X- _ O
contain -X- _ O
at -X- _ O
least -X- _ O
one -X- _ O
of -X- _ O
the -X- _ O
provided -X- _ O
possible -X- _ O
answers. -X- _ O
s -X- _ O
i,j -X- _ O
= -X- _ O
max -X- _ O
j -X- _ O
i -X- _ O
S•T -X- _ O
i -X- _ O
+ -X- _ O
E•T -X- _ O
j -X- _ O
. -X- _ O
We -X- _ O
predict -X- _ O
a -X- _ O
non-null -X- _ O
answer -X- _ O
whenŝ -X- _ O
i,j -X- _ O
> -X- _ O
s -X- _ O
null -X- _ O
+ -X- _ O
⌧ -X- _ O
, -X- _ O
where -X- _ O
the -X- _ O
threshold -X- _ O
⌧ -X- _ O
is -X- _ O
selected -X- _ O
on -X- _ O
the -X- _ O
dev -X- _ O
set -X- _ O
to -X- _ O
maximize -X- _ O
F1. -X- _ B-MetricName
We -X- _ O
did -X- _ O
not -X- _ O
use -X- _ O
TriviaQA -X- _ O
data -X- _ O
for -X- _ O
this -X- _ O
model. -X- _ O
We -X- _ O
fine-tuned -X- _ O
for -X- _ O
2 -X- _ O
epochs -X- _ O
with -X- _ O
a -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
of -X- _ O
5e-5 -X- _ B-HyperparameterValue
and -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
48. -X- _ B-HyperparameterValue
The -X- _ O
results -X- _ O
compared -X- _ O
to -X- _ O
prior -X- _ O
leaderboard -X- _ O
entries -X- _ O
and -X- _ O
top -X- _ O
published -X- _ O
work -X- _ O
(Sun -X- _ O
et -X- _ O
al., -X- _ O
2018;Wang -X- _ O
et -X- _ O
al., -X- _ O
2018b) -X- _ O
are -X- _ O
shown -X- _ O
in -X- _ O
Table -X- _ O
3, -X- _ O
excluding -X- _ O
systems -X- _ O
that -X- _ O
use -X- _ O
BERT -X- _ B-MethodName
as -X- _ O
one -X- _ O
of -X- _ O
their -X- _ O
components. -X- _ O
We -X- _ O
observe -X- _ O
a -X- _ O
+5.1 -X- _ O
F1 -X- _ O
improvement -X- _ O
over -X- _ O
the -X- _ O
previous -X- _ O
best -X- _ O
system. -X- _ O

The -X- _ O
General -X- _ B-DatasetName
Language -X- _ I-DatasetName
Understanding -X- _ I-DatasetName
Evaluation -X- _ I-DatasetName
(GLUE) -X- _ B-DatasetName
benchmark -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2018a) -X- _ O
is -X- _ O
a -X- _ O
collection -X- _ O
of -X- _ O
diverse -X- _ O
natural -X- _ O
language -X- _ O
understanding -X- _ O
tasks. -X- _ O
Detailed -X- _ O
descriptions -X- _ O
of -X- _ O
GLUE -X- _ B-DatasetName
datasets -X- _ O
are -X- _ O
included -X- _ O
in -X- _ O
Appendix -X- _ O
B.1. -X- _ O
To -X- _ O
fine-tune -X- _ O
on -X- _ O
GLUE, -X- _ B-DatasetName
we -X- _ O
represent -X- _ O
the -X- _ O
input -X- _ O
sequence -X- _ O
(for -X- _ O
single -X- _ O
sentence -X- _ O
or -X- _ O
sentence -X- _ O
pairs) -X- _ O
as -X- _ O
described -X- _ O
in -X- _ O
Section -X- _ O
3, -X- _ O
and -X- _ O
use -X- _ O
the -X- _ O
final -X- _ O
hidden -X- _ O
vector -X- _ O
C -X- _ O
2 -X- _ O
R -X- _ O
H -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
first -X- _ O
input -X- _ O
token -X- _ O
([CLS]) -X- _ O
as -X- _ O
the -X- _ O
aggregate -X- _ O
representation. -X- _ O
The -X- _ O
only -X- _ O
new -X- _ O
parameters -X- _ O
introduced -X- _ O
during -X- _ O
fine-tuning -X- _ O
are -X- _ O
classification -X- _ O
layer -X- _ O
weights -X- _ O
W -X- _ O
2 -X- _ O
R -X- _ O
K⇥H -X- _ O
, -X- _ O
where -X- _ O
K -X- _ O
is -X- _ O
the -X- _ O
number -X- _ O
of -X- _ O
labels. -X- _ O
We -X- _ O
compute -X- _ O
a -X- _ O
standard -X- _ O
classification -X- _ O
loss -X- _ O
with -X- _ O
C -X- _ O
and -X- _ O
W -X- _ O
, -X- _ O
i.e., -X- _ O
log(softmax(CW -X- _ O
T -X- _ O
)). -X- _ O
We -X- _ O
use -X- _ O
a -X- _ O
batch -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
of -X- _ O
32 -X- _ B-HyperparameterValue
and -X- _ O
fine-tune -X- _ O
for -X- _ O
3 -X- _ B-HyperparameterValue
epochs -X- _ B-HyperparameterName
over -X- _ O
the -X- _ O
data -X- _ O
for -X- _ O
all -X- _ O
GLUE -X- _ B-DatasetName
tasks. -X- _ O
For -X- _ O
each -X- _ O
task, -X- _ O
we -X- _ O
selected -X- _ O
the -X- _ O
best -X- _ O
fine-tuning -X- _ O
learning -X- _ B-HyperparameterName
rate -X- _ I-HyperparameterName
(among -X- _ O
5e-5, -X- _ B-HyperparameterValue
4e-5, -X- _ B-HyperparameterValue
3e-5, -X- _ B-HyperparameterValue
and -X- _ O
2e-5) -X- _ B-HyperparameterValue
on -X- _ O
the -X- _ O
Dev -X- _ O
set. -X- _ O
Additionally, -X- _ O
for -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
we -X- _ O
found -X- _ O
that -X- _ O
finetuning -X- _ O
was -X- _ O
sometimes -X- _ O
unstable -X- _ O
on -X- _ O
small -X- _ O
datasets, -X- _ O
so -X- _ O
we -X- _ O
ran -X- _ O
several -X- _ O
random -X- _ O
restarts -X- _ O
and -X- _ O
selected -X- _ O
the -X- _ O
best -X- _ O
model -X- _ O
on -X- _ O
the -X- _ O
Dev -X- _ O
set. -X- _ O
With -X- _ O
random -X- _ O
restarts, -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
same -X- _ O
pre-trained -X- _ O
checkpoint -X- _ O
but -X- _ O
perform -X- _ O
different -X- _ O
fine-tuning -X- _ O
data -X- _ O
shuffling -X- _ O
and -X- _ O
classifier -X- _ O
layer -X- _ O
initialization. -X- _ O
9 -X- _ O
Results -X- _ O
are -X- _ O
presented -X- _ O
in -X- _ O
Table -X- _ O
1. -X- _ O
Both -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
and -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
outperform -X- _ O
all -X- _ O
systems -X- _ O
on -X- _ O
all -X- _ O
tasks -X- _ O
by -X- _ O
a -X- _ O
substantial -X- _ O
margin, -X- _ O
obtaining -X- _ O
4.5% -X- _ O
and -X- _ O
7.0% -X- _ O
respective -X- _ O
average -X- _ B-MetricName
accuracy -X- _ I-MetricName
improvement -X- _ O
over -X- _ O
the -X- _ O
prior -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art. -X- _ O
Note -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
and -X- _ O
OpenAI -X- _ O
GPT -X- _ B-MethodName
are -X- _ O
nearly -X- _ O
identical -X- _ O
in -X- _ O
terms -X- _ O
of -X- _ O
model -X- _ O
architecture -X- _ O
apart -X- _ O
from -X- _ O
the -X- _ O
attention -X- _ O
masking. -X- _ O
For -X- _ O
the -X- _ O
largest -X- _ O
and -X- _ O
most -X- _ O
widely -X- _ O
reported -X- _ O
GLUE -X- _ B-DatasetName
task, -X- _ O
MNLI, -X- _ B-DatasetName
BERT -X- _ B-MethodName
obtains -X- _ O
a -X- _ O
4.6% -X- _ O
absolute -X- _ O
accuracy -X- _ O
improvement. -X- _ O
On -X- _ O
the -X- _ O
official -X- _ O
GLUE -X- _ B-TaskName
leaderboard -X- _ O
10 -X- _ O
, -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
obtains -X- _ O
a -X- _ O
score -X- _ B-MetricName
of -X- _ O
80.5, -X- _ B-MetricValue
compared -X- _ O
to -X- _ O
OpenAI -X- _ O
GPT, -X- _ B-MethodName
which -X- _ O
obtains -X- _ O
72.8 -X- _ B-MetricValue
as -X- _ O
of -X- _ O
the -X- _ O
date -X- _ O
of -X- _ O
writing. -X- _ O
We -X- _ O
find -X- _ O
that -X- _ O
BERT -X- _ B-MethodName
LARGE -X- _ I-MethodName
significantly -X- _ O
outperforms -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
across -X- _ O
all -X- _ O
tasks, -X- _ O
especially -X- _ O
those -X- _ O
with -X- _ O
very -X- _ O
little -X- _ O
training -X- _ O
data. -X- _ O
The -X- _ O
effect -X- _ O
of -X- _ O
model -X- _ O
size -X- _ O
is -X- _ O
explored -X- _ O
more -X- _ O
thoroughly -X- _ O
in -X- _ O
Section -X- _ O
5.2. -X- _ O

In -X- _ O
this -X- _ O
section, -X- _ O
we -X- _ O
present -X- _ O
BERT -X- _ O
fine-tuning -X- _ O
results -X- _ O
on -X- _ O
11 -X- _ O
NLP -X- _ O
tasks. -X- _ O

Fine-tuning -X- _ O
is -X- _ O
straightforward -X- _ O
since -X- _ O
the -X- _ O
selfattention -X- _ O
mechanism -X- _ O
in -X- _ O
the -X- _ O
Transformer -X- _ O
allows -X- _ O
BERT -X- _ B-MethodName
to -X- _ O
model -X- _ O
many -X- _ O
downstream -X- _ O
taskswhether -X- _ O
they -X- _ O
involve -X- _ O
single -X- _ O
text -X- _ O
or -X- _ O
text -X- _ O
pairs-by -X- _ O
swapping -X- _ O
out -X- _ O
the -X- _ O
appropriate -X- _ O
inputs -X- _ O
and -X- _ O
outputs. -X- _ O
For -X- _ O
applications -X- _ O
involving -X- _ O
text -X- _ O
pairs, -X- _ O
a -X- _ O
common -X- _ O
pattern -X- _ O
is -X- _ O
to -X- _ O
independently -X- _ O
encode -X- _ O
text -X- _ O
pairs -X- _ O
before -X- _ O
applying -X- _ O
bidirectional -X- _ O
cross -X- _ O
attention, -X- _ O
such -X- _ O
as -X- _ O
Parikh -X- _ O
et -X- _ O
al. -X- _ O
(2016); -X- _ O
Seo -X- _ O
et -X- _ O
al. -X- _ O
(2017). -X- _ O
BERT -X- _ B-MethodName
instead -X- _ O
uses -X- _ O
the -X- _ O
self-attention -X- _ O
mechanism -X- _ O
to -X- _ O
unify -X- _ O
these -X- _ O
two -X- _ O
stages, -X- _ O
as -X- _ O
encoding -X- _ O
a -X- _ O
concatenated -X- _ O
text -X- _ O
pair -X- _ O
with -X- _ O
self-attention -X- _ O
effectively -X- _ O
includes -X- _ O
bidirectional -X- _ O
cross -X- _ O
attention -X- _ O
between -X- _ O
two -X- _ O
sentences. -X- _ O
For -X- _ O
each -X- _ O
task, -X- _ O
we -X- _ O
simply -X- _ O
plug -X- _ O
in -X- _ O
the -X- _ O
taskspecific -X- _ O
inputs -X- _ O
and -X- _ O
outputs -X- _ O
into -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
finetune -X- _ O
all -X- _ O
the -X- _ O
parameters -X- _ O
end-to-end. -X- _ O
At -X- _ O
the -X- _ O
input, -X- _ O
sentence -X- _ O
A -X- _ O
and -X- _ O
sentence -X- _ O
B -X- _ O
from -X- _ O
pre-training -X- _ O
are -X- _ O
analogous -X- _ O
to -X- _ O
(1) -X- _ O
sentence -X- _ O
pairs -X- _ O
in -X- _ O
paraphrasing, -X- _ O
(2) -X- _ O
hypothesis-premise -X- _ O
pairs -X- _ O
in -X- _ O
entailment, -X- _ O
(3) -X- _ O
question-passage -X- _ O
pairs -X- _ O
in -X- _ O
question -X- _ B-TaskName
answering, -X- _ I-TaskName
and -X- _ O
(4) -X- _ O
a -X- _ O
degenerate -X- _ O
text-? -X- _ O
pair -X- _ O
in -X- _ O
text -X- _ O
classification -X- _ O
or -X- _ O
sequence -X- _ O
tagging. -X- _ O
At -X- _ O
the -X- _ O
output, -X- _ O
the -X- _ O
token -X- _ O
representations -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
an -X- _ O
output -X- _ O
layer -X- _ O
for -X- _ O
tokenlevel -X- _ O
tasks, -X- _ O
such -X- _ O
as -X- _ O
sequence -X- _ B-TaskName
tagging -X- _ I-TaskName
or -X- _ O
question -X- _ B-TaskName
answering, -X- _ I-TaskName
and -X- _ O
the -X- _ O
[CLS] -X- _ O
representation -X- _ O
is -X- _ O
fed -X- _ O
into -X- _ O
an -X- _ O
output -X- _ O
layer -X- _ O
for -X- _ O
classification, -X- _ O
such -X- _ O
as -X- _ O
entailment -X- _ O
or -X- _ O
sentiment -X- _ O
analysis. -X- _ O
Compared -X- _ O
to -X- _ O
pre-training, -X- _ O
fine-tuning -X- _ O
is -X- _ O
relatively -X- _ O
inexpensive. -X- _ O
All -X- _ O
of -X- _ O
the -X- _ O
results -X- _ O
in -X- _ O
the -X- _ O
paper -X- _ O
can -X- _ O
be -X- _ O
replicated -X- _ O
in -X- _ O
at -X- _ O
most -X- _ O
1 -X- _ O
hour -X- _ O
on -X- _ O
a -X- _ O
single -X- _ O
Cloud -X- _ O
TPU, -X- _ O
or -X- _ O
a -X- _ O
few -X- _ O
hours -X- _ O
on -X- _ O
a -X- _ O
GPU, -X- _ O
starting -X- _ O
from -X- _ O
the -X- _ O
exact -X- _ O
same -X- _ O
pre-trained -X- _ O
model. -X- _ O
7 -X- _ O
We -X- _ O
describe -X- _ O
the -X- _ O
task-specific -X- _ O
details -X- _ O
in -X- _ O
the -X- _ O
corresponding -X- _ O
subsections -X- _ O
of -X- _ O
Section -X- _ O
4. -X- _ O
More -X- _ O
details -X- _ O
can -X- _ O
be -X- _ O
found -X- _ O
in -X- _ O
Appendix -X- _ O
A.5. -X- _ O

The -X- _ O
pre-training -X- _ O
procedure -X- _ O
largely -X- _ O
follows -X- _ O
the -X- _ O
existing -X- _ O
literature -X- _ O
on -X- _ O
language -X- _ O
model -X- _ O
pre-training. -X- _ O
For -X- _ O
the -X- _ O
pre-training -X- _ O
corpus -X- _ O
we -X- _ O
use -X- _ O
the -X- _ O
BooksCorpus -X- _ B-DatasetName
(800M -X- _ O
words) -X- _ O
and -X- _ O
English -X- _ B-DatasetName
Wikipedia -X- _ I-DatasetName
(2,500M -X- _ O
words). -X- _ O
For -X- _ O
Wikipedia -X- _ B-DatasetName
we -X- _ O
extract -X- _ O
only -X- _ O
the -X- _ O
text -X- _ O
passages -X- _ O
and -X- _ O
ignore -X- _ O
lists, -X- _ O
tables, -X- _ O
and -X- _ O
headers. -X- _ O
It -X- _ O
is -X- _ O
critical -X- _ O
to -X- _ O
use -X- _ O
a -X- _ O
document-level -X- _ O
corpus -X- _ O
rather -X- _ O
than -X- _ O
a -X- _ O
shuffled -X- _ O
sentence-level -X- _ O
corpus -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
Billion -X- _ O
Word -X- _ O
Benchmark -X- _ O
(Chelba -X- _ O
et -X- _ O
al., -X- _ O
2013) -X- _ O
in -X- _ O
order -X- _ O
to -X- _ O
extract -X- _ O
long -X- _ O
contiguous -X- _ O
sequences. -X- _ O

Unlike -X- _ O
Peters -X- _ O
et -X- _ O
al. -X- _ O
(2018a) -X- _ O
and -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
(2018), -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
use -X- _ O
traditional -X- _ O
left-to-right -X- _ O
or -X- _ O
right-to-left -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
pre-train -X- _ O
BERT. -X- _ B-MethodName
Instead, -X- _ O
we -X- _ O
pre-train -X- _ O
BERT -X- _ B-MethodName
using -X- _ O
two -X- _ O
unsupervised -X- _ O
tasks, -X- _ O
described -X- _ O
in -X- _ O
this -X- _ O
section. -X- _ O
This -X- _ O
step -X- _ O
is -X- _ O
presented -X- _ O
in -X- _ O
the -X- _ O
left -X- _ O
part -X- _ O
of -X- _ O
Figure -X- _ O
1. -X- _ O
Task -X- _ O
#1: -X- _ O
Masked -X- _ B-TaskName
LM -X- _ I-TaskName
Intuitively, -X- _ O
it -X- _ O
is -X- _ O
reasonable -X- _ O
to -X- _ O
believe -X- _ O
that -X- _ O
a -X- _ O
deep -X- _ O
bidirectional -X- _ O
model -X- _ O
is -X- _ O
strictly -X- _ O
more -X- _ O
powerful -X- _ O
than -X- _ O
either -X- _ O
a -X- _ O
left-to-right -X- _ O
model -X- _ O
or -X- _ O
the -X- _ O
shallow -X- _ O
concatenation -X- _ O
of -X- _ O
a -X- _ O
left-toright -X- _ O
and -X- _ O
a -X- _ O
right-to-left -X- _ O
model. -X- _ O
Unfortunately, -X- _ O
standard -X- _ O
conditional -X- _ O
language -X- _ O
models -X- _ O
can -X- _ O
only -X- _ O
be -X- _ O
trained -X- _ O
left-to-right -X- _ O
or -X- _ O
right-to-left, -X- _ O
since -X- _ O
bidirectional -X- _ O
conditioning -X- _ O
would -X- _ O
allow -X- _ O
each -X- _ O
word -X- _ O
to -X- _ O
indirectly -X- _ O
"see -X- _ O
itself", -X- _ O
and -X- _ O
the -X- _ O
model -X- _ O
could -X- _ O
trivially -X- _ O
predict -X- _ O
the -X- _ O
target -X- _ O
word -X- _ O
in -X- _ O
a -X- _ O
multi-layered -X- _ O
context. -X- _ O
former -X- _ O
is -X- _ O
often -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
a -X- _ O
"Transformer -X- _ O
encoder" -X- _ O
while -X- _ O
the -X- _ O
left-context-only -X- _ O
version -X- _ O
is -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
a -X- _ O
"Transformer -X- _ O
decoder" -X- _ O
since -X- _ O
it -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
for -X- _ O
text -X- _ O
generation. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
deep -X- _ O
bidirectional -X- _ O
representation, -X- _ O
we -X- _ O
simply -X- _ O
mask -X- _ O
some -X- _ O
percentage -X- _ O
of -X- _ O
the -X- _ O
input -X- _ O
tokens -X- _ O
at -X- _ O
random, -X- _ O
and -X- _ O
then -X- _ O
predict -X- _ O
those -X- _ O
masked -X- _ O
tokens. -X- _ O
We -X- _ O
refer -X- _ O
to -X- _ O
this -X- _ O
procedure -X- _ O
as -X- _ O
a -X- _ O
"masked -X- _ B-TaskName
LM" -X- _ I-TaskName
(MLM), -X- _ B-TaskName
although -X- _ O
it -X- _ O
is -X- _ O
often -X- _ O
referred -X- _ O
to -X- _ O
as -X- _ O
a -X- _ O
Cloze -X- _ O
task -X- _ O
in -X- _ O
the -X- _ O
literature -X- _ O
(Taylor, -X- _ O
1953). -X- _ O
In -X- _ O
this -X- _ O
case, -X- _ O
the -X- _ O
final -X- _ O
hidden -X- _ O
vectors -X- _ O
corresponding -X- _ O
to -X- _ O
the -X- _ O
mask -X- _ O
tokens -X- _ O
are -X- _ O
fed -X- _ O
into -X- _ O
an -X- _ O
output -X- _ O
softmax -X- _ O
over -X- _ O
the -X- _ O
vocabulary, -X- _ O
as -X- _ O
in -X- _ O
a -X- _ O
standard -X- _ O
LM. -X- _ O
In -X- _ O
all -X- _ O
of -X- _ O
our -X- _ O
experiments, -X- _ O
we -X- _ O
mask -X- _ O
15% -X- _ O
of -X- _ O
all -X- _ O
WordPiece -X- _ O
tokens -X- _ O
in -X- _ O
each -X- _ O
sequence -X- _ O
at -X- _ O
random. -X- _ O
In -X- _ O
contrast -X- _ O
to -X- _ O
denoising -X- _ O
auto-encoders -X- _ O
(Vincent -X- _ O
et -X- _ O
al., -X- _ O
2008), -X- _ O
we -X- _ O
only -X- _ O
predict -X- _ O
the -X- _ O
masked -X- _ O
words -X- _ O
rather -X- _ O
than -X- _ O
reconstructing -X- _ O
the -X- _ O
entire -X- _ O
input. -X- _ O
Although -X- _ O
this -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
obtain -X- _ O
a -X- _ O
bidirectional -X- _ O
pre-trained -X- _ O
model, -X- _ O
a -X- _ O
downside -X- _ O
is -X- _ O
that -X- _ O
we -X- _ O
are -X- _ O
creating -X- _ O
a -X- _ O
mismatch -X- _ O
between -X- _ O
pre-training -X- _ O
and -X- _ O
fine-tuning, -X- _ O
since -X- _ O
the -X- _ O
[MASK] -X- _ O
token -X- _ O
does -X- _ O
not -X- _ O
appear -X- _ O
during -X- _ O
fine-tuning. -X- _ O
To -X- _ O
mitigate -X- _ O
this, -X- _ O
we -X- _ O
do -X- _ O
not -X- _ O
always -X- _ O
replace -X- _ O
"masked" -X- _ O
words -X- _ O
with -X- _ O
the -X- _ O
actual -X- _ O
[MASK] -X- _ O
token. -X- _ O
The -X- _ O
training -X- _ O
data -X- _ O
generator -X- _ O
chooses -X- _ O
15% -X- _ O
of -X- _ O
the -X- _ O
token -X- _ O
positions -X- _ O
at -X- _ O
random -X- _ O
for -X- _ O
prediction. -X- _ O
If -X- _ O
the -X- _ O
i-th -X- _ O
token -X- _ O
is -X- _ O
chosen, -X- _ O
we -X- _ O
replace -X- _ O
the -X- _ O
i-th -X- _ O
token -X- _ O
with -X- _ O
(1) -X- _ O
the -X- _ O
[MASK] -X- _ O
token -X- _ O
80% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
(2) -X- _ O
a -X- _ O
random -X- _ O
token -X- _ O
10% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
(3) -X- _ O
the -X- _ O
unchanged -X- _ O
i-th -X- _ O
token -X- _ O
10% -X- _ O
of -X- _ O
the -X- _ O
time. -X- _ O
Then, -X- _ O
T -X- _ O
i -X- _ O
will -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
original -X- _ O
token -X- _ O
with -X- _ O
cross -X- _ B-MetricName
entropy -X- _ I-MetricName
loss. -X- _ I-MetricName
We -X- _ O
compare -X- _ O
variations -X- _ O
of -X- _ O
this -X- _ O
procedure -X- _ O
in -X- _ O
Appendix -X- _ O
C.2. -X- _ O
Task -X- _ O
#2: -X- _ O
Next -X- _ B-TaskName
Sentence -X- _ I-TaskName
Prediction -X- _ I-TaskName
(NSP) -X- _ B-TaskName
Many -X- _ O
important -X- _ O
downstream -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
Question -X- _ B-TaskName
Answering -X- _ I-TaskName
(QA) -X- _ B-TaskName
and -X- _ O
Natural -X- _ B-TaskName
Language -X- _ I-TaskName
Inference -X- _ I-TaskName
(NLI) -X- _ B-TaskName
are -X- _ O
based -X- _ O
on -X- _ O
understanding -X- _ O
the -X- _ O
relationship -X- _ O
between -X- _ O
two -X- _ O
sentences, -X- _ O
which -X- _ O
is -X- _ O
not -X- _ O
directly -X- _ O
captured -X- _ O
by -X- _ O
language -X- _ O
modeling. -X- _ O
In -X- _ O
order -X- _ O
to -X- _ O
train -X- _ O
a -X- _ O
model -X- _ O
that -X- _ O
understands -X- _ O
sentence -X- _ O
relationships, -X- _ O
we -X- _ O
pre-train -X- _ O
for -X- _ O
a -X- _ O
binarized -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
task -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
trivially -X- _ O
generated -X- _ O
from -X- _ O
any -X- _ O
monolingual -X- _ O
corpus. -X- _ O
Specifically, -X- _ O
when -X- _ O
choosing -X- _ O
the -X- _ O
sentences -X- _ O
A -X- _ O
and -X- _ O
B -X- _ O
for -X- _ O
each -X- _ O
pretraining -X- _ O
example, -X- _ O
50% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
B -X- _ O
is -X- _ O
the -X- _ O
actual -X- _ O
next -X- _ O
sentence -X- _ O
that -X- _ O
follows -X- _ O
A -X- _ O
(labeled -X- _ O
as -X- _ O
IsNext), -X- _ O
and -X- _ O
50% -X- _ O
of -X- _ O
the -X- _ O
time -X- _ O
it -X- _ O
is -X- _ O
a -X- _ O
random -X- _ O
sentence -X- _ O
from -X- _ O
the -X- _ O
corpus -X- _ O
(labeled -X- _ O
as -X- _ O
NotNext). -X- _ O
As -X- _ O
we -X- _ O
show -X- _ O
in -X- _ O
Figure -X- _ O
1, -X- _ O
C -X- _ O
is -X- _ O
used -X- _ O
for -X- _ O
next -X- _ O
sentence -X- _ O
prediction -X- _ O
(NSP). -X- _ B-TaskName
5 -X- _ O
Despite -X- _ O
its -X- _ O
simplicity, -X- _ O
we -X- _ O
demonstrate -X- _ O
in -X- _ O
Section -X- _ O
5.1 -X- _ O
that -X- _ O
pre-training -X- _ O
towards -X- _ O
this -X- _ O
task -X- _ O
is -X- _ O
very -X- _ O
beneficial -X- _ O
to -X- _ O
both -X- _ O
QA -X- _ B-TaskName
and -X- _ O
NLI. -X- _ B-TaskName
6 -X- _ O
The -X- _ O
NSP -X- _ B-TaskName
task -X- _ O
is -X- _ O
closely -X- _ O
related -X- _ O
to -X- _ O
representationlearning -X- _ O
objectives -X- _ O
used -X- _ O
in -X- _ O
Jernite -X- _ O
et -X- _ O
al. -X- _ O
(2017) -X- _ O
and -X- _ O
Logeswaran -X- _ O
and -X- _ O
Lee -X- _ O
(2018). -X- _ O
However, -X- _ O
in -X- _ O
prior -X- _ O
work, -X- _ O
only -X- _ O
sentence -X- _ O
embeddings -X- _ O
are -X- _ O
transferred -X- _ O
to -X- _ O
down-stream -X- _ O
tasks, -X- _ O
where -X- _ O
BERT -X- _ B-MethodName
transfers -X- _ O
all -X- _ O
parameters -X- _ O
to -X- _ O
initialize -X- _ O
end-task -X- _ O
model -X- _ O
parameters. -X- _ O

We -X- _ O
introduce -X- _ O
BERT -X- _ B-MethodName
and -X- _ O
its -X- _ O
detailed -X- _ O
implementation -X- _ O
in -X- _ O
this -X- _ O
section. -X- _ O
There -X- _ O
are -X- _ O
two -X- _ O
steps -X- _ O
in -X- _ O
our -X- _ O
framework: -X- _ O
pre-training -X- _ O
and -X- _ O
fine-tuning. -X- _ O
During -X- _ O
pre-training, -X- _ O
the -X- _ O
model -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
unlabeled -X- _ O
data -X- _ O
over -X- _ O
different -X- _ O
pre-training -X- _ O
tasks. -X- _ O
For -X- _ O
finetuning, -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
is -X- _ O
first -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
pre-trained -X- _ O
parameters, -X- _ O
and -X- _ O
all -X- _ O
of -X- _ O
the -X- _ O
parameters -X- _ O
are -X- _ O
fine-tuned -X- _ O
using -X- _ O
labeled -X- _ O
data -X- _ O
from -X- _ O
the -X- _ O
downstream -X- _ O
tasks. -X- _ O
Each -X- _ O
downstream -X- _ O
task -X- _ O
has -X- _ O
separate -X- _ O
fine-tuned -X- _ O
models, -X- _ O
even -X- _ O
though -X- _ O
they -X- _ O
are -X- _ O
initialized -X- _ O
with -X- _ O
the -X- _ O
same -X- _ O
pre-trained -X- _ O
parameters. -X- _ O
The -X- _ O
question-answering -X- _ B-TaskName
example -X- _ O
in -X- _ O
Figure -X- _ O
1 -X- _ O
will -X- _ O
serve -X- _ O
as -X- _ O
a -X- _ O
running -X- _ O
example -X- _ O
for -X- _ O
this -X- _ O
section. -X- _ O
A -X- _ O
distinctive -X- _ O
feature -X- _ O
of -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
its -X- _ O
unified -X- _ O
architecture -X- _ O
across -X- _ O
different -X- _ O
tasks. -X- _ O
There -X- _ O
is -X- _ O
mini-mal -X- _ O
difference -X- _ O
between -X- _ O
the -X- _ O
pre-trained -X- _ O
architecture -X- _ O
and -X- _ O
the -X- _ O
final -X- _ O
downstream -X- _ O
architecture. -X- _ O
Model -X- _ O
Architecture -X- _ O
BERT's -X- _ B-MethodName
model -X- _ O
architecture -X- _ O
is -X- _ O
a -X- _ O
multi-layer -X- _ O
bidirectional -X- _ O
Transformer -X- _ O
encoder -X- _ O
based -X- _ O
on -X- _ O
the -X- _ O
original -X- _ O
implementation -X- _ O
described -X- _ O
in -X- _ O
Vaswani -X- _ O
et -X- _ O
al. -X- _ O
(2017) -X- _ O
and -X- _ O
released -X- _ O
in -X- _ O
the -X- _ O
tensor2tensor -X- _ O
library. -X- _ O
1 -X- _ O
Because -X- _ O
the -X- _ O
use -X- _ O
of -X- _ O
Transformers -X- _ O
has -X- _ O
become -X- _ O
common -X- _ O
and -X- _ O
our -X- _ O
implementation -X- _ O
is -X- _ O
almost -X- _ O
identical -X- _ O
to -X- _ O
the -X- _ O
original, -X- _ O
we -X- _ O
will -X- _ O
omit -X- _ O
an -X- _ O
exhaustive -X- _ O
background -X- _ O
description -X- _ O
of -X- _ O
the -X- _ O
model -X- _ O
architecture -X- _ O
and -X- _ O
refer -X- _ O
readers -X- _ O
to -X- _ O
Vaswani -X- _ O
et -X- _ O
al. -X- _ O
(2017) -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
excellent -X- _ O
guides -X- _ O
such -X- _ O
as -X- _ O
"The -X- _ O
Annotated -X- _ O
Transformer." -X- _ O
2 -X- _ O
In -X- _ O
this -X- _ O
work, -X- _ O
we -X- _ O
denote -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
layers -X- _ I-HyperparameterName
(i.e., -X- _ O
Transformer -X- _ O
blocks) -X- _ O
as -X- _ O
L, -X- _ B-HyperparameterName
the -X- _ O
hidden -X- _ B-HyperparameterName
size -X- _ I-HyperparameterName
as -X- _ O
H, -X- _ B-HyperparameterName
and -X- _ O
the -X- _ O
number -X- _ B-HyperparameterName
of -X- _ I-HyperparameterName
self-attention -X- _ I-HyperparameterName
heads -X- _ I-HyperparameterName
as -X- _ O
A. -X- _ B-HyperparameterName
3 -X- _ O
We -X- _ O
primarily -X- _ O
report -X- _ O
results -X- _ O
on -X- _ O
two -X- _ O
model -X- _ O
sizes: -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
was -X- _ O
chosen -X- _ O
to -X- _ O
have -X- _ O
the -X- _ O
same -X- _ O
model -X- _ O
size -X- _ O
as -X- _ O
OpenAI -X- _ O
GPT -X- _ B-MethodName
for -X- _ O
comparison -X- _ O
purposes. -X- _ O
Critically, -X- _ O
however, -X- _ O
the -X- _ O
BERT -X- _ B-MethodName
Transformer -X- _ O
uses -X- _ O
bidirectional -X- _ O
self-attention, -X- _ O
while -X- _ O
the -X- _ O
GPT -X- _ B-MethodName
Transformer -X- _ O
uses -X- _ O
constrained -X- _ O
self-attention -X- _ O
where -X- _ O
every -X- _ O
token -X- _ O
can -X- _ O
only -X- _ O
attend -X- _ O
to -X- _ O
context -X- _ O
to -X- _ O
its -X- _ O
left. -X- _ O
4 -X- _ O
Input/Output -X- _ O
Representations -X- _ O
To -X- _ O
make -X- _ O
BERT -X- _ B-MethodName
handle -X- _ O
a -X- _ O
variety -X- _ O
of -X- _ O
down-stream -X- _ O
tasks, -X- _ O
our -X- _ O
input -X- _ O
representation -X- _ O
is -X- _ O
able -X- _ O
to -X- _ O
unambiguously -X- _ O
represent -X- _ O
both -X- _ O
a -X- _ O
single -X- _ O
sentence -X- _ O
and -X- _ O
a -X- _ O
pair -X- _ O
of -X- _ O
sentences -X- _ O
(e.g., -X- _ O
h -X- _ O
Question, -X- _ O
Answer -X- _ O
i) -X- _ O
in -X- _ O
one -X- _ O
token -X- _ O
sequence. -X- _ O
Throughout -X- _ O
this -X- _ O
work, -X- _ O
a -X- _ O
"sentence" -X- _ O
can -X- _ O
be -X- _ O
an -X- _ O
arbitrary -X- _ O
span -X- _ O
of -X- _ O
contiguous -X- _ O
text, -X- _ O
rather -X- _ O
than -X- _ O
an -X- _ O
actual -X- _ O
linguistic -X- _ O
sentence. -X- _ O
A -X- _ O
"sequence" -X- _ O
refers -X- _ O
to -X- _ O
the -X- _ O
input -X- _ O
token -X- _ O
sequence -X- _ O
to -X- _ O
BERT, -X- _ B-MethodName
which -X- _ O
may -X- _ O
be -X- _ O
a -X- _ O
single -X- _ O
sentence -X- _ O
or -X- _ O
two -X- _ O
sentences -X- _ O
packed -X- _ O
together. -X- _ O
BERT -X- _ B-MethodName
BASE -X- _ I-MethodName
(L=12, -X- _ B-HyperparameterName
We -X- _ O
use -X- _ O
WordPiece -X- _ O
embeddings -X- _ O
(Wu -X- _ O
et -X- _ O
al., -X- _ O
2016) -X- _ O
with -X- _ O
a -X- _ O
30,000 -X- _ B-HyperparameterValue
token -X- _ B-HyperparameterName
vocabulary. -X- _ I-HyperparameterName
The -X- _ O
first -X- _ O
token -X- _ O
of -X- _ O
every -X- _ O
sequence -X- _ O
is -X- _ O
always -X- _ O
a -X- _ O
special -X- _ O
classification -X- _ O
token -X- _ O
([CLS]). -X- _ O
The -X- _ O
final -X- _ O
hidden -X- _ O
state -X- _ O
corresponding -X- _ O
to -X- _ O
this -X- _ O
token -X- _ O
is -X- _ O
used -X- _ O
as -X- _ O
the -X- _ O
aggregate -X- _ O
sequence -X- _ O
representation -X- _ O
for -X- _ O
classification -X- _ O
tasks. -X- _ O
Sentence -X- _ O
pairs -X- _ O
are -X- _ O
packed -X- _ O
together -X- _ O
into -X- _ O
a -X- _ O
single -X- _ O
sequence. -X- _ O
We -X- _ O
differentiate -X- _ O
the -X- _ O
sentences -X- _ O
in -X- _ O
two -X- _ O
ways. -X- _ O
First, -X- _ O
we -X- _ O
separate -X- _ O
them -X- _ O
with -X- _ O
a -X- _ O
special -X- _ O
token -X- _ O
([SEP]). -X- _ O
Second, -X- _ O
we -X- _ O
add -X- _ O
a -X- _ O
learned -X- _ O
embedding -X- _ O
to -X- _ O
every -X- _ O
token -X- _ O
indicating -X- _ O
whether -X- _ O
it -X- _ O
belongs -X- _ O
to -X- _ O
sentence -X- _ O
A -X- _ O
or -X- _ O
sentence -X- _ O
B. -X- _ O
As -X- _ O
shown -X- _ O
in -X- _ O
Figure -X- _ O
1, -X- _ O
we -X- _ O
denote -X- _ O
input -X- _ O
embedding -X- _ B-HyperparameterName
as -X- _ O
E, -X- _ B-HyperparameterName
the -X- _ O
final -X- _ O
hidden -X- _ O
vector -X- _ O
of -X- _ O
the -X- _ O
special -X- _ O
[CLS] -X- _ O
token -X- _ O
as -X- _ O
C -X- _ O
2 -X- _ O
R -X- _ O
H -X- _ O
, -X- _ O
and -X- _ O
the -X- _ O
final -X- _ O
hidden -X- _ O
vector -X- _ O
for -X- _ O
the -X- _ O
i -X- _ O
th -X- _ O
input -X- _ O
token -X- _ O
as -X- _ O
T -X- _ O
i -X- _ O
2 -X- _ O
R -X- _ O
H -X- _ O
. -X- _ O
For -X- _ O
a -X- _ O
given -X- _ O
token, -X- _ O
its -X- _ O
input -X- _ O
representation -X- _ O
is -X- _ O
constructed -X- _ O
by -X- _ O
summing -X- _ O
the -X- _ O
corresponding -X- _ O
token, -X- _ O
segment, -X- _ O
and -X- _ O
position -X- _ O
embeddings. -X- _ O
A -X- _ O
visualization -X- _ O
of -X- _ O
this -X- _ O
construction -X- _ O
can -X- _ O
be -X- _ O
seen -X- _ O
in -X- _ O
Figure -X- _ O
2. -X- _ O

There -X- _ O
has -X- _ O
also -X- _ O
been -X- _ O
work -X- _ O
showing -X- _ O
effective -X- _ O
transfer -X- _ O
from -X- _ O
supervised -X- _ O
tasks -X- _ O
with -X- _ O
large -X- _ O
datasets, -X- _ O
such -X- _ O
as -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
(Conneau -X- _ O
et -X- _ O
al., -X- _ O
2017) -X- _ O
and -X- _ O
machine -X- _ O
translation -X- _ O
(McCann -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O
Computer -X- _ O
vision -X- _ O
research -X- _ O
has -X- _ O
also -X- _ O
demonstrated -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
transfer -X- _ O
learning -X- _ O
from -X- _ O
large -X- _ O
pre-trained -X- _ O
models, -X- _ O
where -X- _ O
an -X- _ O
effective -X- _ O
recipe -X- _ O
is -X- _ O
to -X- _ O
fine-tune -X- _ O
models -X- _ O
pre-trained -X- _ O
with -X- _ O
Ima-geNet -X- _ O
(Deng -X- _ O
et -X- _ O
al., -X- _ O
2009;Yosinski -X- _ O
et -X- _ O
al., -X- _ O
2014). -X- _ O

There -X- _ O
is -X- _ O
a -X- _ O
long -X- _ O
history -X- _ O
of -X- _ O
pre-training -X- _ O
general -X- _ O
language -X- _ O
representations, -X- _ O
and -X- _ O
we -X- _ O
briefly -X- _ O
review -X- _ O
the -X- _ O
most -X- _ O
widely-used -X- _ O
approaches -X- _ O
in -X- _ O
this -X- _ O
section. -X- _ O

Learning -X- _ O
widely -X- _ O
applicable -X- _ O
representations -X- _ O
of -X- _ O
words -X- _ O
has -X- _ O
been -X- _ O
an -X- _ O
active -X- _ O
area -X- _ O
of -X- _ O
research -X- _ O
for -X- _ O
decades, -X- _ O
including -X- _ O
non-neural -X- _ O
(Brown -X- _ O
et -X- _ O
al., -X- _ O
1992;Ando -X- _ O
and -X- _ O
Zhang, -X- _ O
2005;Blitzer -X- _ O
et -X- _ O
al., -X- _ O
2006) -X- _ O
and -X- _ O
neural -X- _ O
Pennington -X- _ O
et -X- _ O
al., -X- _ O
2014) -X- _ O
methods. -X- _ O
Pre-trained -X- _ O
word -X- _ O
embeddings -X- _ O
are -X- _ O
an -X- _ O
integral -X- _ O
part -X- _ O
of -X- _ O
modern -X- _ O
NLP -X- _ O
systems, -X- _ O
offering -X- _ O
significant -X- _ O
improvements -X- _ O
over -X- _ O
embeddings -X- _ O
learned -X- _ O
from -X- _ O
scratch -X- _ O
(Turian -X- _ O
et -X- _ O
al., -X- _ O
2010). -X- _ O
To -X- _ O
pretrain -X- _ O
word -X- _ O
embedding -X- _ O
vectors, -X- _ O
left-to-right -X- _ O
language -X- _ O
modeling -X- _ O
objectives -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
(Mnih -X- _ O
and -X- _ O
Hinton, -X- _ O
2009), -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
objectives -X- _ O
to -X- _ O
discriminate -X- _ O
correct -X- _ O
from -X- _ O
incorrect -X- _ O
words -X- _ O
in -X- _ O
left -X- _ O
and -X- _ O
right -X- _ O
context -X- _ O
. -X- _ O
These -X- _ O
approaches -X- _ O
have -X- _ O
been -X- _ O
generalized -X- _ O
to -X- _ O
coarser -X- _ O
granularities, -X- _ O
such -X- _ O
as -X- _ O
sentence -X- _ O
embeddings -X- _ O
Logeswaran -X- _ O
and -X- _ O
Lee, -X- _ O
2018) -X- _ O
or -X- _ O
paragraph -X- _ O
embeddings -X- _ O
(Le -X- _ O
and -X- _ O
Mikolov, -X- _ O
2014). -X- _ O
To -X- _ O
train -X- _ O
sentence -X- _ O
representations, -X- _ O
prior -X- _ O
work -X- _ O
has -X- _ O
used -X- _ O
objectives -X- _ O
to -X- _ O
rank -X- _ O
candidate -X- _ O
next -X- _ O
sentences -X- _ O
(Jernite -X- _ O
et -X- _ O
al., -X- _ O
2017;Logeswaran -X- _ O
and -X- _ O
Lee, -X- _ O
2018), -X- _ O
left-to-right -X- _ O
generation -X- _ O
of -X- _ O
next -X- _ O
sentence -X- _ O
words -X- _ O
given -X- _ O
a -X- _ O
representation -X- _ O
of -X- _ O
the -X- _ O
previous -X- _ O
sentence -X- _ O
, -X- _ O
or -X- _ O
denoising -X- _ O
autoencoder -X- _ O
derived -X- _ O
objectives -X- _ O
(Hill -X- _ O
et -X- _ O
al., -X- _ O
2016). -X- _ O
ELMo -X- _ O
and -X- _ O
its -X- _ O
predecessor -X- _ O
(Peters -X- _ O
et -X- _ O
al., -X- _ O
2017(Peters -X- _ O
et -X- _ O
al., -X- _ O
, -X- _ O
2018a -X- _ O
generalize -X- _ O
traditional -X- _ O
word -X- _ O
embedding -X- _ O
research -X- _ O
along -X- _ O
a -X- _ O
different -X- _ O
dimension. -X- _ O
They -X- _ O
extract -X- _ O
context-sensitive -X- _ O
features -X- _ O
from -X- _ O
a -X- _ O
left-to-right -X- _ O
and -X- _ O
a -X- _ O
right-to-left -X- _ O
language -X- _ O
model. -X- _ O
The -X- _ O
contextual -X- _ O
representation -X- _ O
of -X- _ O
each -X- _ O
token -X- _ O
is -X- _ O
the -X- _ O
concatenation -X- _ O
of -X- _ O
the -X- _ O
left-to-right -X- _ O
and -X- _ O
right-to-left -X- _ O
representations. -X- _ O
When -X- _ O
integrating -X- _ O
contextual -X- _ O
word -X- _ O
embeddings -X- _ O
with -X- _ O
existing -X- _ O
task-specific -X- _ O
architectures, -X- _ O
ELMo -X- _ O
advances -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
for -X- _ O
several -X- _ O
major -X- _ O
NLP -X- _ O
benchmarks -X- _ O
(Peters -X- _ O
et -X- _ O
al., -X- _ O
2018a) -X- _ O
including -X- _ O
question -X- _ O
answering -X- _ O
(Rajpurkar -X- _ O
et -X- _ O
al., -X- _ O
2016), -X- _ O
sentiment -X- _ O
analysis -X- _ O
(Socher -X- _ O
et -X- _ O
al., -X- _ O
2013), -X- _ O
and -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
(Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder, -X- _ O
2003). -X- _ O
Melamud -X- _ O
et -X- _ O
al. -X- _ O
(2016) -X- _ O
proposed -X- _ O
learning -X- _ O
contextual -X- _ O
representations -X- _ O
through -X- _ O
a -X- _ O
task -X- _ O
to -X- _ O
predict -X- _ O
a -X- _ O
single -X- _ O
word -X- _ O
from -X- _ O
both -X- _ O
left -X- _ O
and -X- _ O
right -X- _ O
context -X- _ O
using -X- _ O
LSTMs. -X- _ O
Similar -X- _ O
to -X- _ O
ELMo, -X- _ O
their -X- _ O
model -X- _ O
is -X- _ O
feature-based -X- _ O
and -X- _ O
not -X- _ O
deeply -X- _ O
bidirectional. -X- _ O
Fedus -X- _ O
et -X- _ O
al. -X- _ O
(2018) -X- _ O
shows -X- _ O
that -X- _ O
the -X- _ O
cloze -X- _ O
task -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
to -X- _ O
improve -X- _ O
the -X- _ O
robustness -X- _ O
of -X- _ O
text -X- _ O
generation -X- _ O
models. -X- _ O

As -X- _ O
with -X- _ O
the -X- _ O
feature-based -X- _ O
approaches, -X- _ O
the -X- _ O
first -X- _ O
works -X- _ O
in -X- _ O
this -X- _ O
direction -X- _ O
only -X- _ O
pre-trained -X- _ O
word -X- _ O
embedding -X- _ O
parameters -X- _ O
from -X- _ O
unlabeled -X- _ O
text -X- _ O
(Collobert -X- _ O
and -X- _ O
Weston, -X- _ O
2008). -X- _ O
More -X- _ O
recently, -X- _ O
sentence -X- _ O
or -X- _ O
document -X- _ O
encoders -X- _ O
which -X- _ O
produce -X- _ O
contextual -X- _ O
token -X- _ O
representations -X- _ O
have -X- _ O
been -X- _ O
pre-trained -X- _ O
from -X- _ O
unlabeled -X- _ O
text -X- _ O
and -X- _ O
fine-tuned -X- _ O
for -X- _ O
a -X- _ O
supervised -X- _ O
downstream -X- _ O
task -X- _ O
(Dai -X- _ O
and -X- _ O
Le, -X- _ O
2015;Howard -X- _ O
and -X- _ O
Ruder, -X- _ O
2018;Radford -X- _ O
et -X- _ O
al., -X- _ O
2018). -X- _ O
The -X- _ O
advantage -X- _ O
of -X- _ O
these -X- _ O
approaches -X- _ O
is -X- _ O
that -X- _ O
few -X- _ O
parameters -X- _ O
need -X- _ O
to -X- _ O
be -X- _ O
learned -X- _ O
from -X- _ O
scratch. -X- _ O
At -X- _ O
least -X- _ O
partly -X- _ O
due -X- _ O
to -X- _ O
this -X- _ O
advantage, -X- _ O
OpenAI -X- _ O
GPT -X- _ O
(Radford -X- _ O
et -X- _ O
al., -X- _ O
2018) -X- _ O
achieved -X- _ O
previously -X- _ O
state-of-the-art -X- _ O
results -X- _ O
on -X- _ O
many -X- _ O
sentencelevel -X- _ O
tasks -X- _ O
from -X- _ O
the -X- _ O
GLUE -X- _ B-DatasetName
benchmark -X- _ O
(Wang -X- _ O
et -X- _ O
al., -X- _ O
2018a). -X- _ O
Left-to-right -X- _ O
language -X- _ O
model-BERT -X- _ B-MethodName
BERT -X- _ B-MethodName
E -X- _ O
[CLS] -X- _ O
E -X- _ O
1 -X- _ O
E -X- _ O
[SEP] -X- _ O
... -X- _ O
E -X- _ O
N -X- _ O
E -X- _ O
1 -X- _ O
' -X- _ O
... -X- _ O
E -X- _ O
M -X- _ O
' -X- _ O
C -X- _ O
T -X- _ O
1 -X- _ O
T -X- _ O
[SEP] -X- _ O
... -X- _ O
... -X- _ O
ing -X- _ O
and -X- _ O
auto-encoder -X- _ O
objectives -X- _ O
have -X- _ O
been -X- _ O
used -X- _ O
for -X- _ O
pre-training -X- _ O
such -X- _ O
models -X- _ O
(Howard -X- _ O
and -X- _ O
Ruder, -X- _ O
2018;Radford -X- _ O
et -X- _ O
al., -X- _ O
2018;Dai -X- _ O
and -X- _ O
Le, -X- _ O
2015). -X- _ O

Language -X- _ O
model -X- _ O
pre-training -X- _ O
has -X- _ O
been -X- _ O
shown -X- _ O
to -X- _ O
be -X- _ O
effective -X- _ O
for -X- _ O
improving -X- _ O
many -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
tasks -X- _ O
(Dai -X- _ O
and -X- _ O
Le, -X- _ O
2015;Peters -X- _ O
et -X- _ O
al., -X- _ O
2018a;Radford -X- _ O
et -X- _ O
al., -X- _ O
2018;Howard -X- _ O
and -X- _ O
Ruder, -X- _ O
2018). -X- _ O
These -X- _ O
include -X- _ O
sentence-level -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
natural -X- _ O
language -X- _ O
inference -X- _ O
(Bowman -X- _ O
et -X- _ O
al., -X- _ O
2015;Williams -X- _ O
et -X- _ O
al., -X- _ O
2018) -X- _ O
and -X- _ O
paraphrasing -X- _ O
(Dolan -X- _ O
and -X- _ O
Brockett, -X- _ O
2005), -X- _ O
which -X- _ O
aim -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
relationships -X- _ O
between -X- _ O
sentences -X- _ O
by -X- _ O
analyzing -X- _ O
them -X- _ O
holistically, -X- _ O
as -X- _ O
well -X- _ O
as -X- _ O
token-level -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
named -X- _ O
entity -X- _ O
recognition -X- _ O
and -X- _ O
question -X- _ O
answering, -X- _ O
where -X- _ O
models -X- _ O
are -X- _ O
required -X- _ O
to -X- _ O
produce -X- _ O
fine-grained -X- _ O
output -X- _ O
at -X- _ O
the -X- _ O
token -X- _ O
level -X- _ O
(Tjong -X- _ O
Kim -X- _ O
Sang -X- _ O
and -X- _ O
De -X- _ O
Meulder, -X- _ O
2003;Rajpurkar -X- _ O
et -X- _ O
al., -X- _ O
2016). -X- _ O
There -X- _ O
are -X- _ O
two -X- _ O
existing -X- _ O
strategies -X- _ O
for -X- _ O
applying -X- _ O
pre-trained -X- _ O
language -X- _ O
representations -X- _ O
to -X- _ O
downstream -X- _ O
tasks: -X- _ O
feature-based -X- _ O
and -X- _ O
fine-tuning. -X- _ O
The -X- _ O
feature-based -X- _ O
approach, -X- _ O
such -X- _ O
as -X- _ O
ELMo -X- _ O
(Peters -X- _ O
et -X- _ O
al., -X- _ O
2018a), -X- _ O
uses -X- _ O
task-specific -X- _ O
architectures -X- _ O
that -X- _ O
include -X- _ O
the -X- _ O
pre-trained -X- _ O
representations -X- _ O
as -X- _ O
additional -X- _ O
features. -X- _ O
The -X- _ O
fine-tuning -X- _ O
approach, -X- _ O
such -X- _ O
as -X- _ O
the -X- _ O
Generative -X- _ O
Pre-trained -X- _ O
Transformer -X- _ O
(OpenAI -X- _ O
GPT) -X- _ O
(Radford -X- _ O
et -X- _ O
al., -X- _ O
2018), -X- _ O
introduces -X- _ O
minimal -X- _ B-HyperparameterName
task-specific -X- _ O
parameters, -X- _ O
and -X- _ O
is -X- _ O
trained -X- _ O
on -X- _ O
the -X- _ O
downstream -X- _ O
tasks -X- _ O
by -X- _ O
simply -X- _ O
fine-tuning -X- _ O
all -X- _ O
pretrained -X- _ O
parameters. -X- _ O
The -X- _ O
two -X- _ O
approaches -X- _ O
share -X- _ O
the -X- _ O
same -X- _ O
objective -X- _ O
function -X- _ O
during -X- _ O
pre-training, -X- _ O
where -X- _ O
they -X- _ O
use -X- _ O
unidirectional -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
learn -X- _ O
general -X- _ O
language -X- _ O
representations. -X- _ O
We -X- _ O
argue -X- _ O
that -X- _ O
current -X- _ O
techniques -X- _ O
restrict -X- _ O
the -X- _ O
power -X- _ O
of -X- _ O
the -X- _ O
pre-trained -X- _ O
representations, -X- _ O
especially -X- _ O
for -X- _ O
the -X- _ O
fine-tuning -X- _ O
approaches. -X- _ O
The -X- _ O
major -X- _ O
limitation -X- _ O
is -X- _ O
that -X- _ O
standard -X- _ O
language -X- _ O
models -X- _ O
are -X- _ O
unidirectional, -X- _ O
and -X- _ O
this -X- _ O
limits -X- _ O
the -X- _ O
choice -X- _ O
of -X- _ O
architectures -X- _ O
that -X- _ O
can -X- _ O
be -X- _ O
used -X- _ O
during -X- _ O
pre-training. -X- _ O
For -X- _ O
example, -X- _ O
in -X- _ O
OpenAI -X- _ O
GPT, -X- _ O
the -X- _ O
authors -X- _ O
use -X- _ O
a -X- _ O
left-toright -X- _ O
architecture, -X- _ O
where -X- _ O
every -X- _ O
token -X- _ O
can -X- _ O
only -X- _ O
attend -X- _ O
to -X- _ O
previous -X- _ O
tokens -X- _ O
in -X- _ O
the -X- _ O
self-attention -X- _ O
layers -X- _ O
of -X- _ O
the -X- _ O
Transformer -X- _ O
(Vaswani -X- _ O
et -X- _ O
al., -X- _ O
2017). -X- _ O
Such -X- _ O
restrictions -X- _ O
are -X- _ O
sub-optimal -X- _ O
for -X- _ O
sentence-level -X- _ O
tasks, -X- _ O
and -X- _ O
could -X- _ O
be -X- _ O
very -X- _ O
harmful -X- _ O
when -X- _ O
applying -X- _ O
finetuning -X- _ O
based -X- _ O
approaches -X- _ O
to -X- _ O
token-level -X- _ O
tasks -X- _ O
such -X- _ O
as -X- _ O
question -X- _ O
answering, -X- _ O
where -X- _ O
it -X- _ O
is -X- _ O
crucial -X- _ O
to -X- _ O
incorporate -X- _ O
context -X- _ O
from -X- _ O
both -X- _ O
directions. -X- _ O
In -X- _ O
this -X- _ O
paper, -X- _ O
we -X- _ O
improve -X- _ O
the -X- _ O
fine-tuning -X- _ O
based -X- _ O
approaches -X- _ O
by -X- _ O
proposing -X- _ O
BERT: -X- _ B-MethodName
Bidirectional -X- _ B-MethodName
Encoder -X- _ I-MethodName
Representations -X- _ I-MethodName
from -X- _ I-MethodName
Transformers. -X- _ I-MethodName
BERT -X- _ B-MethodName
alleviates -X- _ O
the -X- _ O
previously -X- _ O
mentioned -X- _ O
unidirectionality -X- _ O
constraint -X- _ O
by -X- _ O
using -X- _ O
a -X- _ O
"masked -X- _ O
language -X- _ O
model" -X- _ O
(MLM) -X- _ O
pre-training -X- _ O
objective, -X- _ O
inspired -X- _ O
by -X- _ O
the -X- _ O
Cloze -X- _ O
task -X- _ O
(Taylor, -X- _ O
1953). -X- _ O
The -X- _ O
masked -X- _ O
language -X- _ O
model -X- _ O
randomly -X- _ O
masks -X- _ O
some -X- _ O
of -X- _ O
the -X- _ O
tokens -X- _ O
from -X- _ O
the -X- _ O
input, -X- _ O
and -X- _ O
the -X- _ O
objective -X- _ O
is -X- _ O
to -X- _ O
predict -X- _ O
the -X- _ O
original -X- _ O
vocabulary -X- _ O
id -X- _ O
of -X- _ O
the -X- _ O
masked -X- _ O
word -X- _ O
based -X- _ O
only -X- _ O
on -X- _ O
its -X- _ O
context. -X- _ O
Unlike -X- _ O
left-toright -X- _ O
language -X- _ O
model -X- _ O
pre-training, -X- _ O
the -X- _ O
MLM -X- _ O
objective -X- _ O
enables -X- _ O
the -X- _ O
representation -X- _ O
to -X- _ O
fuse -X- _ O
the -X- _ O
left -X- _ O
and -X- _ O
the -X- _ O
right -X- _ O
context, -X- _ O
which -X- _ O
allows -X- _ O
us -X- _ O
to -X- _ O
pretrain -X- _ O
a -X- _ O
deep -X- _ O
bidirectional -X- _ O
Transformer. -X- _ O
In -X- _ O
addition -X- _ O
to -X- _ O
the -X- _ O
masked -X- _ O
language -X- _ O
model, -X- _ O
we -X- _ O
also -X- _ O
use -X- _ O
a -X- _ O
"next -X- _ O
sentence -X- _ O
prediction" -X- _ O
task -X- _ O
that -X- _ O
jointly -X- _ O
pretrains -X- _ O
text-pair -X- _ O
representations. -X- _ O
The -X- _ O
contributions -X- _ O
of -X- _ O
our -X- _ O
paper -X- _ O
are -X- _ O
as -X- _ O
follows: -X- _ O
• -X- _ O
We -X- _ O
demonstrate -X- _ O
the -X- _ O
importance -X- _ O
of -X- _ O
bidirectional -X- _ O
pre-training -X- _ O
for -X- _ O
language -X- _ O
representations. -X- _ O
Unlike -X- _ O
Radford -X- _ O
et -X- _ O
al. -X- _ O
(2018), -X- _ O
which -X- _ O
uses -X- _ O
unidirectional -X- _ O
language -X- _ O
models -X- _ O
for -X- _ O
pre-training, -X- _ O
BERT -X- _ B-MethodName
uses -X- _ O
masked -X- _ O
language -X- _ O
models -X- _ O
to -X- _ O
enable -X- _ O
pretrained -X- _ O
deep -X- _ O
bidirectional -X- _ O
representations. -X- _ O
This -X- _ O
is -X- _ O
also -X- _ O
in -X- _ O
contrast -X- _ O
to -X- _ O
Peters -X- _ O
et -X- _ O
al. -X- _ O
(2018a), -X- _ O
which -X- _ O
uses -X- _ O
a -X- _ O
shallow -X- _ O
concatenation -X- _ O
of -X- _ O
independently -X- _ O
trained -X- _ O
left-to-right -X- _ O
and -X- _ O
right-to-left -X- _ O
LMs. -X- _ O
• -X- _ O
We -X- _ O
show -X- _ O
that -X- _ O
pre-trained -X- _ O
representations -X- _ O
reduce -X- _ O
the -X- _ O
need -X- _ O
for -X- _ O
many -X- _ O
heavily-engineered -X- _ O
taskspecific -X- _ O
architectures. -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
the -X- _ O
first -X- _ O
finetuning -X- _ O
based -X- _ O
representation -X- _ O
model -X- _ O
that -X- _ O
achieves -X- _ O
state-of-the-art -X- _ O
performance -X- _ O
on -X- _ O
a -X- _ O
large -X- _ O
suite -X- _ O
of -X- _ O
sentence-level -X- _ O
and -X- _ O
token-level -X- _ O
tasks, -X- _ O
outperforming -X- _ O
many -X- _ O
task-specific -X- _ O
architectures. -X- _ O
• -X- _ O
BERT -X- _ B-MethodName
advances -X- _ O
the -X- _ O
state -X- _ O
of -X- _ O
the -X- _ O
art -X- _ O
for -X- _ O
eleven -X- _ O
NLP -X- _ O
tasks. -X- _ O
The -X- _ O
code -X- _ O
and -X- _ O
pre-trained -X- _ O
models -X- _ O
are -X- _ O
available -X- _ O
at -X- _ O
google-research/bert. -X- _ O

We -X- _ O
introduce -X- _ O
a -X- _ O
new -X- _ O
language -X- _ O
representation -X- _ O
model -X- _ O
called -X- _ O
BERT, -X- _ B-MethodName
which -X- _ O
stands -X- _ O
for -X- _ O
Bidirectional -X- _ B-MethodName
Encoder -X- _ I-MethodName
Representations -X- _ I-MethodName
from -X- _ I-MethodName
Transformers. -X- _ I-MethodName
Unlike -X- _ O
recent -X- _ O
language -X- _ O
representation -X- _ O
models -X- _ O
(Peters -X- _ O
et -X- _ O
al., -X- _ O
2018a;Radford -X- _ O
et -X- _ O
al., -X- _ O
2018), -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
designed -X- _ O
to -X- _ O
pretrain -X- _ O
deep -X- _ O
bidirectional -X- _ O
representations -X- _ O
from -X- _ O
unlabeled -X- _ O
text -X- _ O
by -X- _ O
jointly -X- _ O
conditioning -X- _ O
on -X- _ O
both -X- _ O
left -X- _ O
and -X- _ O
right -X- _ O
context -X- _ O
in -X- _ O
all -X- _ O
layers. -X- _ O
As -X- _ O
a -X- _ O
result, -X- _ O
the -X- _ O
pre-trained -X- _ O
BERT -X- _ B-MethodName
model -X- _ O
can -X- _ O
be -X- _ O
finetuned -X- _ O
with -X- _ O
just -X- _ O
one -X- _ O
additional -X- _ O
output -X- _ O
layer -X- _ O
to -X- _ O
create -X- _ O
state-of-the-art -X- _ O
models -X- _ O
for -X- _ O
a -X- _ O
wide -X- _ O
range -X- _ O
of -X- _ O
tasks, -X- _ O
such -X- _ O
as -X- _ O
question -X- _ O
answering -X- _ O
and -X- _ O
language -X- _ O
inference, -X- _ O
without -X- _ O
substantial -X- _ O
taskspecific -X- _ O
architecture -X- _ O
modifications. -X- _ O
BERT -X- _ B-MethodName
is -X- _ O
conceptually -X- _ O
simple -X- _ O
and -X- _ O
empirically -X- _ O
powerful. -X- _ O
It -X- _ O
obtains -X- _ O
new -X- _ O
state-of-the-art -X- _ O
results -X- _ O
on -X- _ O
eleven -X- _ O
natural -X- _ O
language -X- _ O
processing -X- _ O
tasks, -X- _ O
including -X- _ O
pushing -X- _ O
the -X- _ O
GLUE -X- _ O
score -X- _ O
to -X- _ O
80.5% -X- _ O
(7.7% -X- _ O
point -X- _ O
absolute -X- _ O
improvement), -X- _ O
MultiNLI -X- _ O
accuracy -X- _ O
to -X- _ O
86.7% -X- _ O
(4.6% -X- _ O
absolute -X- _ O
improvement), -X- _ O
SQuAD -X- _ O
v1.1 -X- _ O
question -X- _ O
answering -X- _ O
Test -X- _ O
F1 -X- _ O
to -X- _ O
93.2 -X- _ O
(1.5 -X- _ O
point -X- _ O
absolute -X- _ O
improvement) -X- _ O
and -X- _ O
SQuAD -X- _ O
v2.0 -X- _ O
Test -X- _ O
F1 -X- _ O
to -X- _ O
83.1 -X- _ O
(5.1 -X- _ O
point -X- _ O
absolute -X- _ O
improvement). -X- _ O


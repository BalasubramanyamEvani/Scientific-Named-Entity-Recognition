You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/Users/neelpawar/opt/anaconda3/lib/python3.7/site-packages/transformers/data/data_collator.py:318: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  sequence_length = torch.tensor(batch["input_ids"]).shape[1]
/Users/neelpawar/opt/anaconda3/lib/python3.7/site-packages/transformers/data/data_collator.py:329: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  batch = {k: torch.tensor(v, dtype=torch.int64) for k, v in batch.items()}
***** Running training *****
  Num examples = 264
  Num Epochs = 25
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed & accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 225
***** Running Evaluation *****
  Num examples = 66
  Batch size = 32
{'eval_loss': 0.3632640242576599, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.9416267137690302, 'eval_runtime': 183.0875, 'eval_samples_per_second': 0.36, 'eval_steps_per_second': 0.016, 'epoch': 1.0}
/Users/neelpawar/opt/anaconda3/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/Users/neelpawar/opt/anaconda3/lib/python3.7/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
***** Running Evaluation *****
  Num examples = 66
  Batch size = 32
{'eval_loss': 0.2578881084918976, 'eval_precision': 0.8688524590163934, 'eval_recall': 0.3081395348837209, 'eval_f1': 0.4549356223175966, 'eval_accuracy': 0.954916309193372, 'eval_runtime': 184.9391, 'eval_samples_per_second': 0.357, 'eval_steps_per_second': 0.016, 'epoch': 2.0}
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/Users/neelpawar/opt/anaconda3/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/Users/neelpawar/opt/anaconda3/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/neelpawar/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 148, in check_network_status
    status_response = self._interface.communicate_network_status()
  File "/Users/neelpawar/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 125, in communicate_network_status
    resp = self._communicate_network_status(status)
  File "/Users/neelpawar/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 388, in _communicate_network_status
    resp = self._communicate(req, local=True)
  File "/Users/neelpawar/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 213, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/Users/neelpawar/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 218, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Exception in thread ChkStopThr:
Traceback (most recent call last):
  File "/Users/neelpawar/opt/anaconda3/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/Users/neelpawar/opt/anaconda3/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/Users/neelpawar/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 166, in check_status
    status_response = self._interface.communicate_stop_status()
  File "/Users/neelpawar/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface.py", line 114, in communicate_stop_status
    resp = self._communicate_stop_status(status)
  File "/Users/neelpawar/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 378, in _communicate_stop_status
    resp = self._communicate(req, local=True)
  File "/Users/neelpawar/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 213, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/Users/neelpawar/opt/anaconda3/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py", line 218, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
Exception: The wandb backend process has shutdown
Error in callback <function _WandbInit._resume_backend at 0x7fc73ba9aef0> (for pre_run_cell):
Error in callback <function _WandbInit._pause_backend at 0x7fc73baa6b90> (for post_run_cell):
Error in callback <function _WandbInit._resume_backend at 0x7fc73ba9aef0> (for pre_run_cell):
Error in callback <function _WandbInit._pause_backend at 0x7fc73baa6b90> (for post_run_cell):
Error in callback <function _WandbInit._resume_backend at 0x7fc73ba9aef0> (for pre_run_cell):
Error in callback <function _WandbInit._pause_backend at 0x7fc73baa6b90> (for post_run_cell):
Error in callback <function _WandbInit._resume_backend at 0x7fc73ba9aef0> (for pre_run_cell):
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
zsh:1: number expected
Error in callback <function _WandbInit._pause_backend at 0x7fc73baa6b90> (for post_run_cell):